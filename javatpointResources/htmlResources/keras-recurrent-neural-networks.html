 <!DOCTYPE html><html lang="en">
<!-- Mirrored from www.javatpoint.com/keras-recurrent-neural-networks by HTTrack Website Copier/3.x [XR&CO'2014], Sun, 12 Mar 2023 17:02:13 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=ISO-8859-1" /><!-- /Added by HTTrack -->
<head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Recurrent Neural Networks - Javatpoint</title><link rel="SHORTCUT ICON" href="https://static.javatpoint.com/images/favicon2.png" />
<link rel="stylesheet" type="text/css" href="https://static.javatpoint.com/link.css?v=5.1" async /><link rel="dns-prefetch" href="https://clients1.google.com/"><link rel="dns-prefetch" href="https://static.javatpoint.com/"><link rel="dns-prefetch" href="https://googleads.g.doubleclick.net/"><link rel="dns-prefetch" href="https://www.google.com/"><link rel="dns-prefetch" href="https://feedify.net/"><meta name="theme-color" content="#4CAF50" /><meta property="og:title" content="Recurrent Neural Networks - Javatpoint" /><meta property="og:description" content="Recurrent Neural Networks with What is Keras, Keras Backend, Models, Functional API, Pooling Layers, Merge Layers, Sequence Preprocessing, Metrics, Optimizers, Backend, Visualization etc." />
<meta name="keywords" content="keras tutorial, keras, what is keras, keras backend, keras models, keras functional api, core layer, pooling layers, merge layers, sequence preprocessing, metrics, optimizers, backend, visualization" /><meta name="description" content="Recurrent Neural Networks with What is Keras, Keras Backend, Models, Functional API, Pooling Layers, Merge Layers, Sequence Preprocessing, Metrics, Optimizers, Backend, Visualization etc." /><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><link rel="canonical" href="keras-recurrent-neural-networks.html" />
<meta property="og:locale" content="en_US" /><meta property="og:type" content="article" /><meta name="twitter:title" property="og:title" content="Recurrent Neural Networks - Javatpoint" /><meta name="twitter:description" property="og:description" content="Recurrent Neural Networks with What is Keras, Keras Backend, Models, Functional API, Pooling Layers, Merge Layers, Sequence Preprocessing, Metrics, Optimizers, Backend, Visualization etc." /><meta property="og:url" content="keras-recurrent-neural-networks.html" /><meta property="og:site_name" content="www.javatpoint.com" /><meta name="twitter:card" content="summary" /><meta name="twitter:site" content="@pagejavatpoint" /><meta name="twitter:domain" content="www.javatpoint.com" /><meta name="twitter:creator" content="@pagejavatpoint" />
<link href="manifest.json" rel="manifest">
<script data-cfasync="false" type="text/javascript">(function(w, d) { var s = d.createElement('script'); s.src = 'http://delivery.adrecover.com/37784/adRecover.js?ts=1543562646174'; s.type = 'text/javascript'; s.async = true; (d.getElementsByTagName('head')[0] || d.getElementsByTagName('body')[0]).appendChild(s); })(window, document);</script>

<script data-cfasync="false" type="text/javascript">
(function (w, d) {
  var siteId = "37780";
  var targetElement =
    d.getElementsByTagName("head")[0] || d.getElementsByTagName("body")[0];
  var s = d.createElement("script");
  s.src = "//cdn.adpushup.com/" + siteId + "/adpushup.js";
  s.crossOrigin = "anonymous";
  s.type = "text/javascript";
  s.async = true;
  targetElement.appendChild(s);
  function sendErrorLog(log) {
    var eventName = "script_error";
    log.siteId = siteId;
    var data = btoa(JSON.stringify(log));
    var img = document.createElement("img");
    img.src =
      "https://aplogger.adpushup.com/log?event=HC_" + eventName + "&data=" + data;
  }
  var searchParams =
    typeof URLSearchParams === "function" &&
    new URLSearchParams(window.location.search);
  if (searchParams) {
    var isDebugModeOn = searchParams.has("apDebug");
  }
  w.addEventListener("error", function (event) {
    try {
      var filename = event.filename || "";
      if (filename.indexOf("/" + siteId + "/adpushup.js") === -1) {
        return;
      }
      var error = event.error;
      if (error) {
        var message = error.message;
        var stack = error.stack;
      }
      message = message || event.message;
      var log = {
        message: message,
        stack: stack || "",
        timestamp: Math.floor(event.timeStamp),
        type: "uncaughterror",
      };
      sendErrorLog(log);
      !isDebugModeOn && event.preventDefault();
    } catch (error) {}
  });
  w.addEventListener("unhandledrejection", function (event) {
    var reason = event.reason;
    if (typeof reason === "object") reason = JSON.stringify(reason);
    var log = {
      message: reason || "no reason found",
      timestamp: Math.floor(event.timeStamp),
      type: "unhandledrejection",
    };
    sendErrorLog(log);
    !isDebugModeOn && event.preventDefault();
  });
  var ga = d.createElement("script");
  ga.src = "https://www.googletagmanager.com/gtag/js?id=G-Z0TZ7TDHS1";
  ga.type = "text/javascript";
  ga.async = true;
  targetElement.appendChild(ga);
  w.dataLayer = window.dataLayer || [];
  w.gtag = function () {
    window.dataLayer.push(arguments);
  };
  w.gtag("js", new Date());
  w.gtag("config", "G-Z0TZ7TDHS1", {
    custom_map: { dimension1: "siteid" },
  });
  w.gtag("event", "script-call", {
    send_to: "G-Z0TZ7TDHS1",
    siteid: siteId,
  });
  s.onerror = function (msg) {
    w.gtag("event", "ad-block", {
      send_to: "G-Z0TZ7TDHS1",
      siteid: siteId,
    });
  };
})(window, document);
</script>
</head>
<body onload="highlightlink()">

<button onclick="topFunction()" id="myBtn">&#8679; SCROLL TO TOP</button>
<div id="page" style="margin:-8px;background-color:#f5f5f4;"><div id="container"> <div class="header"><table style="width:100%;margin-bottom:5px"> <tr> <td> <div style="clear:both;float:left;width:230px;margin-top:15px;margin-left:20px"> <a href="index.html"><img src="https://static.javatpoint.com/images/logo/jtp_logo.png" alt="Javatpoint Logo" /></a> </div> <div style="float:left;width:60%;"><script> (function() { var cx = '005383125436438536544:y1edweedxwi'; var gcse = document.createElement('script'); gcse.type = 'text/javascript'; gcse.async = true; gcse.src = 'https://cse.google.com/cse.js?cx=' + cx; var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(gcse, s); })();</script><gcse:search></gcse:search> </div> </td> </tr></table> </div>
<div class="headermobile">
<div style="margin-top:10px;padding:0px;text-align:left;">
<span style="float:left"><input type="image" src="images/menuhome64.png" alt="Go To Top" onclick="showmenu()" /></span>
<span style="float:left"><a href="index.html"><img src="images/logo/jtp_logo.png" alt="Javatpoint Logo"></a></span>
</div>
<div style="margin:0px;padding:0px;clear:both">
<script>
  (function() {
    var cx = '005383125436438536544:y1edweedxwi';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>

</div>
</div>
<div id="link" style="clear:both;z-index:999"> <div class="ddsmoothmenu">
<ul>
<li><a href="index.html">Home</a></li>
<li><a href="java-tutorial.html">Java</a></li>
<li><a href="keras.html" class="selected">Keras</a></li>
<li><a href="javascript-tutorial.html">JavaScript</a></li>
<li><a href="bootstrap-tutorial.html">Bootstrap</a></li>
<li><a href="c-programming-language-tutorial.html">C</a></li>
<li><a href="html-tutorial.html">HTML</a></li>
<li><a href="xhtml-tutorial.html">XHTML</a></li>
<li><a href="css-tutorial.html">CSS</a></li>
<li><a href="jquery-tutorial.html">jQuery</a></li>
<li><a href="xml-tutorial.html">XML</a></li>
<li><a href="json-tutorial.html">JSON</a></li>
<li><a href="comment.html">Comment</a></li>
<li><a href="forum.html">Forum</a></li>
<li><a href="training.html">Training</a></li>
</ul>
<br style="clear: left" />
</div></div>
<div class="mobilemenu" style="clear:both">

<ins class="adPushupAds" data-adpControl="hqdgs" data-ver="2" data-siteId="37780" data-ac="PHNjcmlwdCBhc3luYyBzcmM9Ii8vcGFnZWFkMi5nb29nbGVzeW5kaWNhdGlvbi5jb20vcGFnZWFkL2pzL2Fkc2J5Z29vZ2xlLmpzIj48L3NjcmlwdD4KPCEtLSBDbV8zMDB4MjUwX01vYl8xNC85IC0tPgo8aW5zIGNsYXNzPSJhZHNieWdvb2dsZSIKICAgICBzdHlsZT0iZGlzcGxheTppbmxpbmUtYmxvY2s7d2lkdGg6MzAwcHg7aGVpZ2h0OjI1MHB4IgogICAgIGRhdGEtYWQtY2xpZW50PSJjYS1wdWItNDY5OTg1ODU0OTAyMzM4MiIKICAgICBkYXRhLWFkLXNsb3Q9IjcwMTQyNzI1MTkiPjwvaW5zPgo8c2NyaXB0PgooYWRzYnlnb29nbGUgPSB3aW5kb3cuYWRzYnlnb29nbGUgfHwgW10pLnB1c2goe30pOwo8L3NjcmlwdD4="></ins><script data-cfasync="false" type="text/javascript">(function (w, d) { for (var i = 0, j = d.getElementsByTagName("ins"), k = j[i]; i < j.length; k = j[++i]){ if(k.className == "adPushupAds" && k.getAttribute("data-push") != "1") { ((w.adpushup = w.adpushup || {}).control = (w.adpushup.control || [])).push(k); k.setAttribute("data-push", "1");} } })(window, document);</script>
</div>
<div id="menu">
<div class="leftmenu2">
<h2 class="spanh2"><span class="spanh2">Keras Tutorial</span></h2>
</div>
<div class="leftmenu">
<a href="keras.html">Keras Tutorial</a>
<a href="https://www.javatpoint.com/installation-of-keras-library-in-anaconda">Installation of Keras library in Anaconda</a>
<a href="keras-backends.html">Keras Backends</a>
<a href="keras-models.html">Keras Models</a>
<a href="keras-layers.html">Keras layers</a>
</div>
<div class="leftmenu2">
<h2 class="spanh2"><span class="spanh2">Keras Models</span></h2>
</div>
<div class="leftmenu">
<a href="keras-the-model-class.html">Keras Model class</a>
<a href="keras-sequential-class.html">Keras Sequential class</a>
</div>
<div class="leftmenu2">
<h2 class="spanh2"><span class="spanh2">Keras Layers</span></h2>
</div>
<div class="leftmenu">
<a href="keras-core-layers.html">Keras Core Layers</a>
<a href="keras-convolutional-layers.html">Convolutional Layer</a>
<a href="pooling-layers.html">Pooling Layers</a>
<a href="keras-locally-connected-layers.html">Locally-Connected layers</a>
<a href="keras-recurrent-layers.html">Recurrent Layers</a>
<a href="keras-embedding.html">Embedding Layers</a>
<a href="keras-merge-layers.html">Keras Merge Layers</a>
</div>
<div class="leftmenu2">
<h2 class="spanh2"><span class="spanh2">Deep Learning Library</span></h2>
</div>
<div class="leftmenu">
<a href="deep-learning.html">Deep Learning</a>
<a href="https://www.javatpoint.com/keras-artificial-neural-networks">Artificial Neural Network</a>
<a href="keras-convolutional-neural-network.html">Convolutional Neural Network</a>
<a href="keras-recurrent-neural-networks.html">Recurrent Neural Network</a>
<a href="keras-kohonen-self-organizing-maps.html">Self-Organizing Maps</a>
<a href="keras-mega-case-study.html">Mega Case Study</a>
<a href="keras-restricted-boltzmann-machine.html">Restricted Boltzmann Machine</a>
</div>
<img src="wh.jpg" alt="JavaTpoint" />
<br />
<div id="leftad" style="margin-left:20px">

<div id="17c09743-0b89-427c-ba64-e09f6a1745a2" class="_ap_apex_ad">
<script>
		var adpushup = window.adpushup = window.adpushup || {};
		adpushup.que = adpushup.que || [];
		adpushup.que.push(function() {
			adpushup.triggerAd("17c09743-0b89-427c-ba64-e09f6a1745a2");
		});
	</script>
</div>
</div>
</div>
<div class="onlycontent">

<div class="onlycontentad">
<div id="9bbcb75d-b5e2-40e1-a811-e7680d1f59a4" class="_ap_apex_ad">
<script>
		var adpushup = window.adpushup = window.adpushup || {};
		adpushup.que = adpushup.que || [];
		adpushup.que.push(function() {
			adpushup.triggerAd("9bbcb75d-b5e2-40e1-a811-e7680d1f59a4");
		});
	</script>
</div>
</div>
<div class="onlycontentinner">
<div id="city">
<table>
<tr><td>
<div id="bottomnextup">
<a class="next" href="keras-kohonen-self-organizing-maps.html">next &rarr;</a>
<a class="next" href="keras-convolutional-neural-network.html">&larr; prev</a>
</div>
<h1 class="h1">Recurrent Neural Networks</h1>
<h2 class="h2">Why not Feedforward Networks?</h2>
<p>Feedforward networks are used to classify images. Let us understand the concept of a feedforward network with an example given below in which we trained our network for classifying various images of animals. If we feed an image of a cat, it will identify that image and provide a relevant label to that particular image. Similarly, if you feed an image of a dog, it will provide a relevant label to that image a particular image as well.</p>
<p>Consider the following diagram:</p>
<img src="https://static.javatpoint.com/tutorial/keras/images/recurrent-neural-networks.png" alt="Recurrent Neural Networks" />
<p>And if you notice the new output that we have got is classifying, a dog has no relation to the previous output that is of a cat, or you can say that the output at the time '<strong>t</strong>' is independent of output at a time '<strong>t-1</strong>'. It can be clearly seen that there is no relation between the new output and the previous output. So, we can say that in feedforward networks, the outputs are independent of each other.</p>
<p>There are a few scenarios where we will actually need the previous output to get the new output. Let us discuss one such scenario where we will necessitate using the output that has been previously obtained.</p>
<img src="https://static.javatpoint.com/tutorial/keras/images/recurrent-neural-networks2.png" alt="Recurrent Neural Networks" />
<p>Now, what happens when you read a book. You will understand that book only on the understanding of the previous words. So, if we use a feedforward network and try to predict the next word in the sentence, then in such a case, we will not be able to do that because our output will actually depend on previous outputs. But in the feedforward network, the new output is independent of the previous outputs, i.e., output at '<strong>t+1</strong>' has no relation with the output at '<strong>t-2</strong>', '<strong>t-1</strong>', and '<strong>t</strong>.' Therefore, it can be concluded that we cannot use feedforward networks for predicting the next word in the sentence. Similarly, many other examples can also be taken where we need the previous output or some information from the previous output, so as to infer the new output.</p>
<h3 class="h3">How to overcome this challenge?</h3>
<p>Consider the following diagram:</p>
<img src="https://static.javatpoint.com/tutorial/keras/images/recurrent-neural-networks3.jpg" alt="Recurrent Neural Networks" />
<p>We have input at '<strong>t-1</strong>', which we will feed to the network, and then we will get the output at '<strong>t-1</strong>'. Then at the next timestamp that is at a time '<strong>t</strong>', we have an input at a time '<strong>t</strong>', which will be again given to the network along with the information from the previous timestamp, i.e., '<strong>t-1</strong>' and that will further help us to get the output at '<strong>t</strong>'. Similarly, at the output for '<strong>t+1</strong>', we have two inputs; one is the new input that we give, and the other is the information coming from the previous timestamps, i.e., '<strong>t</strong>' in order to get the output at a time '<strong>t+1</strong>'. In the same way, it will go on further like this. Here we have embodied in a more generalized way to represent it. There is a loop where the information from the previous timestamp is flowing, and this is how we can solve a particular challenge.</p>
<h2 class="h2">What are Recurrent Neural Networks?</h2>
<p>"Recurrent Networks are one such kind of artificial neural network that are mainly intended to identify patterns in data sequences, such as text, genomes, handwriting, the spoken word, numerical times series data emanating from sensors, stock markets, and government agencies".</p>
<p>In order to understand the concept of Recurrent Neural Networks, let's consider the following analogy.</p>
<img src="https://static.javatpoint.com/tutorial/keras/images/recurrent-neural-networks4.png" alt="Recurrent Neural Networks" />
<p>Suppose that your gym trainer has made a schedule for you. The exercises are repeated every third day. The above image includes the order of your exercises; on your very first day, you will be doing shoulders, the second day you will be doing biceps, the third day you will be doing cardio, and all these exercises are repeated in proper order.</p>
<p>Let's see what happens if we use a feedforward network for predicting the exercises today.</p>
<img src="https://static.javatpoint.com/tutorial/keras/images/recurrent-neural-networks5.png" alt="Recurrent Neural Networks" />
<p>We have provided in the input such as day of the week, the month of the year, and health status. Also, we need to train our model or the network on the basis of the exercises that we have done in the past. After that, there will be a complex voting procedure involved, which will predict the exercises for us, and that procedure won't be that accurate. In that case, whatever output we will get would be as accurate as we want it to be. Now, what if the inputs get changed, and we make the inputs as the exercises that we have done the previous day.</p>
<img src="https://static.javatpoint.com/tutorial/keras/images/recurrent-neural-networks6.png" alt="Recurrent Neural Networks" />
<p>Therefore, if shoulders were done yesterday, then definitely today will be biceps day. Similarly, if biceps were done yesterday, then today will be the cardio day, and if yesterday was the cardio day, then today, we will need to undergo shoulder.</p>
<p>Now there can be one such scenario, where you are unable to go to the gym for one day due to some personal reasons, then it that case, we will go one timestamp back and will feed in what exercise happened day before yesterday as shown below.</p>
<img src="https://static.javatpoint.com/tutorial/keras/images/recurrent-neural-networks7.png" alt="Recurrent Neural Networks" />
<p>So, if the exercise that happened the day before yesterday was the shoulder, then yesterday there were biceps exercises. Similarly, if biceps happened the day before yesterday, then yesterday would have been cardio exercises, and if cardio would have happened the day before yesterday, then yesterday would have been shoulder exercises. And this prediction for the exercises that happened yesterday will be fed back to our network so that these predictions can be used as inputs in order to predict what exercise will happen today. Similarly, if you have missed your gym say for two days, three days or even one week, you will actually need to roll back, which means that you will need to go to the last day when you went to the gym, you need to figure out what exercises you did on that day and then only you will be getting the relevant output as to what exercises will happen today.</p>
<p>Next, we will convert all these things into a vector, which is nothing but a list of numbers.</p>
<img src="https://static.javatpoint.com/tutorial/keras/images/recurrent-neural-networks8.jpg" alt="Recurrent Neural Networks" />
<p>So, there is new information along with the information which we got from the prediction at the previous timestamp because we need all of these in order to get the prediction at a time '<strong>t</strong>'. Imagine that you did shoulder exercises yesterday, then, in that case, the prediction will be biceps exercise because if the shoulder was done yesterday, then today it will definitely be biceps and output will be <strong>0, 1</strong>, and <strong>0</strong>, which is actually the work of our vectors.</p>
<p>Let's understand the math behind the <a href="recurrent-neural-network-in-tensorflow.html">Recurrent Neural Network</a> by simply having a look at the image given below.</p>
<img src="https://static.javatpoint.com/tutorial/keras/images/recurrent-neural-networks9.png" alt="Recurrent Neural Networks" />
<p>Assume that '<strong>w</strong>' is the weight matrix, and '<strong>b</strong>' is the bias. Consider at time <strong>t=0</strong>, our input is '<strong>x<sub>o</sub></strong>', and we need to figure out what exactly is the '<strong>h<sub>o</sub></strong>'. We will substitute <strong>t=0</strong> in the equation, as shown in the image, so as to procure the function <strong>h<sup>t</sup></strong> value.</p>
<p>After that, we will find out the value of '<strong>y<sub>o</sub></strong>' by using values that were previously calculated when we applied it to the new formula.</p>
<p>The same process is repeated again and again through all the timestamps within the model so as to train it. So, this how a Recurrent Neural Networks works.</p>
<h3 class="h3">Training a Recurrent Neural Network</h3>
<p>A recurrent neural network uses a backpropagation algorithm for training, but backpropagation happens for every timestamp, which is why it is commonly called as backpropagation through time. With backpropagations, there are certain issues, namely vanishing and exploding gradients, that we will see one by one.</p>
<p><strong>Vanishing Gradient</strong></p>
<p>Consider the following diagram:</p>
<img src="https://static.javatpoint.com/tutorial/keras/images/recurrent-neural-networks10.png" alt="Recurrent Neural Networks" />
<p>In vanishing gradient when we use backpropagation, we tend to calculate the error which is nothing but the actual output that we already know subtracted by the model output that we got through the model and the square of that, so we can figure out the error, and with the help of that error, we tend to find out the change in error with respect to change in weight or any variable, which is here called as weight.</p>
<p>So, the change of error with respect to change in weight multiplied by learning rate will give us the change in rate. And then we will add this change in weight to the old weight to get a new weight. Basically, here we are trying to reduce the error, and for that, we need to figure out what will be the change in error if variables get changed, by which we can get the change in the variable and add it to our old variable to get the new variable.</p>
<p>Now over here what can happen if the value <strong>de&frasl;dw</strong>, i.e., gradient or simply we can say the rate of change of error with respect to weight variable becomes very smaller than 1 and if we multiply that with the learning rate, which is the definitely smaller than 1, then, in that case, we will get the change in weight, which is negligible.</p>
<p>Consider a scenario where you need to predict the next word in the sentence, and your sentence is something like "I have been to USA". Then are a lot of words after that few people speak, and then you need to predict what comes after speak. Now, if you need to do that, then you will have to go back and understand the context of what it is talking about, which is nothing but our long-term dependencies. During the long-term dependencies, <strong>de&frasl;dw</strong> becomes very small, and then when you multiply it with <strong><em>n</em></strong>, which is again smaller than <strong>1</strong>, you get <strong>&Delta;w</strong>, which will be very small or simply negligible. So, the new weight that you will get here will be almost equal to your old weight, such that the weight will not get updated further. Also, there will be no learning here, which is nothing but the problem of vanishing gradient.</p>
<p>Similarly, if we talk about the exploding gradient, it is actually opposite to that of the vanishing gradient. Consider the below diagram to have a better understanding of it.</p>
<img src="https://static.javatpoint.com/tutorial/keras/images/recurrent-neural-networks11.png" alt="Recurrent Neural Networks" />
<p>If <strong>de&frasl;dw</strong> becomes very large or greater than <strong>1</strong> and we have some long-term dependencies, then, in that case, <strong>de&frasl;dw</strong> will keep on increasing, and <strong>&Delta;w</strong> will become very large that will make the new weight different than that of the old weights. So, these were the two problems with backpropagation, and now we will see how to solve these problems.</p>
<h3 class="h3">How to overcome these challenges?</h3>
<table class="alt">
<tr>
<th>Exploding Gradients</th>
<th>Vanishing Gradients</th>
</tr>
<tr>
<td>The exploding gradient can be solved with the help of <strong>Truncated BTT</strong> backpropagation through time, so instead of staring backpropagation as the last timestamp, we can choose some smaller timestamps like 10.</td>
<td>For vanishing gradient, we can make use of <strong>the ReLU activation function</strong> that results in the output while calculating the gradient.</td>
</tr>
<tr>
<td>Also, we can <strong>clip the gradients at the threshold</strong>. So, there can be a threshold value where we can clip the gradients.</td>
<td>We can also integrate <strong>RMSprop</strong> for clipping the gradient when it goes higher than the threshold.</td>
</tr>
<tr>
<td>We also adjust the learning rate as well with the <strong>RMSprop</strong>.</td>
<td>Similarly, <strong>LSTM</strong> and <strong>GRUs</strong> can also be incorporated that are specially designed network architectures as these are made to combat this problem.</td>
</tr>
</table>
<h2 class="h2">Long Short-Term Memory Networks (LSTMs)</h2>
<p>Long Short-Term Memory networks, which are commonly known as "LSTMs," are a special kind of Recurrent Neural Networks that are capable enough of learning long-term dependencies.</p>
<h3 class="h3">What are long-term dependencies?</h3>
<p>It has happened many times that we only require recent data in order to perform questions in a model. But at the same time, we may also need data that has been previously obtained.</p>
<p>Consider the following example to have a better understanding of it.</p>
<p>Let's suppose there is a language model, which is trying to predict the next word on the basis of the previous ones. Assume that we are trying to predict the last word in the sentence say, <em>"The car runs on the road".</em></p>
<p>Here the context is quite simple because the last word always ends up being a road. By incorporating Recurrent Neural Networks, the gap present between the former information and the existing necessities can be easily associated.</p>
<p>That is the reason why Vanishing and Exploding Gradient problems do not exist, followed by making this LSTM networks to easily handle long-term dependencies.</p>
<p>LSTM encompasses a layer of neural network in the form of a chain. In a standard recurrent neural network, the repeating module consists of one single function as shown in the image given below:</p>
<img src="https://static.javatpoint.com/tutorial/keras/images/recurrent-neural-networks12.png" alt="Recurrent Neural Networks" />
<p>From the image given above, it can be seen that there is a <strong>tanh</strong> function in the layer, which is called as <strong>squashing function</strong>. So, what is a squashing function?</p>
<p>The squashing function is mainly used in between the range of <strong>-1</strong> to <strong>+1</strong> so that the values can be manipulated on the basis of inputs.</p>
<p>Now, let us consider the structure of an LSTM network:</p>
<img src="https://static.javatpoint.com/tutorial/keras/images/recurrent-neural-networks13.png" alt="Recurrent Neural Networks" />
<p>Here all those functions that are present in the layers have their own structures as and when it comes to LSTM networks. The cell state is represented by the horizontal line, acts as a conveyer belt that carries the data linearly crossways the data channel.</p>
<p>Let us consider a step-by-step approach to understand LSTM networks better.</p>
<p><strong>Step 1:</strong></p>
<p>The first step in the LSTM is to identify that information which is not required and will be thrown away from the cell state. This decision is made by a <strong>sigmoid layer</strong>, which called the <strong>forget gate layer</strong>.</p>
<img src="https://static.javatpoint.com/tutorial/keras/images/recurrent-neural-networks14.png" alt="Recurrent Neural Networks" />
<p>The highlighted layer in the above is the sigmoid layer which is previously mentioned.</p>
<p>The calculation is done by considering the new input, and the previous timestamp is, which eventually leads to the output of a number between <strong>0</strong> and <strong>1</strong> for each number in that cell state.</p>
<p>As a typical binary, <strong>1</strong> represents to <strong>keep</strong> the cell state while <strong>0</strong> represents to <strong>trash</strong> it.</p>
<div class="formula">
<p><strong>f<sub>t</sub> = &sigma;(w<sub>f </sub>[h<sub>t-1</sub>, x<sub>t</sub>] + b<sub>f</sub>)</strong></p>
<p>where, w<sub>f</sub> = Weight</p>
<p>h<sub>t-1</sub> = Output from previous timestamp</p>
<p>x<sub>t</sub> = New input</p>
<p>b<sub>f</sub> = Bias</p>
</div>
<p>Considering a gender classification problem, it necessitates observing the correct gender when we are using the network.</p>
<p><strong>Step 2:</strong></p>
<p>Next, we will decide which information we will store in the cell state. It further consists of the following steps:</p>
<ul class="points">
<li>The <strong>sigmoid layer</strong>, which is also known as the "input gate layer," will make decisions about those values that are needed to be updated.</li>
<li>A vector of new candidate values is created so that they can be added to the state by the <strong>tanh layer</strong>.</li>
</ul>
<img src="https://static.javatpoint.com/tutorial/keras/images/recurrent-neural-networks15.png" alt="Recurrent Neural Networks" />
<p>Then the new input, as well as the preceding timestamp's input, will get passed through a sigmoid function that will result in the value <strong>i(t)</strong>, which will then be multiplied by <strong>c(t)</strong> followed by adding it to the <strong>cell state</strong>.</p>
<p>In the next step, we will combine both of them so as to update the state.</p>
<p><strong>Step 3:</strong></p>
<p>In the 3<sup>rd</sup> step, the previous cell state <strong>Ct-1</strong> will get updated into the new cell state <strong>Ct</strong>.</p>
<p>And for that, we will need to multiply the old state <strong>(Ct-1)</strong> by <strong>f(t)</strong>, keeping the things aside that we thought that we earlier decided to leave.</p>
<img src="https://static.javatpoint.com/tutorial/keras/images/recurrent-neural-networks16.png" alt="Recurrent Neural Networks" />
<p>Next, we will add <strong>i_t* c&tilde;_t</strong>, which is the <strong>new candidate</strong> values. It has been actually scaled by how much we wanted to update each state value.</p>
<p>In the second step, we decided to do make use of the data, which is only required at that stage. However, in the third step, we have executed it.</p>
<p>Step 4:</p>
<p>In the 4<sup>th</sup> step, we will run the <strong>sigmoid layer</strong> that will decide for those parts of the cell state that will result in the output.</p>
<p>Next, we will put the cell state through <strong>tanh</strong>, which means we will be pushing the values in between the range of <strong>-1</strong> and <strong>1</strong>.</p>
<p>And then, further, we will multiply it with the <strong>sigmoid gate's output</strong> so that only the decided parts results in the output.</p>
<img src="https://static.javatpoint.com/tutorial/keras/images/recurrent-neural-networks17.png" alt="Recurrent Neural Networks" />
<p>In this step, we will be doing some calculations that will result in the output.</p>
<p>However, the output consists of only the outputs there were decided to be carry forwarded in the previous steps and not all the outputs at once.</p>
<p>A Quick Recap:</p>
<ul class="points">
<li>At first, we find out what is to be dropped.</li>
<li>Then in the second step, it included newly added inputs to the network.</li>
<li>In the third step, the earlier obtained inputs get combined in order to produce the new cell states.</li>
<li>Lastly, we arrived at the output as per requirement.</li>
</ul>
<h2 class="h2">Building an RNN</h2>
<p>In this third part of deep learning, which is the Recurrent Neural Networks, we are going to tackle a very challenging problem in this part; we are going to predict the <strong>stock price of Google</strong>. There is indeed a Brownian Motion that states the future variations of the stock price are independent of the past. So, we will try to predict the upward and downward trends that exist in Google stock price. And to do so, we will implement the LSTM model.</p>
<p>We will make an LSTM that will try to capture the downward and the upward trend of the Google stock price because LSTM is the only powerful model that can do this as it performs way better than the traditional models. Apart from this, we are not going to perform a simple LSTM model. It's going to be super robust with some high-dimensionality, several layers as well as it is going to be a stacked LSTM, and then we will add some dropout regularization to avoid overfitting. Also, we will use the most powerful optimizer that we have in the Keras library.</p>
<p>In order to approach this problem, we will train our LSTM model on five years of the Google stock price, which is from the beginning of 2012 to the end of 2016 and then based on this training as well as on the identified correlations or captured by the LSTM of the Google stock price, we will try to predict the first month of 2017. We will try to predict January 2017, and again we are not going to predict exactly the stock price, but we are trying to predict the upward and downward trend of the Google stock price.</p>
<p>Here we are using the Spyder IDE for the implementation of our RNN model. So, we will start with importing the essential libraries in the 1<sup>st</sup> part, i.e., data preprocessing followed by importing the training set, and then we will build the RNN. Lastly, we will make predictions and visualize the results.</p>
<h3 class="h3">Part1: Data Preprocessing</h3>
<p>We will start with, as usual, importing the essential libraries that we will use to implement the RNN just the same way as we did in the earlier model. So, we have <a href="numpy-tutorial.html"><strong>NumPy</strong></a> that will allow us to make some arrays, which are the only allowed input of the Neural Networks as opposed to the DataFrames. Then we have <strong>matplotlib.pyplot,</strong> which we will use to visualize the results in the end. Lastly, the <strong>pandas</strong> to be able to import the datasets and manage them easily.</p>
<div class="codeblock"><textarea name="code" class="java">
# Importing the libraries
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
</textarea></div>
<p><strong>Output:</strong></p>
<img src="https://static.javatpoint.com/tutorial/keras/images/recurrent-neural-networks18.png" alt="Recurrent Neural Networks" />
<p>It can be seen in the above image that we have successfully imported these libraries.</p>
<p>Next, we will import the training set and not the whole set as opposed to part1 and part2 because we want to highlight that we are going to train our RNN on only the training set.</p>
<p>The RNN will have no idea of what is going on in the test set. It will have no acquaintance with the test set during its training. It's like the test set doesn't exist for the RNN. But once the training is done, we will then introduce the test set to the RNN, so that it can make some predictions of the future stock price in January 2017. This is why we are only importing the training set now, and after the training is done, we will import the test set.</p>
<p>So, to import the training set, we will first need to import the data as DataFrames, which we will import with pandas using the <strong>read_csv</strong> function. But then remember we have to not only select the right column that we need, which is the open Google stock price, but also, we need to make it a NumPy array because only the NumPy array can be the inputs of neural network in Keras.</p>
<div class="codeblock"><textarea name="code" class="java">
# Importing the training set
dataset_train = pd.read_csv('Google_Stock_Price_Train.csv')
training_set = dataset_train.iloc[:, 1:2].values
</textarea></div>
<p><strong>Output:</strong></p>
<img src="https://static.javatpoint.com/tutorial/keras/images/recurrent-neural-networks19.png" alt="Recurrent Neural Networks" />
<p>From the above image, we can see that <strong>dataset_train</strong> is the <strong>DataFrame</strong> and <strong>training_set</strong> is the <a href="numpy-array.html"><strong>NumPy array</strong></a> of 1258 lines corresponding to 1258 stock prices in between 2012 and 2016, and one column, which is the open Google stock price. We can open them by clicking on the <strong>dataset_train</strong> and <strong>training_set</strong> one by one.</p>
<img src="https://static.javatpoint.com/tutorial/keras/images/recurrent-neural-networks20.png" alt="Recurrent Neural Networks" />
<p>Now we can precisely check from the above image that the open Google stock price in training set with the same number of lines, i.e., the same number of stock prices. So, we have a NumPy array of one column but not the vector.</p>
<p>After this, we will apply the feature scaling to our data to optimize the training process, and feature scaling can be done in two different ways, i.e., <strong>standardization</strong> and <strong>normalization</strong>. In standardization, we subtract the observation by the mean of all observations in one same column and then divide it by the standard deviation. However, in normalization, we subtract the observation by the minimum of all observations, i.e., the minimum stock prices, and then we divide it by the maximum of all the stock prices minus the minimum of all the stock prices.</p>
<p>So, this time is more relevant to use <strong>normalization</strong> because whenever we build an RNN and especially if there is a <strong>sigmoid</strong> function as the activation function in the output layer of the recurrent neural network, it is recommended to apply normalization. Therefore, we will apply normalization, and to do this, we will import the min-max k-load class from the preprocessing module of the scikit learn library, and then from this preprocessing module, we will import the <strong>MinMaxScaler</strong> class.</p>
<p>Now from this class, we will create an object of the same class, which we will call as <strong>sc</strong> for scale. And sc will be the object of <strong>MinMaxScaler</strong> class inside of which we will pass the default argument, i.e., <strong>feature_range</strong>. Here we have made <strong>feature_range</strong> equals to <strong>(0, 1)</strong> because if we look at the case of normalization, we will see that all the new scaled stock processes will be between 0 and 1, which is exactly what we want.</p>
<p>Next, we will apply the <strong>sc</strong> object on our data to effectively apply the normalization. For this we will introduce a new variable which will be the scaled training set, so we will name it as <strong>training_set_scaled,</strong> and in order to get the normalized training set, we will simply take the <strong>sc</strong> object followed by applying <strong>fit_transform</strong> method, which is the method of <strong>MinMaxScaler</strong> class so as to fit the <strong>sc</strong> object to the <strong>training_set</strong> that we will input as an argument and then scale it. Basically, <strong>fit</strong> means that it is just going to get the min of the data, i.e., the minimum stock price and the maximum stock price to be able to the normalization formula. And then, with the <strong>transform</strong> method, it will compute for each of the stock prices of the training set, the scaled stock prices according to the formula.</p>
<div class="codeblock"><textarea name="code" class="java">
# Feature Scaling
from sklearn.preprocessing import MinMaxScaler
sc = MinMaxScaler(feature_range = (0, 1))
training_set_scaled = sc.fit_transform(training_set)
</textarea></div>
<p><strong>Output:</strong></p>
<img src="https://static.javatpoint.com/tutorial/keras/images/recurrent-neural-networks21.png" alt="Recurrent Neural Networks" />
<p>After executing the above lines of code, we will obtain our <strong>training_set_scaled</strong>, as shown in the above image. And if we have a look at it, we can see that indeed all the stock prices are now normalized between <strong>0</strong> and <strong>1</strong>.</p>
<p>In the next step, we will create a specific data structure, which is the most important step of data preprocessing for Recurrent Neural Networks. Basically, we are going to create a data structure specifying what the RNN will need to remember when predicting the next stock price, which is actually called the number of timesteps and it is very important to have a right number of timesteps because the wrong number of timesteps could lead to overfitting or baseless predictions. </p>
<p>So, we will be creating 60 timesteps and 1 output, such that 60 timesteps mean that at each time T, the RNN is going to look back at 60 stock prices before time T, i.e., the stock prices between 60 days before time T and time T, and based on the trends, it is capturing during these 60 previous timesteps, it will try to predict the next output. So, 60 timesteps of the past information from which our RNN is going to learn and understand some correlations or some trends, and based on its understanding, it's going to try to predict the next output, i.e., the stock price at time t+1. Also, 60 timesteps refer to 60 previous financial days, and since there are 20 financial days in one month, so 60 timesteps correspond to three months, which means that each day we are going to look at the three previous months to try to predict the stock price the next day. </p>
<p>So, the first thing that we need to create two separate entities; the first entity that we will create is <strong>X_train</strong>, which will be the inputs of the neural network, and the second will be <strong>y_train</strong> that will contain the output. Basically, for each observation, or we can say for each financial day, X_train will contain 60 previous stock prices before that financial day, and y_train contain the stock price of the next financial day. We will start initializing these two separate entities, i.e., X_train and y_train, as an empty list.</p>
<p>The next step is for a loop because we will populate these entities with <strong>60 previous stock prices</strong> in <strong>X_train</strong> and the <strong>next stock price</strong> in the <strong>y_train</strong>. So, we will start the loop with 60 because then for each <strong>i</strong> which is the index of the stock price observation, we will get the range from <strong>i-60</strong> to <strong>i</strong>, which exactly contains the 60 previous stock prices before the stock price at time <strong>t</strong>. Therefore, we will start the range at <strong>60</strong> because then the upper bound is much easier to find, which is off course, the last index of our observation, i.e., <strong>1258</strong>. Inside the for loop, we will start with <strong>X_train</strong>, which is presently an empty list, so we will append some elements into the X_train by using the <strong>append</strong> function. We will append the 60 previous stock prices before the stock price at index <strong>i</strong>, i.e., the <strong>stock price</strong> at the <strong>i<sup>th</sup></strong> financial day. So, in order to get them, we will get our <strong>training_set_scaled</strong>, and in this, we will take 60 previous stock prices before the i<sup>th </sup>financial day, which is the range of the indexes from <strong>i-60</strong> to <strong>i</strong>. Since we already selected correct lines for X_train, but we still need to specify the column and as we have one column in the scaled training set, i.e., the column of index 0, which is exactly what we need to add here.</p>
<p>Now, in the same way, we will do for <strong>y_train</strong>, which will be much easier because we simply need to input the stock price at time t+1, and therefore we just need to do the same here. The stock price at t+1 is, of course, going to be taken from <strong>training_set_scaled</strong> and inside it we will take same indexes for columns, i.e., 0, but for the observation line, we will take the <strong>i<sup>th</sup></strong> index because if we consider the same example when we have <strong>i</strong> equal to 60, then X_train will contain all the stock prices from 0 to 59 as the upper bound was excluded, but what we want to predict is actually based on the 60 previous stock prices is the stock price at time <strong>t+1</strong>, which is 60 and that is the reason we input <strong>i</strong> here instead of i+1.</p>
<p>So, now we have the 60 previous stock prices in X_train and the stock price at time t+1 in y_train. Since X_trian and y_train are lists, so we again need to make them NumPy arrays for them to be accepted by our future Recurrent Neural Network.</p>
<div class="codeblock"><textarea name="code" class="java">
# Creating a data structure with 60 timesteps and 1 output
X_train = []
y_train = []
for i in range(60, 1258):
    X_train.append(training_set_scaled[i-60:i, 0])
    y_train.append(training_set_scaled[i, 0])
X_train, y_train = np.array(X_train), np.array(y_train)
</textarea></div>
<p><strong>Output:</strong></p>
<p>Once we execute the above give code, we can have a look at X_train and y_train by clicking them individually on the from the variable explorer pane.</p>
<p><strong>X_train</strong></p>
<img src="https://static.javatpoint.com/tutorial/keras/images/recurrent-neural-networks22.png" alt="Recurrent Neural Networks" />
<p>As we can see from the above image, <strong>X_train</strong> is a <strong>special data structure</strong>. Here the first line of observation corresponds to time <strong>t</strong> equals <strong>60</strong>, which means it corresponds to the stock price at the <strong>60<sup>th</sup></strong> financial day of our training dataset. And all those values are the previous 60 stock prices before that stock price at the <strong>60<sup>th</sup></strong> financial day, which means that there are 59 values here, such that if we have a look at the first line, i.e., observation of the 1<sup>st </sup>index, corresponds to the stock price at the 61<sup>st</sup> financial day of the training set. All these stock prices are the preview stock prices before that 61<sup>st</sup> stock price of our training dataset.</p>
<p><strong>y_train</strong></p>
<img src="https://static.javatpoint.com/tutorial/keras/images/recurrent-neural-networks23.png" alt="Recurrent Neural Networks" />
<p>Now if we have a look at <strong>y_train</strong>, we can see it very simple to visualize as it contains the stock price at time <strong>t+1</strong> and if compare both the X_train and y_train, we will see that <strong>X_train</strong> contains all the 60 previous stock prices <strong>t = 60</strong>, and based on the stock prices of each individual line, we will train our Recurrent Neural Network to predict the stock price at time <strong>t+1</strong>.</p>
<p>After this, we will perform our last step of data pre-processing, which is reshaping the data, or in simple words, we can say we will add some more dimensionality to the previous data structure. And the dimensionality that we are going to add is the '<strong>unit</strong>', i.e., the number of predictors that we can use to predict the Google stock prices at time t+1.</p>
<p>So, in the scope of this financial engineering problem where we are trying to predict the trend of the Google stock price, these predictors are <strong>indicators</strong>. Presently we are having one indicator, which is the Google Stock Prices and so we are taking 60 previous Google stock prices to predict the next one. But with the help of a new dimension that we are going to add to our data structure, we will be able to add some more indicators that will help in predicting even better the upward and downward trends of the Google Stock Price.</p>
<p>We will use the reshape function to add a dimension in the NumPy array. We just need to do this for X_train because it actually contains the inputs of the neural network. So, we create a new dimensionality of the new data structure because simply that is exactly what is expected by the future recurrent neural network that we are going to build in our 2<sup>nd</sup> part.</p>
<p>So, we will start by updating the <strong>X_train</strong> by using the <strong>reshape</strong> function, which is taken from the <strong>NumPy</strong> library because we are reshaping a NumPy array. Inside the reshape function, we will input the following arguments:</p>
<ul class="points">
<li>The first argument is the NumPy array, i.e., <strong>X_train</strong> that we want to reshape as we want to add the new dimension corresponding to the predictor, which is the <strong>indicato</strong>r in our case.</li>
<li>And in the second argument of the reshape function, we need to specify this new structure, i.e., the new shape we want for our X_train to have. So, we will input the structure in parenthesis as we will include three elements in it because, at present, our data structure has two dimensions, i.e., X_train comprise of two dimensions, which is the NumPy array of 1198 lines and 60 columns. Therefore now we will add a new dimension due to which there will be like 3D shape encompassing a new dimension that corresponds to the indicator, and we have to visualize it.<br>
The first dimension that we will add is the <strong>X_train.shape[0]</strong> as it will help us to get the exact number of lines of X_train and then to get the number of timesteps, which is exactly the number of columns, we will get it with the help of <strong>X_train.shape[1]</strong> as it gives the number of columns that further corresponds to the number of timesteps. And the last dimension will be <strong>1</strong> as we have only a single indicator, but they can be changed in case there are several indicators.</li>
</ul>
<div class="codeblock"><textarea name="code" class="java">
# Reshaping
X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))
</textarea></div>
<p><strong>Output:</strong></p>
<img src="https://static.javatpoint.com/tutorial/keras/images/recurrent-neural-networks24.png" alt="Recurrent Neural Networks" />
<p>By executing the above line of code, we will see that we have our new X_train, and if we have a look at the above image, we will see that it has the three dimensions, the exact same ones as we just mentioned. Further to have a look at X_train, we will need to again click on it from the Variable explorer pane, and it will be like something as given below.</p>
<img src="https://static.javatpoint.com/tutorial/keras/images/recurrent-neural-networks25.png" alt="Recurrent Neural Networks" />
<p>From the above image, we can clearly visualize that although it is not in the 3-dimension, so we can see it simply by changing the axis. As we can see in the image, it is in the 1-dimension, the axis is 0. In the same way, we will see the rest of the axis that corresponds to the three dimensions of the structure.</p>
<p>Now that we are done with the data preprocessing, we will now move on to part2, i.e., building the Recurrent Neural Network, where we will build the whole architecture of our stacked LSTM with several LSTM layers.</p>
<h3 class="h3">Part 2 - Building the RNN</h3>
<p>In the second part, we are going to build the whole architecture of the neural network, a robust architecture, because we are not only going to make a simple LSTM but a stacked LSTM with some dropout regularization to prevent overfitting.</p>
<p>So, we will not import the <strong>Sequential</strong> class that will help us in creating the neural network object representing a sequence of layers, but also the <strong>Dense</strong> class to add the output layer. We will also import the <strong>LSTM</strong> class to add the LSTM layers and then the <strong>Dropout</strong> class to add some dropout regularization. This is all that we need to build a powerful RNN.</p>
<div class="codeblock"><textarea name="code" class="java">
# Importing the Keras libraries and packages
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM
from keras.layers import Dropout
</textarea></div>
<p><strong>Output:</strong></p>
<img src="https://static.javatpoint.com/tutorial/keras/images/recurrent-neural-networks26.png" alt="Recurrent Neural Networks" />
<p>Using the <a href="tensorflow.html">TensorFlow</a> backend, all the classes are imported, as shown above.</p>
<p>Next, we will initialize our Recurrent Neural Network as a sequence of layers as opposed to a computational graph. We will use the <strong>Sequential</strong> class from the Keras to introduce the <strong>regressor</strong> as a sequence of layers. Regressor is nothing but an object of the sequential class that represents the exact sequence of the layers.</p>
<p>We are calling it as regressor as opposed to the classifiers in <a href="artificial-neural-network.html">ANN</a> and CNN models because this time, we are predicting a continuous output, or we can say a continuous value, which is the Google stock price at time t+1. So, we can say that we are doing a regression, which is all about predicting continuous value, whereas classification was predicting a category or a class, and since we are predicting a continuous value, this is the reason why we called our Recurrent Neural Network a regressor.</p>
<div class="codeblock"><textarea name="code" class="java">
# Initialising the RNN
regressor = Sequential()
</textarea></div>
<p>After initializing the regressor, we will add different layers to make it a powerful stacked LSTM. So, we will start by adding the first <a href="long-short-term-memory-rnn-in-tensorflow.html">LSTM</a> layer of our Recurrent Neural Network, which was introduced as a sequence of layers and also some dropout regularization so as to avoid overfitting as we don't want while predicting the stock price. We will do this in two steps: we will add the first LSTM layer, and then we will add the dropout regularization.</p>
<p>Let's starts with adding our first LSTM layer, and for that, we will take our <strong>regressor</strong>, which is an object of the <strong>sequential</strong> class. The sequential class contains the <strong>add</strong> method that allows adding some layers of the neural network, and inside the add method, we will input the type of layer that we want to add, i.e., an <strong>LSTM</strong> layer and that is where we use the LSTM class because actually what we are adding in this add method will be an object of the LSTM class. Therefore, we create the LSTM layer by creating an object of the LSTM class, which will take several arguments that are as follows:</p>
<ul class="points">
<li>The first argument is the number of <strong>units</strong>, which is the number of LSTM cells or memory unit, but for simplicity, we call it neurons that we want to have in this LSTM layer. So, we will choose a relevant number.<br>
Even if we want to stack so many layers, we want our model to have high dimensionality. So, indeed we are making the high dimensionality with the help of LSTM layers that we are going to add, but we can even increase its dimensionality by including a large number of neurons in each of the LSTM layers. Since capturing the trends of the stock price is pretty much complex and we need to have this high dimensionality for which we also need to have a large number of neurons in each of the multiples of LSTM layers. Therefore, we will choose <strong>50</strong> neurons for this LSTM layers because if we have chosen too little neurons, then they would not have captured the upward and forward trends, but as we already selected 50 neurons, it will definitely lead to a better result.</li>
<li>Then the second argument is the <strong>return_sequences</strong>, which we have to set it equal to <strong>True</strong> because we are building a stacked LSTM that further contains several LSTM layers and when we add another LSTM layer after creating the first one, then we will need to set the return_sequences argument equals to True.<br>
Once we are done with adding the LSTM layers, such that we will not incorporate more layers, then we will set it to False. But we would not do it because it's a default value of the return_sequences parameter.</li>
<li>Lastly, the third argument is the <strong>input_shape</strong>, which is exactly the shape of the input containing the <strong>X_train</strong> that we created in the last step of the data preprocessing part. It is an input shape in the 3-dimension corresponding to the observation, the timesteps, and the indicators. But in the third argument of the LSTM class, we are not required to add the three dimensions, only the two last ones corresponding to the timesteps and indicators because the first one corresponds to the observations that will be automatically taken into account.<br>
So, we will only specify the <strong>X_train.shape[1]</strong> that corresponds to the timesteps, and <strong>[1]</strong> corresponds to the predictors or indicators.</li>
</ul>
<div class="codeblock"><textarea name="code" class="java">
# Adding the first LSTM layer and some Dropout regularization
regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))
</textarea></div>
<p>After we are done with our first step, now we will take care of the second sub-step of the first step building the architecture of the neural network, i.e., adding some <strong>Dropout regularization</strong> and to do this, we will again take our <strong>regressor</strong> followed by using the <strong>add</strong> method of the sequential class because it will work the same way as for the LSTM. We will start by creating an object of the Dropout class that we already imported to include this dropout regularization.</p>
<p>Therefore, exactly as for LSTM, we need to specify here the name of this class as <strong>Dropout</strong> that will take only one argument, i.e., Dropout rate, which is nothing but the number of neurons that we want to drop or in simple words that we want to ignore in the layer to do this regularization. And the relevant number to use them is to drop 20% of the neurons in the layer, which is exactly that we need to input here. This is the reason why we have added <strong>0.2</strong> as it corresponds to 20%.</p>
<p>So, we will 20% of dropout, i.e., 20% of the neurons of the LSTM layer will be ignored during the training that is during forward and backward propagation happening in each iteration of training. Therefore, since 20% of 50 is 10 neurons, which simply means that 10 neurons will be ignored and dropped out during each iteration of the training. Hence, we are done here with our first LSTM layer, to which we added some dropout regularization.</p>
<div class="codeblock"><textarea name="code" class="java">
regressor.add(Dropout(0.2))
</textarea></div>
<p>Now we will add some extra LSTM layers followed by adding to each of them some dropout regularization. So, we will start by adding our second LSTM layer in the same way as we did in the previous step because we will again use the <strong>add</strong> method from the <strong>sequential</strong> class to add a new LSTM layer and some dropout regularization to our regressor, but we will do some changes to the <strong>input_shape</strong> argument. As in the previous step had to specify the input_shape argument because that was our first LSTM layer and we were required to specify the shape of the input with the last two dimensions corresponding to the timesteps and the predictors, but now things are slightly different, we are just adding our second LSTM layer, which is why we don't need to specify it anymore. Since it is automatically recognized, so will skip adding it to the code when we are adding our next LSTM layers after the first one.</p>
<p>Therefore, we will keep the same number of neurons in the second LSTM layer, i.e., 50 neurons, as well as the same 20% dropout for the regularization due to the fact that it's a relevant choice.</p>
<div class="codeblock"><textarea name="code" class="java">
# Adding a second LSTM layer and some Dropout regularization
regressor.add(LSTM(units = 50, return_sequences = True))
regressor.add(Dropout(0.2))
</textarea></div>
<p>Similarly, in order to add our third LSTM layer, we will exactly copy the above two lines of code that added out the second LSTM layer because adding the third LSTM layer is similar to that of adding the second LSTM layer. We simply need to specify the number of neurons in the LSTM layer, which we are keeping it as 50 neurons so as to have the same goal of having a high dimensionality. We still need to keep return_sequences equal to True because we are adding another LSTM layer after the second LSTM layer, and again, we will keep 20% dropout regularization.</p>
<div class="codeblock"><textarea name="code" class="java">
# Adding a third LSTM layer and some Dropout regularization
regressor.add(LSTM(units = 50, return_sequences = True))
regressor.add(Dropout(0.2))
</textarea></div>
<p>Next, we will add our fourth LSTM layer, but this time things will be slightly changed. We will keep 50 neurons in this fourth LSTM layer because this is not the final layer of the Recurrent Neural layer. But after the fourth layer, we will have our output layer with the output dimension, which will be 1, of course, as we are predicting only one value, the value of the stock price at time t+1. Since we are adding the fourth LSTM layer, which is the last LSTM layer that we are adding, so we will need to set the <strong>return_sequences</strong> equal to <strong>False</strong> because we are not going to return any more sequences. But as we know, the default value for the return_sequences parameter is False, so we will just remove that part as that is what we have to do for the fourth LSTM layer.</p>
<p>We are just adding the LSTM class with 50 units, and the same we will keep the 20% dropout regularization.</p>
<div class="codeblock"><textarea name="code" class="java">
# Adding a fourth LSTM layer and some Dropout regularization
regressor.add(LSTM(units = 50))
regressor.add(Dropout(0.2))
</textarea></div>
<p><strong>Output:</strong></p>
<img src="https://static.javatpoint.com/tutorial/keras/images/recurrent-neural-networks27.png" alt="Recurrent Neural Networks" />
<p>From the above image, we can clearly see that we are successfully done with the LSTM part.</p>
<p>Now we just need to add our final layer, which is the output layer. We will simply take our regressor, which is exactly the same as for the ANN and CNN, followed by adding the <strong>add</strong> method again from sequential class to add the final output layer of our neural network. Since we are not adding the LSTM layer, but actually a classic fully connected layer because the output layer is fully connected to the previous LSTM layer, so in that case to make it a fully connected layer, we will need to use the Dense class exactly as we did for the ANN and CNN.</p>
<p>So, we will specify the <strong>Dense</strong> class in the <strong>add</strong> method, and then we will add one argument which will correspond to the number of neurons that are needed to be in the output layer. Since we are predicting a real value corresponding to the stock price, so the output has only one dimension, which is exactly what we need to input and the argument for that is <strong>units</strong> as it corresponds to the number of neurons in the output layer or the dimension of the output layer, which is <strong>1</strong>.</p>
<div class="codeblock"><textarea name="code" class="java">
# Adding the output layer
regressor.add(Dense(units = 1))
</textarea></div>
<p>Now that we are done with the architecture of our super robust LSTM recurrent neural network, we have two remaining steps of Building the RNN; first one is compiling the RNN with a powerful optimizer and the right loss, which will be the mean squared error because we are doing some regression and the second step is to fit this recurrent neural network to the training set.</p>
<p>Since our training set is composed of X_train, which is the right data structure expected by the neural networks, so we will take <strong>X_train</strong> instead of the training set or the training_set_scaled, and of course, we will need to specify the outputs when fitting the regressor to our training sets because the output contains the ground truth that is the stock price at time t+1. As we are training the RNN on the truth, i.e., the true stock price that is happening at time t+1 after the 60 produced stock prices during the 60 produced financial days, so that's why we also need to include the ground truth, i.e., y_train.</p>
<p>Let's compile the RNN with the right optimizer and the right loss function. So, we will start by taking our <strong>regressor</strong> as we are predicting a continuous value followed by using the <strong>compile</strong> method, which is another method of a sequential class, and inside the compile method, we will input two arguments, i.e., the <strong>optimizer</strong> and the <strong>loss function</strong>.</p>
<p>In general, for recurrent neural network, an RMS prop optimizer is recommended, but in our case of a problem, we will be using <strong>adam</strong> optimizer because it's always a safe choice as it very powerful and always perform some relevant updates of the weights. And the second argument that we will input is the <strong>loss</strong> function. Since we are not dealing with the classification problem, but the regression problem because we have to predict a continuous value, so this time the loss function is <strong>mean_squared_error</strong> due to the fact that the error can be measured by the mean of the squared differences between the predictions and targets, i.e., the real values.</p>
<div class="codeblock"><textarea name="code" class="java">
# Compiling the RNN
regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')
</textarea></div>
<p>After compiling the RNN, we will fit the RNN to the training set that is composed of <strong>X_train</strong> and <strong>y_train</strong>. So, we will again start by taking the <strong>regressor</strong> and not the classifier followed by using the <strong>fit</strong> method, which will not only connect the neural network to the training set but will also execute the training over a certain number of <strong>epochs</strong> that we will choose in the same fit method. Inside the fit method, we will pass four arguments that are the <strong>X_train</strong>, <strong>y_train</strong>, <strong>epochs</strong>, and the <strong>batch_size</strong>. So, our network is going to be trained not on the single observation going to the neural network but on the batches of observation, i.e., the batches of the stock prices going into the neural network.</p>
<p>Instead of updating the weights every stock price being forward propagated into the neural network and then generating an error, which is backpropagated into the neural network, we will do that for every 32 stock prices because we have chosen the <strong>batch_size</strong> of <strong>32</strong>. So, here we are done with building a super robust recurrent neural network as well as we are ready to train it on 5 years of the Google Stock Prices.</p>
<div class="codeblock"><textarea name="code" class="java">
# Fitting the RNN to the Training set
regressor.fit(X_train, y_train, epochs = 100, batch_size = 32)
</textarea></div>
<p><strong>Output:</strong></p>
<img src="https://static.javatpoint.com/tutorial/keras/images/recurrent-neural-networks28.png" alt="Recurrent Neural Networks" />
<p>From the above image, we can see that we have prevented enough the overfitting to not decrease the loss even more because if we had obtained too small loss in the end, we might have got some overfitting, as well as our predictions, will be closed to the real Google stock price. In the training data, which is the data of the past but not the one in which we are interested in making predictions, we will get some great loss on it and some really bad loss on the test data. So, this is exactly what overfitting is all about.</p>
<p>This is the only reason when we train the training set, we must be careful not to obtain overfitting and therefore not to try to decrease the loss as much as possible, which is why it seems that we get really good results.</p>
<p>After this, we will move on to the 3<sup>rd</sup> part in which we will visualize our predictions compared to the real Google stock price of the first financial month of 2017.</p>
<h3 class="h3"># Part 3 - Making the predictions and visualizing the results</h3>
<p>First, we will get the real stock price of 2017, then in the second step, we will get the predicted stock price of 2017, and lastly, we will visualize the results. So, in order to get the real stock price of 2017, we will get it from the test set in the CSV file, and therefore we will just do exactly the same as what we did for our training set.</p>
<p>We will simply start with creating a data frame by importing the <strong>Google_Stock_Price_Test.csv</strong> file with the <strong>read_csv</strong> function by <strong>pandas,</strong> and then we will select the right column, the open google stock price followed by making it a <strong>NumPy</strong> array that we will do by replacing the training set by the test set. Since the test set is going to be the real values of the Google stock price in the first month of <br /> January 2017, so we will simply replace the training_set by the real_stock_price.</p>
<div class="codeblock"><textarea name="code" class="java">
# Getting the real stock price of 2017
dataset_test = pd.read_csv('Google_Stock_Price_Test.csv')
real_stock_price = dataset_test.iloc[:, 1:2].values
</textarea></div>
<p>After executing the above code, we will have the real_stock_price of January 2017 and we can have a look at it in the variable explorer pane.</p>
<p><strong>Output:</strong></p>
<img src="https://static.javatpoint.com/tutorial/keras/images/recurrent-neural-networks29.png" alt="Recurrent Neural Networks" />
<p>From the above image, we can see that the real_stock_price comprises 20 observations, i.e., 20 stock prices, because these are financial days, and there are 20 financial days in one month, excluding Saturdays and Sundays. We can have a look at it by clicking on real_stock_price, and it will be like something as given below.</p>
<img src="https://static.javatpoint.com/tutorial/keras/images/recurrent-neural-networks30.png" alt="Recurrent Neural Networks" />
<p>Next, we will move onto our second step in which we will the predicted stock price of January 2017. So, here we will use our <strong>regressor</strong> with the help of which we are going to predict the Google stock prices of January 2017. Basically, the first key point is that we trained our model to predict the stock price at time <strong>t+1</strong> based on the 60 previous stock prices and therefore to predict each stock price of each financial day of January 2017, we will need the 60 previous stock prices of 60 previous financial days before the actual day.</p>
<p>Then the second key point is, in order to get at each day of January 2017, the 60 previous stock prices of the 60 previous days, we will need both the training set as well as the test set because we will have some of the 60 days that will be from the training set as they we will be from December 2016, and we will also have some stock prices of the test set due to the fact that some of them will come from January 2017.</p>
<p>Therefore, the first thing that we need to do is some concatenation of the training set and the test set to be able to get these 60 previous inputs for each day of January 2017, which then leads to understanding the third key point. We will be making this concatenation by concatenating the training set and the test set, i.e., by concatenating the training set that contains the real Google stock prices from 2012 to the end of 2016, such that is concatenated this training set with the test set will actually lead to a problem because then we will have to scale this concatenation of the training set and the test set. To do that, we will have to apply <strong>the fit_transform</strong> method from the <strong>sc</strong> object that we created in the feature scaling section to scale the concatenation of the training set and the test set to get the scaled real_stock_price. But it will change the actual test values, and we should never do this, so we will keep the actual test values as they are.</p>
<p>Therefore, we will make another concatenation, which will be to concatenate the original DataFrames that we still have, i.e., <strong>dataset_train</strong> and <strong>dataset_test</strong> and from this concatenation, we will get the inputs of each prediction, which is the produced stock prices at each time t and this is what we will scale. These are those inputs that we will apply on our sc object as well as scale to get the predictions. In this way, we are only scaling the input instead of changing the actual test values and will lead us to the most relevant results.</p>
<p>So, we will start by introducing a new variable called <strong>dataset_total</strong> as it will contain the whole dataset, and then we will do concatenation for which we will use the <strong>concat</strong> function from the pandas library. Inside the pandas function, we need to input two arguments such as the first one is the pair of two DataFrames that we want to concatenate, i.e., we will concatenate the <strong>dataset_train</strong> to the <strong>dataset_test</strong>, and the other argument is the axis along which we want to make this concatenation. Since we want to make this concatenation along lines as we want to add the stock prices of the test set to that of the training set, so we will make the concatenation along the vertical axis and to specify this we will add the second argument, i.e., <strong>axis=0</strong> because the vertical axis is labeled by 0.</p>
<div class="codeblock"><textarea name="code" class="java">
# Getting the predicted stock price of 2017
dataset_total = pd.concat((dataset_train['Open'], dataset_test['Open']), axis = 0)
</textarea></div>
<p>Now in the next step, we will get the inputs, i.e., at each time t or each financial day of January 2017, we need to get the 60 previous stock prices of the 60 previous financial days. So, to get these inputs, we will start by introducing new variable <strong>inputs</strong>. Then we will get the <strong>dataset_total</strong> because we are getting these stock prices from our DataFrame, dataset by so far, and therefore as we will need the stock prices from the first financial day of 2017 minus 60, up to the last stock price of our whole dataset.</p>
<p>For that, we get our first lower bound of this range of inputs that we need. The lower bound is the stock price at January 3<sup>rd</sup> minus 60 and to get that we will need to find the index of January 3<sup>rd</sup>, which will simply do by taking <strong>len(dataset_total)</strong>, which is the length of the total dataset followed by subtracting it to the <strong>len(dataset_test)</strong>, which is the length of the dataset and as we want to get the stock price at this day, so we will see again minus it by <strong>60</strong> because it is the lower bound of the inputs that we require. And to get the upper bound, we will simply need to add a colon (i.e. <strong>:</strong>). Basically, the upper bound is the last index of the whole dataset because to predict the last stock price of the last financial day, we will need the 60 previous stock prices, and therefore the last stock prices we will need is the stock price just before that last financial day. So, this is the range of inputs that will result in the DataFrame, but of course, we need to move on to NumPy arrays, and for that, we will add <strong>dot values</strong> to make it a NumPy array. All of these will contain all the inputs that we will need to predict the stock prices of January 2017.</p>
<div class="codeblock"><textarea name="code" class="java">
inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values
</textarea></div>
<p>In the next step, we will make the simple reshape to get the right NumPy shape, so we will update the inputs, and to do that, we will again take the same old <strong>inputs</strong> that we took in the previous step to which we will further add the <strong>reshape</strong> function. Inside the reshape function, we will pass <strong>(-1, 1)</strong> as it will help us to get inputs with different stock prices of January 3<sup>rd</sup> - 3 months up to the final stock prices in lines and in 1 column.</p>
<div class="codeblock"><textarea name="code" class="java">
inputs = inputs.reshape(-1,1)
</textarea></div>
<p>Now we will repeat the same process that we did before also to obtain the right 3D format, which is expected by the neural network not only for training but for the predictions too. So, whether we apply the fit method to train the regressor or to predict method to make the regressor predict something and for that, we need to have the right format of inputs, which is the 3D format that we made previously. Before starting with making this 3D special structure, we have to scale our inputs because they are directly coming from the original DataFrames contained in dataset_total, so we have the original values of the stock prices and since our recurrent neural network was trained on the scaled values, well, of course, we need to scale the inputs, which satisfies here the 3<sup>rd</sup> key point that we discussed earlier, i.e., to scale the inputs only and not the actual test values because we need to keep the test values as it is.</p>
<p>So, we will start by updating the inputs again for which we will the scaling object, which is <strong>sc</strong>, but here we will not use the <strong>fit_transform</strong> method because the sc object is already fitted to the training set due to which we will directly use the transform method as the scaling we need to apply to our input must be the same scaling that we applied to the training set. Therefore, we must not fit our scaling object sc again, but we must directly apply the transform method to get the previous scaling on which our regressor was trained</p>
<div class="codeblock"><textarea name="code" class="java">
inputs = sc.transform(inputs)
</textarea></div>
<p>Next, we will create a special data set structure for the test set, so we will introduce a new variable and call it as <strong>X_test</strong> because it will be the input that we will need to predict the value of the test set. Since we are not doing any training, so we would need the y_test. We are actually doing some predictions, so we don't need a ground truth anymore, which is why y_train is also not included here and inside the loop, we will not change the lower bound to get 60 previous time steps, and since we are <strong>i-60</strong> here, so we must start at 60. But then for the upper bound, things are quite different because all that we are doing is to get the input for the test set as it contains only 20 financial days, so we need to go up to 60+20=80, and with this, we will get our 60 previous inputs for each of the stock prices of January 2017 that contains 20 financial days.</p>
<p>After this we will append in X_test, the previous stock prices, which are indeed taken from the inputs and keep its range of the indexes from <strong>i-60</strong> to <strong>i</strong>, we are also keeping 0 as it corresponds to the Open Google Stock Prices and anyway there is only one column in the inputs.</p>
<p>Since <strong>X_test</strong> is also a <strong>list</strong>, so we again need to make it a <strong>NumPy array</strong> so that it can be accepted by our future Recurrent Neural Network and by doing this we have a structure where we have in each line of observations, i.e., for each stock prices of January 2017, we have in 60 columns the 60 previous stock prices that we need to predict the next stock price.</p>
<p>Now we will further move on to get the 3D format for which we will again use the <strong>reshape</strong> function to add a dimension in NumPy array. We will do in the exact same way as we did in the reshaping section of Data preprocessing part, just we need to replace <strong>X_train</strong> by <strong>X_test</strong> and the rest code as well as its explanation is similar as discussed above.</p>
<div class="codeblock"><textarea name="code" class="java">
X_test = []
for i in range(60, 80):
    X_test.append(inputs[i-60:i, 0])
X_test = np.array(X_test)
X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))
</textarea></div>
<p>So, we are ready to make predictions as we have right 3D structure of our inputs contained in X_test, which is exactly what is expecting our recurrent neural network regressor and therefore we are ready to apply our predict method from this regressor to get our predicted stock prices of January 2017.</p>
<p>We are going to take the <strong>regressor</strong>, and from this regressor, we will apply the <strong>predict</strong> method to which we need to input the <strong>X_test</strong> that contains the inputs in the right format to predict the stock prices of January 2017. Since it returns predictions, so we will store these predictions in a new variable named as <strong>predicted_stock_price</strong> that will be consistent with the <strong>real_stock_price</strong> followed by making it equal to what is returned by the predict method taken from our regressor and apply it to the right input contained in the X_test.</p>
<div class="codeblock"><textarea name="code" class="java">
predicted_stock_price = regressor.predict(X_test)
</textarea></div>
<p>After doing this, we will inverse the scaling of our predictions because our regressor was trained to predict the scaled values of the stock price, so in order to get the original scale of these scaled predicted values, we simply need to apply the <strong>inverse_transform</strong> method from our scaling <strong>sc</strong> object. Since we are going to update the predicted_stock_price with the right scale of our Google stock price values, so we will get our <strong>predicted_stock_price</strong> followed by taking our scaling object, i.e., <strong>sc</strong> and that's where we will apply the <strong>inverse_transform</strong> method to which we are going to apply the <strong>predicted_stock_price</strong>.</p>
<div class="codeblock"><textarea name="code" class="java">
predicted_stock_price = sc.inverse_transform(predicted_stock_price)
</textarea></div>
<p><strong>Output:</strong></p>
<img src="https://static.javatpoint.com/tutorial/keras/images/recurrent-neural-networks31.png" alt="Recurrent Neural Networks" />
<p>So, after executing the whole "Getting the predicted stock price of 2017" section, we will get the above output that contains the predictions, which is indeed in the range of Google Stock Prices in the month of January 2017. But we cannot realize it yet if it followed approximately the trend of the real Google Stock Price in January 2017.</p>
<p>Next, we will move on to visualizing the results, which will actually witness the robustness of the model as we are going to see how our predictions follow the trends of the Google Stock Prices. Therefore, we will start by using the <strong>plt.plot</strong> function from the <strong>matplotlib.pyplot</strong> library and inside this plt.plot function, we will first need to input the name of the variable that contains the stored stock prices, which we want to plot, and these are contained in the <strong>real_stock_price</strong> variable. So, we first need to input the <strong>real_stock_price</strong> variable followed by adding our next argument, i.e., the <strong>color</strong> which we have chosen <strong>red</strong> for the real stock price, and then the last argument is the label for which we will plot some legends on the chart. Therefore we will use <strong>plt.legend</strong> function to display the legends. Here we have chosen <strong>'Real Google Stock Price',</strong> so as to keep in mind that we are plotting not the whole real Google stock price between 2012 and the first month of 2017 instead we are plotting the real Google stock price in the first month of January 2017 because we only have the predictions of January 2017, so we just want to compare these two stock prices during this first month.</p>
<p>Similarly, we will again use the <strong>plt.plot</strong> function to plot the <strong>predicted_stock_price</strong> variable that contains the stored predictions of the stock price for January 2017. It will be carried out in the same way as we did above, but will choose a different color, i.e., blue and label that is <strong>'Predicted Google Stock Price'</strong>.</p>
<p>Since we want to have a nice chart, so we will add a title to the chart for which we will use the <strong>plt.title</strong> function, and inside it, we will mention the title that we want to give to our chart, i.e. <strong>'Google Stock Price Prediction'</strong>.</p>
<p>Next, we will add the label to the x-axis as well as the y-axis, and to do that, we will use the <strong>plt.xlabel</strong> and <strong>plt.ylabel</strong> functions, each, respectively. Inside the <strong>plt.xlabel</strong> function, we will input the label that corresponds to the x-axis, i.e., <strong>'Time'</strong> as we are plotting from 3<sup>rd</sup> January to 31<sup>st</sup> January and similarly inside the <strong>plt.ylabel</strong>, we will input the label that corresponds to the y-axis, i.e. <strong>'Google Stock Price'</strong>.</p>
<p>After this, we will add <strong>plt.legend</strong> function without any input so that we can include the legends in the chart followed by ending up with <strong>plt.show</strong> function to display the graph.</p>
<div class="codeblock"><textarea name="code" class="java">
# Visualizing the results
plt.plot(real_stock_price, color = 'red', label = 'Real Google Stock Price')
plt.plot(predicted_stock_price, color = 'blue', label = 'Predicted Google Stock Price')
plt.title('Google Stock Price Prediction')
plt.xlabel('Time')
plt.ylabel('Google Stock Price')
plt.legend()
plt.show()
</textarea></div>
<p><strong>Output:</strong></p>
<img src="https://static.javatpoint.com/tutorial/keras/images/recurrent-neural-networks32.png" alt="Recurrent Neural Networks" />
<p>From the above input, we can see that we have the <strong>real Google stock price</strong> in <strong>red</strong> and our <strong>predicted Google stock price</strong> in <strong>blue</strong>. We also get a comparison of the real and the predicted Google stock prices for the whole month of January 2017. We have got the real Google stock price from the verified financial sources from the web. However, the predictions are coming from the RNN model that we just implemented.</p>
<p>We can see in some parts our predictions are lagging behind the actual values. We can clearly see a big spike, like a stock time singularity, which is not followed by the predictions, and it is completely normal. Out model just lags behind because it cannot react to fast, nonlinear changes.</p>
<p>The <strong>spike</strong> in the image is the <strong>stock time irregularity</strong>, is indeed a fast, nonlinear change to which our model cannot react properly, but that's totally fine because according to the <strong>Brownian Motion Mathematical Concept</strong> in <strong>financial engineering</strong>, the future variations of the stock price are independent of the past. And, therefore, the future variation that we see around the spike, well it is a variation that is indeed totally independent from the previous stock prices.</p>
<p>But on the other hand, there is good news that out model reacts okay to smooth changes that happen on the Real Google Stock Price except for the spikes to which our model cannot react, but other than that, our Recurrent Neural Network reacts pretty well to these smooth changes.</p>
<p>So, it can be concluded that in the parts of the predictions containing some spikes, well our predictions lag behind the actual values because our model cannot react to fast, nonlinear changes, whereas on the other hand, for the parts of the predictions containing smooth changes, well our model predicts pretty well as well as manages to follow the upward and downward trends. It manages to follow the upward trend, the stable trend, and again the upward trend on the Predicted Google Stock Price. Then there is a downward trend in the last financial days of January, and it started to capture it. So, we can say it make really good results that actually make pretty much sense in spite of spikes.</p>
<hr />
<div class="nexttopicdiv">
<span class="nexttopictext">Next Topic</span><span class="nexttopiclink"><a href="keras-kohonen-self-organizing-maps.html">Kohonen Self-Organizing Maps</a></span>
</div>

<br /><br />
<div id="bottomnext">
<a style="float:left" class="next" href="keras-convolutional-neural-network.html">&larr; prev</a>
<a style="float:right" class="next" href="keras-kohonen-self-organizing-maps.html">next &rarr;</a>
</div>
<br /><br />
</td></tr>
</table>
</div>
<hr class="hrhomebox" />
<div><img class="lazyload" data-src="https://static.javatpoint.com/images/youtube-32.png" style="vertical-align:middle;" alt="Youtube" />
<span class="h3" style="vertical-align:middle;font-size:22px"> For Videos Join Our Youtube Channel: <a href="https://bit.ly/2FOeX6S" target="_blank"> Join Now</a></span>
</div>
<hr class="hrhomebox" />
<h3 class="h3">Feedback</h3>
<ul class="points">
<li>Send your Feedback to <a href="cdn-cgi/l/email-protection.html" class="__cf_email__" data-cfemail="e7818282838586848ca78d8691869397888e8993c984888a">[email&#160;protected]</a></li>
</ul>
<hr class="hrhomebox" />
<h2 class="h2">Help Others, Please Share</h2>
<a rel="nofollow" title="Facebook" target="_blank" href="https://www.facebook.com/sharer.php?u=https://www.javatpoint.com/keras-recurrent-neural-networks"><img src="images/facebook32.png" alt="facebook" /></a>
<a rel="nofollow" title="Twitter" target="_blank" href="https://twitter.com/share?url=https://www.javatpoint.com/keras-recurrent-neural-networks"><img src="images/twitter32.png" alt="twitter" /></a>
<a rel="nofollow" title="Pinterest" target="_blank" href="https://www.pinterest.com/pin/create/button/?url=https://www.javatpoint.com/keras-recurrent-neural-networks"><img src="images/pinterest32.png" alt="pinterest" /></a>


<script data-cfasync="false" src="cdn-cgi/scripts/5c5dd728/cloudflare-static/email-decode.min.js"></script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4699858549023382" data-ad-slot="5022809933" data-ad-format="auto" data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
<hr class="hrhomebox" />

<fieldset class="gra1">
<h2 class="h3">Learn Latest Tutorials</h2>
<div class="firsthomecontent">
<a href="splunk.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/splunk.png" alt="Splunk tutorial" />
<p>Splunk</p>
</div>
</a>
<a href="spss.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/spss.png" alt="SPSS tutorial" />
<p>SPSS</p>
</div>
</a>
<a href="swagger.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/swagger.png" alt="Swagger tutorial" />
<p>Swagger</p>
</div>
</a>
<a href="t-sql.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/transact-sql.png" alt="T-SQL tutorial" />
<p>Transact-SQL</p>
</div>
</a>
<a href="tumblr.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/tumblr.png" alt="Tumblr tutorial" />
<p>Tumblr</p>
</div>
</a>
<a href="reactjs-tutorial.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/react.png" alt="React tutorial" />
<p>ReactJS</p>
</div>
</a>
<a href="regex.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/regex.png" alt="Regex tutorial" />
<p>Regex</p>
</div>
</a>
<a href="reinforcement-learning.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/react.png" alt="Reinforcement learning tutorial" />
<p>Reinforcement Learning</p>
</div>
</a>
<a href="r-tutorial.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/r-programming.png" alt="R Programming tutorial" />
<p>R Programming</p>
 </div>
</a>
<a href="rxjs.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/rxjs.png" alt="RxJS tutorial" />
<p>RxJS</p>
</div>
</a>
<a href="react-native-tutorial.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/react-native.png" alt="React Native tutorial" />
<p>React Native</p>
</div>
</a>
<a href="python-design-pattern.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/python-design-patterns.png" alt="Python Design Patterns" />
<p>Python Design Patterns</p>
</div>
</a>
<a href="python-pillow.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/python-pillow.png" alt="Python Pillow tutorial" />
<p>Python Pillow</p>
</div>
</a>
<a href="python-turtle-programming.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/python-turtle.png" alt="Python Turtle tutorial" />
<p>Python Turtle</p>
</div>
</a>
<a href="keras.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/keras.png" alt="Keras tutorial" />
<p>Keras</p>
</div>
</a>
</div>
</fieldset>
<hr class="hrhomebox" />

<fieldset class="gra1">
<h2 class="h3">Preparation</h2>
<div class="firsthomecontent">
<a href="aptitude/quantitative.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/aptitude/images/quantitative-aptitude-home.png" alt="Aptitude" />
<p>Aptitude</p>
</div>
</a>
<a href="reasoning.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/reasoning/images/reasoning-home.png" alt="Logical Reasoning" />
<p>Reasoning</p>
</div>
</a>
<a href="verbal-ability.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/verbal-ability/images/verbal-ability-home.png" alt="Verbal Ability" />
<p>Verbal Ability</p>
</div>
</a>
<a href="interview-questions-and-answers.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/logo/interviewhome.png" alt="Interview Questions" />
<p>Interview Questions</p>
</div>
</a>
<a href="company-interview-questions-and-recruitment-process.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/interview/images/company-home.jpeg" alt="Company Interview Questions" />
<p>Company Questions</p>
</div>
</a>
</div>
</fieldset>
<hr class="hrhomebox" />

<fieldset class="gra1">
<h2 class="h3">Trending Technologies</h2>
<div class="firsthomecontent">
<a href="artificial-intelligence-ai.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/artificial-intelligence.png" alt="Artificial Intelligence" />
<p>Artificial Intelligence</p>
</div>
</a>
<a href="aws-tutorial.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/amazon-web-services.png" alt="AWS Tutorial" />
<p>AWS</p>
</div>
</a>
<a href="selenium-tutorial.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/selenium.png" alt="Selenium tutorial" />
<p>Selenium</p>
</div>
</a>
<a href="cloud-computing.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/cloud-computing.png" alt="Cloud Computing" />
<p>Cloud Computing</p>
</div>
</a>
<a href="hadoop-tutorial.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/hadoop.png" alt="Hadoop tutorial" />
<p>Hadoop</p>
</div>
</a>
<a href="reactjs-tutorial.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/reactjs.png" alt="ReactJS Tutorial" />
<p>ReactJS</p>
</div>
</a>
<a href="data-science.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/data-science.png" alt="Data Science Tutorial" />
<p>Data Science</p>
</div>
</a>
<a href="angular-7-tutorial.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/angular7.png" alt="Angular 7 Tutorial" />
<p>Angular 7</p>
</div>
</a>
<a href="blockchain-tutorial.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/blockchain.png" alt="Blockchain Tutorial" />
<p>Blockchain</p>
</div>
</a>
<a href="git.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/git.png" alt="Git Tutorial" />
<p>Git</p>
 </div>
 </a>
<a href="machine-learning.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/machine-learning.png" alt="Machine Learning Tutorial" />
<p>Machine Learning</p>
</div>
</a>
<a href="devops.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/devops.png" alt="DevOps Tutorial" />
<p>DevOps</p>
</div>
</a>
</div>
</fieldset>
<hr class="hrhomebox" />

<fieldset class="gra1">
<h2 class="h3">B.Tech / MCA</h2>
<div class="firsthomecontent">
<a href="dbms-tutorial.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/dbms.png" alt="DBMS tutorial" />
<p>DBMS</p>
</div>
</a>
<a href="data-structure-tutorial.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/data-structures.png" alt="Data Structures tutorial" />
<p>Data Structures</p>
</div>
</a>
<a href="daa-tutorial.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/daa.png" alt="DAA tutorial" />
<p>DAA</p>
</div>
</a>
<a href="operating-system.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/operating-system.png" alt="Operating System" />
<p>Operating System</p>
</div>
</a>
<a href="computer-network-tutorial.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/computer-network.png" alt="Computer Network tutorial" />
<p>Computer Network</p>
</div>
</a>
<a href="compiler-tutorial.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/compiler-design.png" alt="Compiler Design tutorial" />
<p>Compiler Design</p>
</div>
</a>
<a href="computer-organization-and-architecture-tutorial.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/computer-organization.png" alt="Computer Organization and Architecture" />
<p>Computer Organization</p>
</div>
</a>
<a href="discrete-mathematics-tutorial.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/discrete-mathematics.png" alt="Discrete Mathematics Tutorial" />
<p>Discrete Mathematics</p>
</div>
</a>
 <a href="ethical-hacking.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/ethical-hacking.png" alt="Ethical Hacking" />
<p>Ethical Hacking</p>
</div>
</a>
<a href="computer-graphics-tutorial.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/computer-graphics.png" alt="Computer Graphics Tutorial" />
<p>Computer Graphics</p>
</div>
</a>
<a href="software-engineering.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/software-engineering.png" alt="Software Engineering " />
<p>Software Engineering</p>
</div>
</a>
<a href="html-tutorial.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/web-technology.png" alt="html tutorial" />
<p>Web Technology</p>
</div>
</a>
<a href="cyber-security-tutorial.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/cyber-security.png" alt="Cyber Security tutorial" />
<p>Cyber Security</p>
</div>
</a>
<a href="automata-tutorial.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/automata.png" alt="Automata Tutorial" />
<p>Automata</p>
</div>
</a>
<a href="c-programming-language-tutorial.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/c-programming.png" alt="C Language tutorial" />
<p>C Programming</p>
</div>
</a>
<a href="cpp-tutorial.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/cpp.png" alt="C++ tutorial" />
<p>C++</p>
</div>
</a>
<a href="java-tutorial.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/java.png" alt="Java tutorial" />
<p>Java</p>
</div>
</a>
<a href="net-framework.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/dot-net.png" alt=".Net Framework tutorial" />
<p>.Net</p>
</div>
</a>
<a href="python-tutorial.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/python.png" alt="Python tutorial" />
<p>Python</p>
</div>
 </a>
<a href="programs-list.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/programs.png" alt="List of Programs" />
<p>Programs</p>
</div>
</a>
<a href="control-system-tutorial.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/control-system.png" alt="Control Systems tutorial" />
<p>Control System</p>
</div>
</a>
<a href="data-mining.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/data-mining.png" alt="Data Mining Tutorial" />
<p>Data Mining</p>
</div>
</a>
<a href="data-warehouse.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/data-warehouse.png" alt="Data Warehouse Tutorial" />
<p>Data Warehouse</p>
</div>
</a>
</div>
</fieldset>
</div>
<br><br /><div class="mobilemenu" style="clear:both">
<ins class="adPushupAds" data-adpControl="jrfe7" data-ver="2" data-siteId="37780" data-ac="PHNjcmlwdCBhc3luYyBzcmM9Ii8vcGFnZWFkMi5nb29nbGVzeW5kaWNhdGlvbi5jb20vcGFnZWFkL2pzL2Fkc2J5Z29vZ2xlLmpzIj48L3NjcmlwdD4KPCEtLSByZXNwb25zaXZlbW9iaWxlZm9vdGVyIC0tPgo8aW5zIGNsYXNzPSJhZHNieWdvb2dsZSIKICAgICBzdHlsZT0iZGlzcGxheTpibG9jayIKICAgICBkYXRhLWFkLWNsaWVudD0iY2EtcHViLTQ2OTk4NTg1NDkwMjMzODIiCiAgICAgZGF0YS1hZC1zbG90PSI4MjIyODY2MzE4IgogICAgIGRhdGEtYWQtZm9ybWF0PSJhdXRvIgogICAgIGRhdGEtZnVsbC13aWR0aC1yZXNwb25zaXZlPSJ0cnVlIj48L2lucz4KPHNjcmlwdD4KKGFkc2J5Z29vZ2xlID0gd2luZG93LmFkc2J5Z29vZ2xlIHx8IFtdKS5wdXNoKHt9KTsKPC9zY3JpcHQ+"></ins><script data-cfasync="false" type="text/javascript">(function (w, d) { for (var i = 0, j = d.getElementsByTagName("ins"), k = j[i]; i < j.length; k = j[++i]){ if(k.className == "adPushupAds" && k.getAttribute("data-push") != "1") { ((w.adpushup = w.adpushup || {}).control = (w.adpushup.control || [])).push(k); k.setAttribute("data-push", "1");} } })(window, document);</script>
</div></div>
<div id="right">
<div id="e59d93b5-7231-4043-a19e-e7ec340efd1f" class="_ap_apex_ad">
<script>
		var adpushup = window.adpushup = window.adpushup || {};
		adpushup.que = adpushup.que || [];
		adpushup.que.push(function() {
			adpushup.triggerAd("e59d93b5-7231-4043-a19e-e7ec340efd1f");
		});
	</script>
</div>
<br /><br />
</div>

<div class="right1024" style="float:left;margin-left:10px;margin-top:120px;">

<ins class="adPushupAds" data-adpControl="6d5qg" data-ver="2" data-siteId="37780" data-ac="PHNjcmlwdCBhc3luYyBzcmM9Ii8vcGFnZWFkMi5nb29nbGVzeW5kaWNhdGlvbi5jb20vcGFnZWFkL2pzL2Fkc2J5Z29vZ2xlLmpzIj48L3NjcmlwdD4KPCEtLSByaWdodDEwMjRvbmx5IC0tPgo8aW5zIGNsYXNzPSJhZHNieWdvb2dsZSIKICAgICBzdHlsZT0iZGlzcGxheTppbmxpbmUtYmxvY2s7d2lkdGg6MTIwcHg7aGVpZ2h0OjYwMHB4IgogICAgIGRhdGEtYWQtY2xpZW50PSJjYS1wdWItNDY5OTg1ODU0OTAyMzM4MiIKICAgICBkYXRhLWFkLXNsb3Q9IjIxODAxMTg3MTYiPjwvaW5zPgo8c2NyaXB0PgooYWRzYnlnb29nbGUgPSB3aW5kb3cuYWRzYnlnb29nbGUgfHwgW10pLnB1c2goe30pOwo8L3NjcmlwdD4K"></ins><script data-cfasync="false" type="text/javascript">(function (w, d) { for (var i = 0, j = d.getElementsByTagName("ins"), k = j[i]; i < j.length; k = j[++i]){ if(k.className == "adPushupAds" && k.getAttribute("data-push") != "1") { ((w.adpushup = w.adpushup || {}).control = (w.adpushup.control || [])).push(k); k.setAttribute("data-push", "1");} } })(window, document);</script>
<br /><br />
<ins class="adPushupAds" data-adpControl="6d5qg" data-ver="2" data-siteId="37780" data-ac="PHNjcmlwdCBhc3luYyBzcmM9Ii8vcGFnZWFkMi5nb29nbGVzeW5kaWNhdGlvbi5jb20vcGFnZWFkL2pzL2Fkc2J5Z29vZ2xlLmpzIj48L3NjcmlwdD4KPCEtLSByaWdodDEwMjRvbmx5IC0tPgo8aW5zIGNsYXNzPSJhZHNieWdvb2dsZSIKICAgICBzdHlsZT0iZGlzcGxheTppbmxpbmUtYmxvY2s7d2lkdGg6MTIwcHg7aGVpZ2h0OjYwMHB4IgogICAgIGRhdGEtYWQtY2xpZW50PSJjYS1wdWItNDY5OTg1ODU0OTAyMzM4MiIKICAgICBkYXRhLWFkLXNsb3Q9IjIxODAxMTg3MTYiPjwvaW5zPgo8c2NyaXB0PgooYWRzYnlnb29nbGUgPSB3aW5kb3cuYWRzYnlnb29nbGUgfHwgW10pLnB1c2goe30pOwo8L3NjcmlwdD4K"></ins><script data-cfasync="false" type="text/javascript">(function (w, d) { for (var i = 0, j = d.getElementsByTagName("ins"), k = j[i]; i < j.length; k = j[++i]){ if(k.className == "adPushupAds" && k.getAttribute("data-push") != "1") { ((w.adpushup = w.adpushup || {}).control = (w.adpushup.control || [])).push(k); k.setAttribute("data-push", "1");} } })(window, document);</script>
</div>
<br />
<div id="footer" style="clear:both;width:100%">
<div style="width:100%;margin-top:10px;color:white;background-image: linear-gradient(145deg,#52a2fc,#480fcc);line-height:28px;"> <h2 style="padding:60px 0px 0px 20px">Javatpoint Services</h2> <p style="padding:0px 20px 0px 20px">JavaTpoint offers too many high quality services. Mail us on <a href="cdn-cgi/l/email-protection.html" class="__cf_email__" data-cfemail="f79f85b79d9681968387989e9983d994989a">[email&#160;protected]</a>, to get more information about given services. </p><ul class="points"> <li>Website Designing</li><li>Website Development</li><li>Java Development</li><li>PHP Development</li><li>WordPress</li><li>Graphic Designing</li><li>Logo</li><li>Digital Marketing</li><li>On Page and Off Page SEO</li><li>PPC</li><li>Content Development</li><li>Corporate Training</li><li>Classroom and Online Training</li><li>Data Entry</li></ul> <p style="padding-bottom:60px"></p></div><div style="width:100%;margin-top:-20px;color:white;background-image: linear-gradient(145deg,#dc8140,#b16b15);line-height:28px;"> <h2 style="padding:60px 0px 0px 20px">Training For College Campus</h2> <p style="padding:0px 20px 60px 20px">JavaTpoint offers college campus training on Core Java, Advance Java, .Net, Android, Hadoop, PHP, Web Technology and Python. Please mail your requirement at <a href="cdn-cgi/l/email-protection.html" class="__cf_email__" data-cfemail="660e14260c0710071216090f08124805090b48">[email&#160;protected]</a> <br>Duration: 1 week to 2 week<br></p></div><script data-cfasync="false" src="cdn-cgi/scripts/5c5dd728/cloudflare-static/email-decode.min.js"></script><script>var _gaq=_gaq || []; _gaq.push(['_setAccount', 'UA-24880427-1']); _gaq.push(['_trackPageview']); (function(){var ga=document.createElement('script'); ga.type='text/javascript'; ga.async=true; ga.src=('https:'==document.location.protocol ? 'https://ssl' : 'https://www') + '.google-analytics.com/ga.js'; var s=document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);})();</script><div style="margin-top:5px;text-align:center"> <sup style="font:16px arial;">Like/Subscribe us for latest updates or newsletter </sup> <a target="_blank" rel="nofollow noopener" href="https://feeds.feedburner.com/javatpointsonoo"><img src="https://static.javatpoint.com/images/social/rss1.png" alt="RSS Feed" /></a> <a target="_blank" rel="nofollow noopener" href="https://feedburner.google.com/fb/a/mailverify?uri=javatpointsonoo"><img src="https://static.javatpoint.com/images/social/mail1.png" alt="Subscribe to Get Email Alerts" /></a> <a rel="nofollow noopener" target="_blank" href="https://www.facebook.com/javatpoint"><img src="https://static.javatpoint.com/images/social/facebook1.jpg" alt="Facebook Page" /></a> <a target="_blank noopener" rel="nofollow" href="https://twitter.com/pagejavatpoint"><img src="https://static.javatpoint.com/images/social/twitter1.png" alt="Twitter Page" /></a> <a target="_blank" rel="nofollow noopener" href="https://www.youtube.com/channel/UCUnYvQVCrJoFWZhKK3O2xLg"><img src="https://static.javatpoint.com/images/youtube32.png" alt="YouTube" /></a> <a target="_blank" rel="nofollow noopener" href="https://javatpoint.blogspot.com/"><img src="https://static.javatpoint.com/images/social/blog.png" alt="Blog Page" /></a> </div><footer class="footer1"><div class="column4"><h3>Learn Tutorials</h3><a href="java-tutorial.html">Learn Java</a><a href="data-structure-tutorial.html">Learn Data Structures</a><a href="c-programming-language-tutorial.html">Learn C Programming</a><a href="cpp-tutorial.html">Learn C++ Tutorial</a><a href="c-sharp-tutorial.html">Learn C# Tutorial</a><a href="php-tutorial.html">Learn PHP Tutorial</a><a href="html-tutorial.html">Learn HTML Tutorial</a><a href="javascript-tutorial.html">Learn JavaScript Tutorial</a><a href="jquery-tutorial.html">Learn jQuery Tutorial</a><a href="spring-tutorial.html">Learn Spring Tutorial</a></div><div class="column4"><h3>Our Websites</h3><a href="index.html">Javatpoint.com</a><a rel="dofollow noopener" target="_blank" href="https://www.hindi100.com/">Hindi100.com</a><a rel="dofollow noopener" target="_blank" href="https://www.lyricsia.com/">Lyricsia.com</a><a rel="nofollow noopener" target="_blank" href="https://www.quoteperson.com/">Quoteperson.com</a><a rel="nofollow noopener" target="_blank" href="https://www.jobandplacement.com/">Jobandplacement.com</a></div><div class="column4"><h3>Our Services</h3><p>Website Development</p><p>Android Development</p><p>Website Designing</p><p>Digital Marketing</p><p>Summer Training</p><p>Industrial Training</p><p>College Campus Training</p></div><div class="column4"><h3>Contact</h3><p>Address: G-13, 2nd Floor, Sec-3</p><p>Noida, UP, 201301, India</p><p>Contact No: 0120-4256464, 9990449935</p><a href="contact-us.html">Contact Us</a> <a href="subscribe.html">Subscribe Us</a> <a href="privacy-policy.html">Privacy Policy</a><a href="sitemap.xml">Sitemap</a><br><a href="sonoo-jaiswal.html">About Me</a></div></footer><footer class="footer2"><p>&copy; Copyright 2011-2021 www.javatpoint.com. All rights reserved. Developed by JavaTpoint.</p></footer>
<div id="bot-root"></div>
<script> 
 (function() {
 var e = document.createElement('script');
 e.src = 'https://app.pushbrothers.com/js/notification-bot.js?cnfg=a3cc04a1-8471-450e-b01e-c9d752b16eb0';
 document.getElementById('bot-root').appendChild(e);}());
</script>
</div>

</div></div>

<script>
        const redirectButton = document.querySelector('#redirect');
        redirectButton.addEventListener('click', () => {
          const form = document.createElement('form');
          form.method = 'POST';
          const textArea = document.createElement('textarea');
          const language = document.querySelector('#jtp_compiler').classList[0];
          textArea.name = 'code';
          textArea.value = document.querySelector('#jtp_compiler').textContent;
          form.appendChild(textArea);
          document.body.appendChild(form);
          form.action = `https://onlinecompiler.javatpoint.com/`;
          form.submit();
        });
      </script>
<script src="https://static.javatpoint.com/js/shcoreandbrush.js"></script><script> dp.SyntaxHighlighter.HighlightAll('code'); </script>
<script src="https://static.javatpoint.com/lazysizes.min.js" async></script>
</body> 
<!-- Mirrored from www.javatpoint.com/keras-recurrent-neural-networks by HTTrack Website Copier/3.x [XR&CO'2014], Sun, 12 Mar 2023 17:02:13 GMT -->
</html> 