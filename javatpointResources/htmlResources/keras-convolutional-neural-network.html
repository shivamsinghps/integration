 <!DOCTYPE html><html lang="en">
<!-- Mirrored from www.javatpoint.com/keras-convolutional-neural-network by HTTrack Website Copier/3.x [XR&CO'2014], Sun, 12 Mar 2023 17:02:13 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=ISO-8859-1" /><!-- /Added by HTTrack -->
<head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Convolutional Neural Network - Javatpoint</title><link rel="SHORTCUT ICON" href="https://static.javatpoint.com/images/favicon2.png" />
<link rel="stylesheet" type="text/css" href="https://static.javatpoint.com/link.css?v=5.1" async /><link rel="dns-prefetch" href="https://clients1.google.com/"><link rel="dns-prefetch" href="https://static.javatpoint.com/"><link rel="dns-prefetch" href="https://googleads.g.doubleclick.net/"><link rel="dns-prefetch" href="https://www.google.com/"><link rel="dns-prefetch" href="https://feedify.net/"><meta name="theme-color" content="#4CAF50" /><meta property="og:title" content="Convolutional Neural Network - Javatpoint" /><meta property="og:description" content="Convolutional Neural Network with What is Keras, Keras Backend, Models, Functional API, Pooling Layers, Merge Layers, Sequence Preprocessing, Metrics, Optimizers, Backend, Visualization etc." />
<meta name="keywords" content="keras tutorial, keras, what is keras, keras backend, keras models, keras functional api, core layer, pooling layers, merge layers, sequence preprocessing, metrics, optimizers, backend, visualization" /><meta name="description" content="Convolutional Neural Network with What is Keras, Keras Backend, Models, Functional API, Pooling Layers, Merge Layers, Sequence Preprocessing, Metrics, Optimizers, Backend, Visualization etc." /><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><link rel="canonical" href="keras-convolutional-neural-network.html" />
<meta property="og:locale" content="en_US" /><meta property="og:type" content="article" /><meta name="twitter:title" property="og:title" content="Convolutional Neural Network - Javatpoint" /><meta name="twitter:description" property="og:description" content="Convolutional Neural Network with What is Keras, Keras Backend, Models, Functional API, Pooling Layers, Merge Layers, Sequence Preprocessing, Metrics, Optimizers, Backend, Visualization etc." /><meta property="og:url" content="keras-convolutional-neural-network.html" /><meta property="og:site_name" content="www.javatpoint.com" /><meta name="twitter:card" content="summary" /><meta name="twitter:site" content="@pagejavatpoint" /><meta name="twitter:domain" content="www.javatpoint.com" /><meta name="twitter:creator" content="@pagejavatpoint" />
<link href="manifest.json" rel="manifest">
<script data-cfasync="false" type="text/javascript">(function(w, d) { var s = d.createElement('script'); s.src = 'http://delivery.adrecover.com/37784/adRecover.js?ts=1543562646174'; s.type = 'text/javascript'; s.async = true; (d.getElementsByTagName('head')[0] || d.getElementsByTagName('body')[0]).appendChild(s); })(window, document);</script>

<script data-cfasync="false" type="text/javascript">
(function (w, d) {
  var siteId = "37780";
  var targetElement =
    d.getElementsByTagName("head")[0] || d.getElementsByTagName("body")[0];
  var s = d.createElement("script");
  s.src = "//cdn.adpushup.com/" + siteId + "/adpushup.js";
  s.crossOrigin = "anonymous";
  s.type = "text/javascript";
  s.async = true;
  targetElement.appendChild(s);
  function sendErrorLog(log) {
    var eventName = "script_error";
    log.siteId = siteId;
    var data = btoa(JSON.stringify(log));
    var img = document.createElement("img");
    img.src =
      "https://aplogger.adpushup.com/log?event=HC_" + eventName + "&data=" + data;
  }
  var searchParams =
    typeof URLSearchParams === "function" &&
    new URLSearchParams(window.location.search);
  if (searchParams) {
    var isDebugModeOn = searchParams.has("apDebug");
  }
  w.addEventListener("error", function (event) {
    try {
      var filename = event.filename || "";
      if (filename.indexOf("/" + siteId + "/adpushup.js") === -1) {
        return;
      }
      var error = event.error;
      if (error) {
        var message = error.message;
        var stack = error.stack;
      }
      message = message || event.message;
      var log = {
        message: message,
        stack: stack || "",
        timestamp: Math.floor(event.timeStamp),
        type: "uncaughterror",
      };
      sendErrorLog(log);
      !isDebugModeOn && event.preventDefault();
    } catch (error) {}
  });
  w.addEventListener("unhandledrejection", function (event) {
    var reason = event.reason;
    if (typeof reason === "object") reason = JSON.stringify(reason);
    var log = {
      message: reason || "no reason found",
      timestamp: Math.floor(event.timeStamp),
      type: "unhandledrejection",
    };
    sendErrorLog(log);
    !isDebugModeOn && event.preventDefault();
  });
  var ga = d.createElement("script");
  ga.src = "https://www.googletagmanager.com/gtag/js?id=G-Z0TZ7TDHS1";
  ga.type = "text/javascript";
  ga.async = true;
  targetElement.appendChild(ga);
  w.dataLayer = window.dataLayer || [];
  w.gtag = function () {
    window.dataLayer.push(arguments);
  };
  w.gtag("js", new Date());
  w.gtag("config", "G-Z0TZ7TDHS1", {
    custom_map: { dimension1: "siteid" },
  });
  w.gtag("event", "script-call", {
    send_to: "G-Z0TZ7TDHS1",
    siteid: siteId,
  });
  s.onerror = function (msg) {
    w.gtag("event", "ad-block", {
      send_to: "G-Z0TZ7TDHS1",
      siteid: siteId,
    });
  };
})(window, document);
</script>
</head>
<body onload="highlightlink()">

<button onclick="topFunction()" id="myBtn">&#8679; SCROLL TO TOP</button>
<div id="page" style="margin:-8px;background-color:#f5f5f4;"><div id="container"> <div class="header"><table style="width:100%;margin-bottom:5px"> <tr> <td> <div style="clear:both;float:left;width:230px;margin-top:15px;margin-left:20px"> <a href="index.html"><img src="https://static.javatpoint.com/images/logo/jtp_logo.png" alt="Javatpoint Logo" /></a> </div> <div style="float:left;width:60%;"><script> (function() { var cx = '005383125436438536544:y1edweedxwi'; var gcse = document.createElement('script'); gcse.type = 'text/javascript'; gcse.async = true; gcse.src = 'https://cse.google.com/cse.js?cx=' + cx; var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(gcse, s); })();</script><gcse:search></gcse:search> </div> </td> </tr></table> </div>
<div class="headermobile">
<div style="margin-top:10px;padding:0px;text-align:left;">
<span style="float:left"><input type="image" src="images/menuhome64.png" alt="Go To Top" onclick="showmenu()" /></span>
<span style="float:left"><a href="index.html"><img src="images/logo/jtp_logo.png" alt="Javatpoint Logo"></a></span>
</div>
<div style="margin:0px;padding:0px;clear:both">
<script>
  (function() {
    var cx = '005383125436438536544:y1edweedxwi';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>

</div>
</div>
<div id="link" style="clear:both;z-index:999"> <div class="ddsmoothmenu">
<ul>
<li><a href="index.html">Home</a></li>
<li><a href="java-tutorial.html">Java</a></li>
<li><a href="keras.html" class="selected">Keras</a></li>
<li><a href="javascript-tutorial.html">JavaScript</a></li>
<li><a href="bootstrap-tutorial.html">Bootstrap</a></li>
<li><a href="c-programming-language-tutorial.html">C</a></li>
<li><a href="html-tutorial.html">HTML</a></li>
<li><a href="xhtml-tutorial.html">XHTML</a></li>
<li><a href="css-tutorial.html">CSS</a></li>
<li><a href="jquery-tutorial.html">jQuery</a></li>
<li><a href="xml-tutorial.html">XML</a></li>
<li><a href="json-tutorial.html">JSON</a></li>
<li><a href="comment.html">Comment</a></li>
<li><a href="forum.html">Forum</a></li>
<li><a href="training.html">Training</a></li>
</ul>
<br style="clear: left" />
</div></div>
<div class="mobilemenu" style="clear:both">

<ins class="adPushupAds" data-adpControl="hqdgs" data-ver="2" data-siteId="37780" data-ac="PHNjcmlwdCBhc3luYyBzcmM9Ii8vcGFnZWFkMi5nb29nbGVzeW5kaWNhdGlvbi5jb20vcGFnZWFkL2pzL2Fkc2J5Z29vZ2xlLmpzIj48L3NjcmlwdD4KPCEtLSBDbV8zMDB4MjUwX01vYl8xNC85IC0tPgo8aW5zIGNsYXNzPSJhZHNieWdvb2dsZSIKICAgICBzdHlsZT0iZGlzcGxheTppbmxpbmUtYmxvY2s7d2lkdGg6MzAwcHg7aGVpZ2h0OjI1MHB4IgogICAgIGRhdGEtYWQtY2xpZW50PSJjYS1wdWItNDY5OTg1ODU0OTAyMzM4MiIKICAgICBkYXRhLWFkLXNsb3Q9IjcwMTQyNzI1MTkiPjwvaW5zPgo8c2NyaXB0PgooYWRzYnlnb29nbGUgPSB3aW5kb3cuYWRzYnlnb29nbGUgfHwgW10pLnB1c2goe30pOwo8L3NjcmlwdD4="></ins><script data-cfasync="false" type="text/javascript">(function (w, d) { for (var i = 0, j = d.getElementsByTagName("ins"), k = j[i]; i < j.length; k = j[++i]){ if(k.className == "adPushupAds" && k.getAttribute("data-push") != "1") { ((w.adpushup = w.adpushup || {}).control = (w.adpushup.control || [])).push(k); k.setAttribute("data-push", "1");} } })(window, document);</script>
</div>
<div id="menu">
<div class="leftmenu2">
<h2 class="spanh2"><span class="spanh2">Keras Tutorial</span></h2>
</div>
<div class="leftmenu">
<a href="keras.html">Keras Tutorial</a>
<a href="https://www.javatpoint.com/installation-of-keras-library-in-anaconda">Installation of Keras library in Anaconda</a>
<a href="keras-backends.html">Keras Backends</a>
<a href="keras-models.html">Keras Models</a>
<a href="keras-layers.html">Keras layers</a>
</div>
<div class="leftmenu2">
<h2 class="spanh2"><span class="spanh2">Keras Models</span></h2>
</div>
<div class="leftmenu">
<a href="keras-the-model-class.html">Keras Model class</a>
<a href="keras-sequential-class.html">Keras Sequential class</a>
</div>
<div class="leftmenu2">
<h2 class="spanh2"><span class="spanh2">Keras Layers</span></h2>
</div>
<div class="leftmenu">
<a href="keras-core-layers.html">Keras Core Layers</a>
<a href="keras-convolutional-layers.html">Convolutional Layer</a>
<a href="pooling-layers.html">Pooling Layers</a>
<a href="keras-locally-connected-layers.html">Locally-Connected layers</a>
<a href="keras-recurrent-layers.html">Recurrent Layers</a>
<a href="keras-embedding.html">Embedding Layers</a>
<a href="keras-merge-layers.html">Keras Merge Layers</a>
</div>
<div class="leftmenu2">
<h2 class="spanh2"><span class="spanh2">Deep Learning Library</span></h2>
</div>
<div class="leftmenu">
<a href="deep-learning.html">Deep Learning</a>
<a href="https://www.javatpoint.com/keras-artificial-neural-networks">Artificial Neural Network</a>
<a href="keras-convolutional-neural-network.html">Convolutional Neural Network</a>
<a href="keras-recurrent-neural-networks.html">Recurrent Neural Network</a>
<a href="keras-kohonen-self-organizing-maps.html">Self-Organizing Maps</a>
<a href="keras-mega-case-study.html">Mega Case Study</a>
<a href="keras-restricted-boltzmann-machine.html">Restricted Boltzmann Machine</a>
</div>
<img src="wh.jpg" alt="JavaTpoint" />
<br />
<div id="leftad" style="margin-left:20px">

<div id="17c09743-0b89-427c-ba64-e09f6a1745a2" class="_ap_apex_ad">
<script>
		var adpushup = window.adpushup = window.adpushup || {};
		adpushup.que = adpushup.que || [];
		adpushup.que.push(function() {
			adpushup.triggerAd("17c09743-0b89-427c-ba64-e09f6a1745a2");
		});
	</script>
</div>
</div>
</div>
<div class="onlycontent">

<div class="onlycontentad">
<div id="9bbcb75d-b5e2-40e1-a811-e7680d1f59a4" class="_ap_apex_ad">
<script>
		var adpushup = window.adpushup = window.adpushup || {};
		adpushup.que = adpushup.que || [];
		adpushup.que.push(function() {
			adpushup.triggerAd("9bbcb75d-b5e2-40e1-a811-e7680d1f59a4");
		});
	</script>
</div>
</div>
<div class="onlycontentinner">
<div id="city">
<table>
<tr><td>
<div id="bottomnextup">
<a class="next" href="keras-recurrent-neural-networks.html">next &rarr;</a>
<a class="next" href="https://www.javatpoint.com/keras-artificial-neural-networks">&larr; prev</a>
</div>
<h1 class="h1">Convolutional Neural Network</h1>
<p>Convolutional Neural Networks are a special type of feed-forward artificial neural network in which the connectivity pattern between its neuron is inspired by the visual cortex.</p>
<img src="https://static.javatpoint.com/tutorial/keras/images/convolutional-neural-network.png" alt="Convolutional Neural Network" />
<p>The visual cortex encompasses a small region of cells that are region sensitive to visual fields. In case some certain orientation edges are present then only some individual neuronal cells get fired inside the brain such as some neurons responds as and when they get exposed to the vertical edges, however some responds when they are shown to horizontal or diagonal edges, which is nothing but the motivation behind Convolutional Neural Networks.</p>
<p>The Convolutional Neural Networks, which are also called as covnets, are nothing but neural networks, sharing their parameters. Suppose that there is an image, which is embodied as a cuboid, such that it encompasses length, width, and height. Here the dimensions of the image are represented by the Red, Green, and Blue channels, as shown in the image given below.</p>
<img src="https://static.javatpoint.com/tutorial/keras/images/convolutional-neural-network2.png" alt="Convolutional Neural Network" />
<p>Now assume that we have taken a small patch of the same image, followed by running a small neural network on it, having k number of outputs, which is represented in a vertical manner. Now when we slide our small neural network all over the image, it will result in another image constituting different width, height as well as depth. We will notice that rather than having R, G, B channels, we have come across some more channels that, too, with less width and height, which is actually the concept of Convolution. In case, if we accomplished in having similar patch size as that of the image, then it would have been a regular neural network. We have some wights due to this small patch.</p>
<img src="https://static.javatpoint.com/tutorial/keras/images/convolutional-neural-network3.png" alt="Convolutional Neural Network" />
<p>Mathematically it could be understood as follows;</p>
<ul class="points">
<li>The Convolutional layers encompass a set of learnable filters, such that each filter embraces small width, height as well as depth as that of the provided input volume (if the image is the input layer then probably it would be 3).</li>
<li>Suppose that we want to run the convolution over the image that comprises of 34x34x3 dimension, such that the size of a filter can be axax3. Here a can be any of the above 3, 5, 7, etc. It must be small in comparison to the dimension of the image.</li>
<li>Each filter gets slide all over the input volume during the forward pass. It slides step by step, calling each individual step as a stride that encompasses a value of 2 or 3 or 4 for higher-dimensional images, followed by calculating a dot product in between filter's weights and patch from input volume.</li>
<li>It will result in 2-Dimensional output for each filter as and when we slide our filters followed by stacking them together so as to achieve an output volume to have a similar depth value as that of the number of filters. And then, the network will learn all the filters.</li>
</ul>
<h2 class="h2">Working of CNN</h2>
<p>Generally, a Convolutional Neural Network has three layers, which are as follows;</p>
<ul class="points">
<li><strong>Input:</strong> If the image consists of 32 widths, 32 height encompassing three R, G, B channels, then it will hold the raw pixel([32x32x3]) values of an image.</li>
<li><strong>Convolution:</strong> It computes the output of those neurons, which are associated with input's local regions, such that each neuron will calculate a dot product in between weights and a small region to which they are actually linked to in the input volume. For example, if we choose to incorporate 12 filters, then it will result in a volume of [32x32x12].</li>
<li><strong>ReLU Layer:</strong> It is specially used to apply an activation function elementwise, like as max (0, x) thresholding at zero. It results in ([32x32x12]), which relates to an unchanged size of the volume.</li>
<li><strong>Pooling:</strong> This layer is used to perform a downsampling operation along the spatial dimensions (width, height) that results in [16x16x12] volume.<br>
<img src="https://static.javatpoint.com/tutorial/keras/images/convolutional-neural-network4.png" alt="Convolutional Neural Network" /></li>
<li><strong>Locally Connected:</strong> It can be defined as a regular neural network layer that receives an input from the preceding layer followed by computing the class scores and results in a 1-Dimensional array that has the equal size to that of the number of classes.<br>
<img src="https://static.javatpoint.com/tutorial/keras/images/convolutional-neural-network5.png" alt="Convolutional Neural Network" /></li>
</ul>
<p>We will start with an input image to which we will be applying multiple feature detectors, which are also called as filters to create the feature maps that comprises of a Convolution layer. Then on the top of that layer, we will be applying the ReLU or Rectified Linear Unit to remove any linearity or increase non-linearity in our images.</p>
<p>Next, we will apply a Pooling layer to our Convolutional layer, so that from every feature map we create a Pooled feature map as the main purpose of the pooling layer is to make sure that we have spatial invariance in our images. It also helps to reduce the size of our images as well as avoid any kind of overfitting of our data. After that, we will flatten all of our pooled images into one long vector or column of all of these values, followed by inputting these values into our artificial neural network. Lastly, we will feed it into the locally connected layer to achieve the final output.</p>
<img src="https://static.javatpoint.com/tutorial/keras/images/convolutional-neural-network6.png" alt="Convolutional Neural Network" />
<h2 class="h2">Building a CNN</h2>
<p>Basically, a Convolutional Neural Network consists of adding an extra layer, which is called convolutional that gives an eye to the Artificial Intelligence or Deep Learning model because with the help of it we can easily take a 3D frame or image as an input as opposed to our previous artificial neural network that could only take an input vector containing some features as information.</p>
<p>But here we are going to add at the front a convolutional layer which will be able to visualize images just like humans do.</p>
<p>In our dataset, we have all the images of cats and dogs in training as well as in the test set folders. We are going to train our CNN model on 4000 images of cats as well as 4000 images of dogs, each respectively that are present in the training set followed by evaluating our model with the new 1000 images of cats and 1000 images of dogs, each respectively in the test set on which our model was not trained. So, we are actually going to build and train a Convolutional Neural network to recognize if there is a dog or cat in the image.</p>
<p>For the implementation of CNN, we are going to use the <a href="jupyter-notebook.html">Jupyter notebook</a>. So, we will start with importing the libraries, data preprocessing followed by building a CNN, training the CNN and lastly, we will make a single prediction. All the steps will be carried out in the same way as we did in ANN, the only difference is that now we are not pre-processing the classic dataset, but some images, which is why the data preprocessing is different and will consist of doing two steps, i.e., in the first, we will pre-process the training set and then will pre-process the test set.</p>
<p>In the second part, we will build the whole architecture of CNN. We will initialize the CNN as a sequence of layers, and then we will add the convolution layer followed by adding the max-pooling layer. Then we will add the second convolutional layer to make it a deep neural network as opposed to a shallow neural network. Next, we will proceed to the flattening layer to flatten the result of all the convolutions and pooling into a one-dimensional vector, which will become the input of a fully connected neural network. Finally, we will connect all this to the output layer.</p>
<p>In the third part, we will first compile the CNN, and then we will train the <a href="convolutional-neural-network-in-tensorflow.html">CNN</a> on the training set. And then, finally, we will make a single prediction to test our model in a prediction that is when we will deploy our CNN on to different images, one that has a dog and the other that has a cat.</p>
<p>So, this was just a brief description of how we will build our CNN model, let's get started with its practical implementation.</p>
<p>We will start by importing the <a href="tensorflow.html">TensorFlow</a> library and actually the preprocessing module by Keras library. And then, we will import the image sub-module of the preprocessing module of the Keras library, which will allow us to do image pre-processing in part 1.</p>
<div class="codeblock"><textarea name="code" class="java">
import tensorflow as tf
from keras.preprocessing.image import ImageDataGenerator
</textarea></div>
<p><strong>Output</strong></p>
<img src="https://static.javatpoint.com/tutorial/keras/images/convolutional-neural-network7.png" alt="Convolutional Neural Network" />
<p>It can be seen that we have successfully run our first cell from the image given above. Using TensorFlow backend, which is the output of the first cell, and in order for this to work this way, we have to make sure to run pip install commands of TensorFlow and <a href="keras.html">Keras</a>.</p>
<p>Next, we will check the version of the TensorFlow.</p>
<div class="codeblock"><textarea name="code" class="java">
tf.__version__
</textarea></div>
<p><strong>Output</strong></p>
<img src="https://static.javatpoint.com/tutorial/keras/images/convolutional-neural-network8.png" alt="Convolutional Neural Network" />
<p>It can be seen that the version of TensorFlow is 2.0.0.</p>
<p>After this, we will move on to Part1: Data Pre-processing, which will be done in two steps, i.e., firstly, we will preprocess the training set, and secondly, we will preprocess the test set.</p>
<h3 class="h3">Part1: Data Pre-processing</h3>
<p><strong>Preprocessing the Training set</strong></p>
<p>We will apply some transformations on all the images of the training set but not on the images of the test set, so as to avoid overfitting. Indeed, if we don't apply these transformations while training our CNN on the training set, we will get a huge difference between the accuracy on the training set and the one on the test set.</p>
<p>For the computer vision, the way to avoid overfitting is to apply the transformations, which are nothing but a simple geometrical transformation or some zoom or some rotations on the images. So, basically, we are going to apply some geometrical transformations to shift some of the pixels followed by rotating a bit the images, we will be doing some horizontal flips, zoom in as well as zoom out. We are actually going to apply some series of transformations to modify the images and get them augmented, which is called image augmentation. It actually consists of transforming the images of the training set so that our CNN model doesn't overlearn.</p>
<p>We will create an object of <strong>train_datagen</strong> of the <strong>ImageDataGenerator</strong> class that represents the tool that will apply all the transformations on the images of the training set, such that the <strong>rescale</strong> argument will apply feature scaling to each and every single one the pixel by dividing their value 255 as each pixel take a value between 0 and 255, which is really necessary for neural networks and the rest are the transformations that will perform image augmentation on the training set images so as to prevent the overfitting.</p>
<div class="codeblock"><textarea name="code" class="java">
train_datagen = ImageDataGenerator(rescale = 1./255,
                                   shear_range = 0.2,
                                   zoom_range = 0.2,
                                   horizontal_flip = True)
</textarea></div>
<p>After this, we will need to connect the <strong>train_datagen</strong> object to the training set, and to do this, we will have to import the training set, which can be done as given below. Here <strong>training_set</strong> is the name of the training set that we are importing in the notebook, and then we indeed take our <strong>train_datagen</strong> object so as to call the method of <strong>ImageDataGenerator</strong> class. The method that we will call is the <strong>flow_from_directory</strong> that will help to connect the image augmentation tool to the image of the training set. we will pass the following parameter;</p>
<ul class="points">
<li>The first parameter is the path leading to the training set.</li>
<li>The next parameter is the target_size, which is the final size of the images when they will be fed into the convolutional neural network.</li>
<li>The third one is the batch_size, which relates to the size of the batches, i.e., the total number of images we want to have in each batch. We have chosen 32, which is the classic default value.</li>
<li>Lastly, we will classify the class mode to be either binary or categorical. Since we are looking for a binary outcome, so will choose binary class mode.</li>
</ul>
<div class="codeblock"><textarea name="code" class="java">
training_set = train_datagen.flow_from_directory('dataset/training_set',
                                                 target_size = (64, 64),
                                                 batch_size = 32,
                                                 class_mode = 'binary')
</textarea></div>
<p><strong>Output</strong></p>
<img src="https://static.javatpoint.com/tutorial/keras/images/convolutional-neural-network9.png" alt="Convolutional Neural Network" />
<p>After running the above cell, which is Preprocessing the Training Set, we will get in the output from the above image that indeed we imported and preprocessed with the data augmentation; 8000 images belonging to 2 classes, i.e., dogs and cats.</p>
<p><strong>Preprocessing the Test set</strong></p>
<p>After we are done with preprocessing the training set, we will further move on to preprocessing the test set. We will again take the ImageDataGenerator object to apply transformations to the test images, but here we will not apply the same transformations as we did in the previous step. However, we need to rescale their pixels the same as before because the future predict method of CNN will have to be applied to the same scaling as the one that was applied to the training set.</p>
<div class="codeblock"><textarea name="code" class="java">
test_datagen = ImageDataGenerator(rescale = 1./255)
</textarea></div>
<p>Here <strong>test_set</strong> is the name of the test set that we are importing in the notebook, and then we indeed take our <strong>test_datagen</strong>, which will only apply if it is going to the pixels of the test set images. Then we call the same <strong>flow_from_directory</strong> function to access the test set from the directory. Then we will need to have the same target_size, batch_size, and class_mode as used in the previous step.</p>
<div class="codeblock"><textarea name="code" class="java">
test_set = test_datagen.flow_from_directory('dataset/test_set',
                                            target_size = (64, 64),
                                            batch_size = 32,
                                            class_mode = 'binary')
</textarea></div>
<p><strong>Output</strong></p>
<img src="https://static.javatpoint.com/tutorial/keras/images/convolutional-neural-network10.png" alt="Convolutional Neural Network" />
<p>We can see from the above image, which we got after running Preprocessing the Test Set cell, that 2000 images belong to 2 classes. Instead of applying image augmentation, we have only applied feature scaling.</p>
<h3 class="h3">Part2: Building the CNN</h3>
<p>In part two, we are going to build together the convolutional neural network and, more specifically, the whole architecture of the artificial neural network. So, it is actually going to start the same as with our artificial neural network because the convolutional neural network is still a sequence of layers.</p>
<p>Therefore, we are going to initialize our CNN with the same class, which is the sequential class.</p>
<p><strong>Initializing the CNN</strong></p>
<p>So, this is the first step where we are not only going to call the sequential class but will actually create the cnn variable, which will represent this convolutional neural network. And this <strong>cnn</strong> variable will be created once again as an instance of that sequential class allows us to create an artificial neural network as a sequence of layers.</p>
<p>First, we will need to call the TensorFlow that has a shortcut <strong>tf</strong> from which we are going to call Keras library from where we are going to get access to the model's module, or we can say from where we are going to call that sequential class.</p>
<div class="codeblock"><textarea name="code" class="java">
cnn = tf.keras.models.Sequential()
</textarea></div>
<p>After this, we will step by step use the add method to add different layers, whether they are convolutional layers or fully connected layers, and in the end, the output layer. So, we are now going to successfully use the add method starting with the step1: convolution.</p>
<p><strong>Step1: Convolution</strong></p>
<p>We will first take the <strong>cnn</strong> object or the convolutional neural network from which we will call the add method to add our very first convolutional layer, which will further be an object of a certain class, i.e., <strong>Conv2D</strong> class. And this class, just like the dense class that allows us to build a fully connected layer, belongs to the same module, which is the layer module from the Keras library, but this time it is the TensorFlow.</p>
<p>Inside the class, we are going to pass three important parameters, which are as follows:</p>
<ul class="points">
<li>The first parameter is the <strong>filters</strong>, which is the number of feature detectors that we want to apply to images for feature detection.</li>
<li>The <strong>kernel_size</strong> is exactly the size of the feature detector, i.e., the number of rows, which is also the number of columns.</li>
<li>The third one is the <strong>activation</strong> but here we are not going to keep the default value for the activation parameter corresponding to the activation function, because indeed as long as we don't reach the output layer, we rather want to get a rectifier activation function. That is why we will choose the <strong>ReLU</strong> parameter name once again as it corresponds to the rectifier activation function.</li>
<li>Lastly, the <strong>input_shape</strong> parameter because it is necessary to specify the input shape of inputs. Since we are working with the colored images, so the input_shape will be [64, 64, 3].</li>
</ul>
<div class="codeblock"><textarea name="code" class="java">
cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))
</textarea></div>
<p><strong>Step2: Pooling</strong></p>
<p>Next, we will move on to applying pooling, and more specifically, if we talk about, we are going to apply the max pooling, and for that, we will again take cnn object from which we are going to call our new method. Since we are adding the pooling layer to our convolutional layer, so we will again call the add method, and inside it, we will create an object of a max-pooling layer or an instance of a certain class, which is called <strong>MaxPool2D</strong> class. Inside the class, we will <strong>pass pool_size</strong> and <strong>strides</strong> parameters.</p>
<div class="codeblock"><textarea name="code" class="java">
cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))
</textarea></div>
<p><strong>Adding a second layer</strong></p>
<p>Now we will add our second layer, for which again we have to undergo applying convolutional as well as pooling layer just like we did in the previous step, but here will need to change the <strong>input_shape</strong> parameter because it is entered only when we add our very first layer to automatically connect that first layer to the input layer, which automatically adds the input layer.</p>
<p>Since we are already here adding the second convolution layer, so we can simply remove that parameter. So, we are all set to move on to step3.</p>
<div class="codeblock"><textarea name="code" class="java">
cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))
cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))
</textarea></div>
<p><strong>Step3: Flattening</strong></p>
<p>In the third step, we will undergo flattening the result of these convolutions and pooling into a one-dimensional vector, which will become the input of a fully connected layer neural network in a similar way as we did in the previous section. We will start with again taking our <strong>cnn</strong> object from which we will call the <strong>add</strong> method because the way we are going to create that flattening layer is once again by creating an instance of the <strong>Flatten</strong> class, such that Keras will automatically understand that this is the result of all these convolutions and pooling, which will be flattened into the one-dimensional vector.</p>
<p>So, we just need to specify that we want to apply flattening and to do this we will have to call once again the layers module by the Keras library by TensorFlow from which we are actually going to call the flatten class, and we don't need to pass any kind of parameter inside it.</p>
<div class="codeblock"><textarea name="code" class="java">
cnn.add(tf.keras.layers.Flatten())
</textarea></div>
<p><strong>Step4: Full Conversion</strong></p>
<p>In step 4, we are exactly in the same situation as before building a fully connected neural network. So, we will be adding a new fully-connected layer to that flatten layer, which is nothing but a one-dimensional vector that will become the input of a fully connected neural network. And for this, we will again start by taking a <strong>cnn</strong> neural network from which we are going to call the <strong>add</strong> method because now we are about to add a new layer, which is a fully connected layer that belongs to <strong>tf.keras.layers</strong>. But this time, we will take <strong>a Dense</strong> class followed by passing <strong>units</strong>, which is the number of hidden neurons we want to have into this fully connected layer and <strong>activation function</strong> parameter.</p>
<div class="codeblock"><textarea name="code" class="java">
cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))
</textarea></div>
<p><strong>Step5: Output Layer</strong></p>
<p>Here we need to add the final output layer, which will be fully connected to the previous hidden layer. Therefore, we will call the Dense class once again in the same way as we did in the previous step but will change the value of the input parameters because the numbers of units in the output layer are definitely not 128. Since we are doing binary classification, it will actually be one neuron to encode that binary class into a 'cat' or 'dog'. And for the activation layer, it is recommended to have a sigmoid activation function. Otherwise, if we were doing multiclass classification, we would have used the SoftMax activation function.</p>
<div class="codeblock"><textarea name="code" class="java">
cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))
</textarea></div>
<h3 class="h3">Part3: Training the CNN</h3>
<p>In the previous steps, we built the brain the, which contained in the eyes of the Artificial Intelligence and now we are going to make that brain smart with the training of CNN on all our training set images, and at the same time, we will evaluate our same model on the test set over the epochs. Now we are going to train our CNN over 25 epochs, and at each epoch, we will actually see how our model is performing on our test set images. This is a different kind of training as we did before because we always used to separate the training and evaluation, but here this will happen at the same time as we are making some specific application, i.e., computer vision.</p>
<p><strong>Compiling the CNN</strong></p>
<p>Now we are going to compile the CNN, which means that we are going to connect it to an optimizer, a loss function, and some metrics. As we are doing once again a binary classification, so we are going to compile our CNN exactly the same way as we complied our ANN model because indeed, we are going to choose once again <strong>adam</strong> optimizer to perform stochastic gradient descent to update the weights in order to reduce the loss error between the predictions and target. Then we will choose the same loss, i.e., the <strong>binary_crossentrophy</strong> loss because we are doing exactly the same task binary classification. And then same for the metrics, we will choose <strong>accuracy</strong> metrics because it is the most relevant way to measure the performance of the classification model, which is exactly our case of CNN.</p>
<p>So, we will take our cnn from which we will be calling the compile method that will take as input the optimizer, loss function, and the metrics.</p>
<div class="codeblock"><textarea name="code" class="java">
cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])
</textarea></div>
<p><strong>Training the CNN on the Training set and evaluation on the Test set</strong></p>
<p>After the compilation, we will train the CNN on the training set followed by evaluating at the same time on the test set, which will not be exactly the same as before but will be somewhat similar. Basically, the first two steps are always the same, i.e., in the first step, we will take cnn followed by taking the fit method in the second step that will train the cnn on the training set. Inside it, we will pass the following parameters:</p>
<ul class="points">
<li>The first parameter is the set, which is off course the dataset (<strong>training set</strong>) on which we are going to train our model, and the name for that parameter is simply X, created in part1.</li>
<li>The second parameter is the difference with what we did before. So, it has to do, of course with the fact that we are not only training the CNN on the training set but also evaluating it at the same time on the test set. And that is what exactly our second parameter corresponds to, so we will be specifying here the <strong>validation data</strong> (test set), which is the set on which we want to evaluate our CNN.</li>
<li>Lastly, the epochs parameter, which is the number of epochs. Here we are choosing 25 epochs to converge the accuracy not only on the training set but also on the test set.</li>
</ul>
<div class="codeblock"><textarea name="code" class="java">
cnn.fit(x = training_set, validation_data = test_set, epochs = 25)
</textarea></div>
<p><strong>Output</strong></p>
<img src="https://static.javatpoint.com/tutorial/keras/images/convolutional-neural-network11.png" alt="Convolutional Neural Network" />
<p>From the image given above, it can be seen that we ended with <strong>90%</strong> of final accuracy on the training set and final accuracy of <strong>80.50%</strong>on the test set. Let's remind it again that if we had not done image augmentation preprocessing in part1, we would have ended up with an accuracy of around <strong>98%</strong> or even <strong>99%</strong> on the training set, which clearly indicates <strong>overfitting</strong> and lower accuracy here on the test set around <strong>70%</strong>. This is the reason why we insisted image augmentation is absolutely fundamental.</p>
<h3 class="h3">Part4: Making a single prediction</h3>
<p>In part4, we will make a single prediction, which actually consists of deploying our model on the two separate images of this single prediction folder for which our model will have to recognize for both the dog and cat, respectively. So, basically, we will deploy our CNN model on each of these single images, and we will hope that our CNN successfully predicts a dog as well as a cat. And for this, we will start with importing <strong><a href="numpy-tutorial.html">NumPy</a></strong>. Next, we will import a new module that we actually imported earlier, i.e., we imported the <strong>ImageDataGenerator</strong> from the image submodule of the preprocessing module of the <strong>Keras</strong> library. And in fact, what we are going to import now is that image module. But because we specifically imported something specific from that module, well, we need to import it again.</p>
<p>So, we will start with <strong>Keras</strong>, which we will help us to get access to the preprocessing module from which we will further import that image module. The next is, of course, to load that single image on which we want to deploy our model to predict if there is a cat or dog inside. We will create a new variable, i.e., the <strong>test_set</strong> that will be initialized with loading the image on which we want to test out model from the same single prediction folder. It can be done by first calling the <strong>image</strong> submodule from which we will call the <strong>load_img</strong> function, and inside this function, we will simply pass two arguments, i.e., the first parameter is the <strong>path</strong> specifying that particular image we want to select which will actually lead us to the test_set image variable and the second one plays a vital role as it relates to the image which will become the input of the predict method has to have the same size as the one that was used during the training.</p>
<p>Since we actually resized our images into the size target of (64, 64), whether it was for the training set or test set and we also specify it again while building the CNN with the same input shape, so the size of the image we are going to work with either for training the CNN or calling the predict method has to be (64, 64). So, in order to specify it here, we will enter our second parameter, which is the <strong>target_size.</strong></p>
<div class="codeblock"><textarea name="code" class="java">
import numpy as np
from keras.preprocessing import image
test_image = image.load_img('dataset/single_prediction/cat_or_dog_1.jpg', target_size = (64, 64))
</textarea></div>
<p>But to make our first test _set image accepted by the predict method, we need to convert the format of an image into an array because the predict method expects its input to be a 2D array. And we will do this with the help of another function of the image preprocessing module, i.e., <strong>img_to_array</strong> function, which indeed converts <strong>PIL image</strong> instance into a <strong>NumPy array</strong> that is exactly the format of array expected by the predict method. We will again use our image submodule from which we will call <strong>img_to_array()</strong>, and inside, it will take the test_size image in PIL format that we are looking forward to convert it into the NumPy array format.</p>
<div class="codeblock"><textarea name="code" class="java">
test_image = image.img_to_array(test_image)
</textarea></div>
<p>Since the predict method has to be called on the exact same format that was used during the training, so if we go back into the preprocessing phase of both training set as well as the test set, we created batches of images. Therefore, our CNN was not trained in any single image; rather, it was trained on the batches of images. So, as we have an extra dimension of batch and we are about to deploy our model on a single image, then that single image still has to be into the batch even if we are going to have one image in the batch, it has to be into this batch so that the predict method of our CNN model can recognize the batch as that extra dimension.</p>
<p>Next, we will add an extra dimension, which will correspond to the batch that will contain that image into the batch, and it can be simply done by updating our test image by adding extra dimensions corresponding to batch. And the way to do it is with <strong>NumPy</strong> as the NumPy arrays can be easily manipulated, so we will first call the NumPy from which we will call this function that allows exactly to add a fake dimension, or we can say a dimension corresponding to the batch, which is called <strong>expand_dims</strong> function inside of which we will input the image to which we want to add this extra dimension corresponding to the batch followed by adding an extra argument, i.e., where we want to add that extra dimension such that the dimension of the batch is always the first dimension to which we always give our first batch of images, and then inside of each batch we get the different images. So, it seems natural to have the batch as the first dimension and to specify this is exactly what we need to enter as a second argument, which is <strong>an axis</strong> that we have to set equal to zero. That is why the dimension of a batch that we want to add to our image will be the first dimension.</p>
<div class="codeblock"><textarea name="code" class="java">
test_image = np.expand_dims(test_image, axis = 0)
</textarea></div>
<p>After this, we can call the predict method because, indeed, that test set image, which is not only in the right NumPy array but also which has the extra dimension corresponding to the batch, has exactly the right format expected by the predict method.</p>
<p>Therefore, we can create a new variable which will call result as it will actually predict our CNN model with the test image. Here we are not calling it prediction because it will only return or zero or one, which is why we are required to encode so as to represent 0 relates to cat and 1 is a dog. So, we will call our first result variable, which will actually be the output of the predict method called from our CNN. Inside the predict method, we will pass the <strong>test_image</strong>, which now has the right format expected by that predict method.</p>
<div class="codeblock"><textarea name="code" class="java">
result = cnn.predict(test_image)
</textarea></div>
<p>To figure out in between what relates to 0 and what narrates about 1, we will call either the <strong>training_set</strong> or <strong>test_set</strong> and then from which we will further call <strong>class_indices</strong>, such that by printing this, we will get the right class_indices. And with this, we indeed get that dog corresponds to 1 and cat relates to 0.</p>
<div class="codeblock"><textarea name="code" class="java">
training_set.class_indices
</textarea></div>
<p>In the end, when the two single predictions are made on these two single images, we will finish it with the if condition. Since we already know that result contains the outcome in batches because it was called on a test image that was into a batch, so results also have a batch dimension, and we are going to get access to the batch.</p>
<p>After this, inside the batch, we are going to get access to the first element of the batch that corresponds to the prediction of that same <strong>cat_or_dog_1</strong> image. As we are dealing with a single image, so a single prediction is needed, and to get that, we will need to get inside the batch of index zero, the first and only prediction once again, which has a [0] index. So, that is how we get our prediction by first accessing the batch followed by accessing the single element of the batch, and if that prediction equals to one, then we already know that it corresponds to the dog, then we will create a new variable which we will call as prediction and will set that prediction variable equals to the dog. Likewise, in the else condition, if the result prediction equals to 1, then the prediction will be a cat. Now we will wrap it up by simply printing the prediction.</p>
<div class="codeblock"><textarea name="code" class="java">
if result[0][0] == 1:
  prediction = 'dog'
else:
  prediction = 'cat'

print(prediction)
</textarea></div>
<p><strong>Output</strong></p>
<img src="https://static.javatpoint.com/tutorial/keras/images/convolutional-neural-network12.png" alt="Convolutional Neural Network" />
<p>We can see our Convolution Neural Network predicted that there is a dog inside the image. So, it can be concluded that our first test is passed successfully.</p>
<p>Now we will check for the other image which is of the cat, so for that we will need to deploy our model on this single image and check that indeed, our CNN returns a cat. To do this, we need to change the name here, i.e. <strong>cat_or_dog_2.jpg</strong> and then play this cell again by clicking on the Run button.</p>
<div class="codeblock"><textarea name="code" class="java">
import numpy as np
from keras.preprocessing import image
test_image = image.load_img('dataset/single_prediction/cat_or_dog_2.jpg', target_size = (64, 64))
test_image = image.img_to_array(test_image)
test_image = np.expand_dims(test_image, axis = 0)
result = cnn.predict(test_image)
training_set.class_indices
if result[0][0] == 1:
  prediction = 'dog'
else:
  prediction = 'cat'

print(prediction)
</textarea></div>
<p><strong>Output</strong></p>
<img src="https://static.javatpoint.com/tutorial/keras/images/convolutional-neural-network13.png" alt="Convolutional Neural Network" />
<p>So, it's clear now that our CNN model is successful in predicting cat in the output of the console. Hence our CNN got all the answers correct.</p>
<hr />
<div class="nexttopicdiv">
<span class="nexttopictext">Next Topic</span><span class="nexttopiclink"><a href="keras-recurrent-neural-networks.html">Recurrent Neural Networks</a></span>
</div>

<br /><br />
<div id="bottomnext">
<a style="float:left" class="next" href="https://www.javatpoint.com/keras-artificial-neural-networks">&larr; prev</a>
<a style="float:right" class="next" href="keras-recurrent-neural-networks.html">next &rarr;</a>
</div>
<br /><br />
</td></tr>
</table>
</div>
<hr class="hrhomebox" />
<div><img class="lazyload" data-src="https://static.javatpoint.com/images/youtube-32.png" style="vertical-align:middle;" alt="Youtube" />
<span class="h3" style="vertical-align:middle;font-size:22px"> For Videos Join Our Youtube Channel: <a href="https://bit.ly/2FOeX6S" target="_blank"> Join Now</a></span>
</div>
<hr class="hrhomebox" />
<h3 class="h3">Feedback</h3>
<ul class="points">
<li>Send your Feedback to <a href="cdn-cgi/l/email-protection.html" class="__cf_email__" data-cfemail="e0868585848281838ba08a81968194908f898e94ce838f8d">[email&#160;protected]</a></li>
</ul>
<hr class="hrhomebox" />
<h2 class="h2">Help Others, Please Share</h2>
<a rel="nofollow" title="Facebook" target="_blank" href="https://www.facebook.com/sharer.php?u=https://www.javatpoint.com/keras-convolutional-neural-network"><img src="images/facebook32.png" alt="facebook" /></a>
<a rel="nofollow" title="Twitter" target="_blank" href="https://twitter.com/share?url=https://www.javatpoint.com/keras-convolutional-neural-network"><img src="images/twitter32.png" alt="twitter" /></a>
<a rel="nofollow" title="Pinterest" target="_blank" href="https://www.pinterest.com/pin/create/button/?url=https://www.javatpoint.com/keras-convolutional-neural-network"><img src="images/pinterest32.png" alt="pinterest" /></a>


<script data-cfasync="false" src="cdn-cgi/scripts/5c5dd728/cloudflare-static/email-decode.min.js"></script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-4699858549023382" data-ad-slot="5022809933" data-ad-format="auto" data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
<hr class="hrhomebox" />

<fieldset class="gra1">
<h2 class="h3">Learn Latest Tutorials</h2>
<div class="firsthomecontent">
<a href="splunk.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/splunk.png" alt="Splunk tutorial" />
<p>Splunk</p>
</div>
</a>
<a href="spss.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/spss.png" alt="SPSS tutorial" />
<p>SPSS</p>
</div>
</a>
<a href="swagger.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/swagger.png" alt="Swagger tutorial" />
<p>Swagger</p>
</div>
</a>
<a href="t-sql.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/transact-sql.png" alt="T-SQL tutorial" />
<p>Transact-SQL</p>
</div>
</a>
<a href="tumblr.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/tumblr.png" alt="Tumblr tutorial" />
<p>Tumblr</p>
</div>
</a>
<a href="reactjs-tutorial.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/react.png" alt="React tutorial" />
<p>ReactJS</p>
</div>
</a>
<a href="regex.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/regex.png" alt="Regex tutorial" />
<p>Regex</p>
</div>
</a>
<a href="reinforcement-learning.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/react.png" alt="Reinforcement learning tutorial" />
<p>Reinforcement Learning</p>
</div>
</a>
<a href="r-tutorial.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/r-programming.png" alt="R Programming tutorial" />
<p>R Programming</p>
</div>
</a>
<a href="rxjs.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/rxjs.png" alt="RxJS tutorial" />
<p>RxJS</p>
</div>
</a>
<a href="react-native-tutorial.html">
 <div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/react-native.png" alt="React Native tutorial" />
<p>React Native</p>
</div>
</a>
<a href="python-design-pattern.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/python-design-patterns.png" alt="Python Design Patterns" />
<p>Python Design Patterns</p>
</div>
</a>
<a href="python-pillow.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/python-pillow.png" alt="Python Pillow tutorial" />
<p>Python Pillow</p>
</div>
</a>
<a href="python-turtle-programming.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/python-turtle.png" alt="Python Turtle tutorial" />
<p>Python Turtle</p>
</div>
</a>
<a href="keras.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/keras.png" alt="Keras tutorial" />
<p>Keras</p>
</div>
</a>
</div>
</fieldset>
<hr class="hrhomebox" />

<fieldset class="gra1">
<h2 class="h3">Preparation</h2>
<div class="firsthomecontent">
<a href="aptitude/quantitative.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/aptitude/images/quantitative-aptitude-home.png" alt="Aptitude" />
<p>Aptitude</p>
</div>
</a>
<a href="reasoning.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/reasoning/images/reasoning-home.png" alt="Logical Reasoning" />
<p>Reasoning</p>
</div>
</a>
<a href="verbal-ability.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/verbal-ability/images/verbal-ability-home.png" alt="Verbal Ability" />
<p>Verbal Ability</p>
</div>
</a>
<a href="interview-questions-and-answers.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/logo/interviewhome.png" alt="Interview Questions" />
<p>Interview Questions</p>
</div>
</a>
<a href="company-interview-questions-and-recruitment-process.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/interview/images/company-home.jpeg" alt="Company Interview Questions" />
<p>Company Questions</p>
</div>
</a>
</div>
</fieldset>
<hr class="hrhomebox" />

<fieldset class="gra1">
<h2 class="h3">Trending Technologies</h2>
<div class="firsthomecontent">
<a href="artificial-intelligence-ai.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/artificial-intelligence.png" alt="Artificial Intelligence" />
<p>Artificial Intelligence</p>
</div>
</a>
<a href="aws-tutorial.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/amazon-web-services.png" alt="AWS Tutorial" />
<p>AWS</p>
</div>
</a>
<a href="selenium-tutorial.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/selenium.png" alt="Selenium tutorial" />
<p>Selenium</p>
</div>
</a>
<a href="cloud-computing.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/cloud-computing.png" alt="Cloud Computing" />
<p>Cloud Computing</p>
</div>
</a>
<a href="hadoop-tutorial.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/hadoop.png" alt="Hadoop tutorial" />
<p>Hadoop</p>
</div>
</a>
<a href="reactjs-tutorial.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/reactjs.png" alt="ReactJS Tutorial" />
<p>ReactJS</p>
</div>
</a>
<a href="data-science.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/data-science.png" alt="Data Science Tutorial" />
<p>Data Science</p>
</div>
</a>
<a href="angular-7-tutorial.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/angular7.png" alt="Angular 7 Tutorial" />
<p>Angular 7</p>
</div>
</a>
<a href="blockchain-tutorial.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/blockchain.png" alt="Blockchain Tutorial" />
<p>Blockchain</p>
</div>
</a>
<a href="git.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/git.png" alt="Git Tutorial" />
<p>Git</p>
</div>
</a>
<a href="machine-learning.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/machine-learning.png" alt="Machine Learning Tutorial" />
<p>Machine Learning</p>
</div>
</a>
<a href="devops.html">
 <div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/devops.png" alt="DevOps Tutorial" />
<p>DevOps</p>
</div>
</a>
</div>
</fieldset>
<hr class="hrhomebox" />

<fieldset class="gra1">
<h2 class="h3">B.Tech / MCA</h2>
<div class="firsthomecontent">
<a href="dbms-tutorial.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/dbms.png" alt="DBMS tutorial" />
<p>DBMS</p>
</div>
</a>
<a href="data-structure-tutorial.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/data-structures.png" alt="Data Structures tutorial" />
<p>Data Structures</p>
</div>
</a>
<a href="daa-tutorial.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/daa.png" alt="DAA tutorial" />
<p>DAA</p>
</div>
</a>
<a href="operating-system.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/operating-system.png" alt="Operating System" />
<p>Operating System</p>
</div>
</a>
<a href="computer-network-tutorial.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/computer-network.png" alt="Computer Network tutorial" />
<p>Computer Network</p>
</div>
</a>
<a href="compiler-tutorial.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/compiler-design.png" alt="Compiler Design tutorial" />
<p>Compiler Design</p>
</div>
</a>
<a href="computer-organization-and-architecture-tutorial.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/computer-organization.png" alt="Computer Organization and Architecture" />
<p>Computer Organization</p>
</div>
</a>
<a href="discrete-mathematics-tutorial.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/discrete-mathematics.png" alt="Discrete Mathematics Tutorial" />
<p>Discrete Mathematics</p>
</div>
</a>
<a href="ethical-hacking.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/ethical-hacking.png" alt="Ethical Hacking" />
<p>Ethical Hacking</p>
</div>
</a>
<a href="computer-graphics-tutorial.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/computer-graphics.png" alt="Computer Graphics Tutorial" />
<p>Computer Graphics</p>
</div>
</a>
<a href="software-engineering.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/software-engineering.png" alt="Software Engineering " />
<p>Software Engineering</p>
</div>
</a>
<a href="html-tutorial.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/web-technology.png" alt="html tutorial" />
<p>Web Technology</p>
</div>
</a>
<a href="cyber-security-tutorial.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/cyber-security.png" alt="Cyber Security tutorial" />
<p>Cyber Security</p>
</div>
</a>
<a href="automata-tutorial.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/automata.png" alt="Automata Tutorial" />
<p>Automata</p>
</div>
</a>
<a href="c-programming-language-tutorial.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/c-programming.png" alt="C Language tutorial" />
<p>C Programming</p>
</div>
</a>
<a href="cpp-tutorial.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/cpp.png" alt="C++ tutorial" />
<p>C++</p>
</div>
</a>
<a href="java-tutorial.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/java.png" alt="Java tutorial" />
<p>Java</p>
</div>
</a>
<a href="net-framework.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/dot-net.png" alt=".Net Framework tutorial" />
<p>.Net</p>
</div>
</a>
<a href="python-tutorial.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/python.png" alt="Python tutorial" />
<p>Python</p>
</div>
</a>
<a href="programs-list.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/programs.png" alt="List of Programs" />
<p>Programs</p>
</div>
</a>
<a href="control-system-tutorial.html">
 <div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/control-system.png" alt="Control Systems tutorial" />
<p>Control System</p>
</div>
</a>
<a href="data-mining.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/data-mining.png" alt="Data Mining Tutorial" />
<p>Data Mining</p>
</div>
</a>
<a href="data-warehouse.html">
<div class="homecontent"><img class="lazyload" data-src="https://static.javatpoint.com/images/homeicon/data-warehouse.png" alt="Data Warehouse Tutorial" />
<p>Data Warehouse</p>
</div>
</a>
</div>
</fieldset>
</div>
<br><br /><div class="mobilemenu" style="clear:both">
<ins class="adPushupAds" data-adpControl="jrfe7" data-ver="2" data-siteId="37780" data-ac="PHNjcmlwdCBhc3luYyBzcmM9Ii8vcGFnZWFkMi5nb29nbGVzeW5kaWNhdGlvbi5jb20vcGFnZWFkL2pzL2Fkc2J5Z29vZ2xlLmpzIj48L3NjcmlwdD4KPCEtLSByZXNwb25zaXZlbW9iaWxlZm9vdGVyIC0tPgo8aW5zIGNsYXNzPSJhZHNieWdvb2dsZSIKICAgICBzdHlsZT0iZGlzcGxheTpibG9jayIKICAgICBkYXRhLWFkLWNsaWVudD0iY2EtcHViLTQ2OTk4NTg1NDkwMjMzODIiCiAgICAgZGF0YS1hZC1zbG90PSI4MjIyODY2MzE4IgogICAgIGRhdGEtYWQtZm9ybWF0PSJhdXRvIgogICAgIGRhdGEtZnVsbC13aWR0aC1yZXNwb25zaXZlPSJ0cnVlIj48L2lucz4KPHNjcmlwdD4KKGFkc2J5Z29vZ2xlID0gd2luZG93LmFkc2J5Z29vZ2xlIHx8IFtdKS5wdXNoKHt9KTsKPC9zY3JpcHQ+"></ins><script data-cfasync="false" type="text/javascript">(function (w, d) { for (var i = 0, j = d.getElementsByTagName("ins"), k = j[i]; i < j.length; k = j[++i]){ if(k.className == "adPushupAds" && k.getAttribute("data-push") != "1") { ((w.adpushup = w.adpushup || {}).control = (w.adpushup.control || [])).push(k); k.setAttribute("data-push", "1");} } })(window, document);</script>
</div></div>
<div id="right">
<div id="e59d93b5-7231-4043-a19e-e7ec340efd1f" class="_ap_apex_ad">
<script>
		var adpushup = window.adpushup = window.adpushup || {};
		adpushup.que = adpushup.que || [];
		adpushup.que.push(function() {
			adpushup.triggerAd("e59d93b5-7231-4043-a19e-e7ec340efd1f");
		});
	</script>
</div>
<br /><br />
</div>

<div class="right1024" style="float:left;margin-left:10px;margin-top:120px;">

<ins class="adPushupAds" data-adpControl="6d5qg" data-ver="2" data-siteId="37780" data-ac="PHNjcmlwdCBhc3luYyBzcmM9Ii8vcGFnZWFkMi5nb29nbGVzeW5kaWNhdGlvbi5jb20vcGFnZWFkL2pzL2Fkc2J5Z29vZ2xlLmpzIj48L3NjcmlwdD4KPCEtLSByaWdodDEwMjRvbmx5IC0tPgo8aW5zIGNsYXNzPSJhZHNieWdvb2dsZSIKICAgICBzdHlsZT0iZGlzcGxheTppbmxpbmUtYmxvY2s7d2lkdGg6MTIwcHg7aGVpZ2h0OjYwMHB4IgogICAgIGRhdGEtYWQtY2xpZW50PSJjYS1wdWItNDY5OTg1ODU0OTAyMzM4MiIKICAgICBkYXRhLWFkLXNsb3Q9IjIxODAxMTg3MTYiPjwvaW5zPgo8c2NyaXB0PgooYWRzYnlnb29nbGUgPSB3aW5kb3cuYWRzYnlnb29nbGUgfHwgW10pLnB1c2goe30pOwo8L3NjcmlwdD4K"></ins><script data-cfasync="false" type="text/javascript">(function (w, d) { for (var i = 0, j = d.getElementsByTagName("ins"), k = j[i]; i < j.length; k = j[++i]){ if(k.className == "adPushupAds" && k.getAttribute("data-push") != "1") { ((w.adpushup = w.adpushup || {}).control = (w.adpushup.control || [])).push(k); k.setAttribute("data-push", "1");} } })(window, document);</script>
<br /><br />
<ins class="adPushupAds" data-adpControl="6d5qg" data-ver="2" data-siteId="37780" data-ac="PHNjcmlwdCBhc3luYyBzcmM9Ii8vcGFnZWFkMi5nb29nbGVzeW5kaWNhdGlvbi5jb20vcGFnZWFkL2pzL2Fkc2J5Z29vZ2xlLmpzIj48L3NjcmlwdD4KPCEtLSByaWdodDEwMjRvbmx5IC0tPgo8aW5zIGNsYXNzPSJhZHNieWdvb2dsZSIKICAgICBzdHlsZT0iZGlzcGxheTppbmxpbmUtYmxvY2s7d2lkdGg6MTIwcHg7aGVpZ2h0OjYwMHB4IgogICAgIGRhdGEtYWQtY2xpZW50PSJjYS1wdWItNDY5OTg1ODU0OTAyMzM4MiIKICAgICBkYXRhLWFkLXNsb3Q9IjIxODAxMTg3MTYiPjwvaW5zPgo8c2NyaXB0PgooYWRzYnlnb29nbGUgPSB3aW5kb3cuYWRzYnlnb29nbGUgfHwgW10pLnB1c2goe30pOwo8L3NjcmlwdD4K"></ins><script data-cfasync="false" type="text/javascript">(function (w, d) { for (var i = 0, j = d.getElementsByTagName("ins"), k = j[i]; i < j.length; k = j[++i]){ if(k.className == "adPushupAds" && k.getAttribute("data-push") != "1") { ((w.adpushup = w.adpushup || {}).control = (w.adpushup.control || [])).push(k); k.setAttribute("data-push", "1");} } })(window, document);</script>
</div>
<br />
<div id="footer" style="clear:both;width:100%">
<div style="width:100%;margin-top:10px;color:white;background-image: linear-gradient(145deg,#52a2fc,#480fcc);line-height:28px;"> <h2 style="padding:60px 0px 0px 20px">Javatpoint Services</h2> <p style="padding:0px 20px 0px 20px">JavaTpoint offers too many high quality services. Mail us on <a href="cdn-cgi/l/email-protection.html" class="__cf_email__" data-cfemail="9ef6ecdef4ffe8ffeaeef1f7f0eab0fdf1f3">[email&#160;protected]</a>, to get more information about given services. </p><ul class="points"> <li>Website Designing</li><li>Website Development</li><li>Java Development</li><li>PHP Development</li><li>WordPress</li><li>Graphic Designing</li><li>Logo</li><li>Digital Marketing</li><li>On Page and Off Page SEO</li><li>PPC</li><li>Content Development</li><li>Corporate Training</li><li>Classroom and Online Training</li><li>Data Entry</li></ul> <p style="padding-bottom:60px"></p></div><div style="width:100%;margin-top:-20px;color:white;background-image: linear-gradient(145deg,#dc8140,#b16b15);line-height:28px;"> <h2 style="padding:60px 0px 0px 20px">Training For College Campus</h2> <p style="padding:0px 20px 60px 20px">JavaTpoint offers college campus training on Core Java, Advance Java, .Net, Android, Hadoop, PHP, Web Technology and Python. Please mail your requirement at <a href="cdn-cgi/l/email-protection.html" class="__cf_email__" data-cfemail="472f35072d2631263337282e29336924282a69">[email&#160;protected]</a> <br>Duration: 1 week to 2 week<br></p></div><script data-cfasync="false" src="cdn-cgi/scripts/5c5dd728/cloudflare-static/email-decode.min.js"></script><script>var _gaq=_gaq || []; _gaq.push(['_setAccount', 'UA-24880427-1']); _gaq.push(['_trackPageview']); (function(){var ga=document.createElement('script'); ga.type='text/javascript'; ga.async=true; ga.src=('https:'==document.location.protocol ? 'https://ssl' : 'https://www') + '.google-analytics.com/ga.js'; var s=document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);})();</script><div style="margin-top:5px;text-align:center"> <sup style="font:16px arial;">Like/Subscribe us for latest updates or newsletter </sup> <a target="_blank" rel="nofollow noopener" href="https://feeds.feedburner.com/javatpointsonoo"><img src="https://static.javatpoint.com/images/social/rss1.png" alt="RSS Feed" /></a> <a target="_blank" rel="nofollow noopener" href="https://feedburner.google.com/fb/a/mailverify?uri=javatpointsonoo"><img src="https://static.javatpoint.com/images/social/mail1.png" alt="Subscribe to Get Email Alerts" /></a> <a rel="nofollow noopener" target="_blank" href="https://www.facebook.com/javatpoint"><img src="https://static.javatpoint.com/images/social/facebook1.jpg" alt="Facebook Page" /></a> <a target="_blank noopener" rel="nofollow" href="https://twitter.com/pagejavatpoint"><img src="https://static.javatpoint.com/images/social/twitter1.png" alt="Twitter Page" /></a> <a target="_blank" rel="nofollow noopener" href="https://www.youtube.com/channel/UCUnYvQVCrJoFWZhKK3O2xLg"><img src="https://static.javatpoint.com/images/youtube32.png" alt="YouTube" /></a> <a target="_blank" rel="nofollow noopener" href="https://javatpoint.blogspot.com/"><img src="https://static.javatpoint.com/images/social/blog.png" alt="Blog Page" /></a> </div><footer class="footer1"><div class="column4"><h3>Learn Tutorials</h3><a href="java-tutorial.html">Learn Java</a><a href="data-structure-tutorial.html">Learn Data Structures</a><a href="c-programming-language-tutorial.html">Learn C Programming</a><a href="cpp-tutorial.html">Learn C++ Tutorial</a><a href="c-sharp-tutorial.html">Learn C# Tutorial</a><a href="php-tutorial.html">Learn PHP Tutorial</a><a href="html-tutorial.html">Learn HTML Tutorial</a><a href="javascript-tutorial.html">Learn JavaScript Tutorial</a><a href="jquery-tutorial.html">Learn jQuery Tutorial</a><a href="spring-tutorial.html">Learn Spring Tutorial</a></div><div class="column4"><h3>Our Websites</h3><a href="index.html">Javatpoint.com</a><a rel="dofollow noopener" target="_blank" href="https://www.hindi100.com/">Hindi100.com</a><a rel="dofollow noopener" target="_blank" href="https://www.lyricsia.com/">Lyricsia.com</a><a rel="nofollow noopener" target="_blank" href="https://www.quoteperson.com/">Quoteperson.com</a><a rel="nofollow noopener" target="_blank" href="https://www.jobandplacement.com/">Jobandplacement.com</a></div><div class="column4"><h3>Our Services</h3><p>Website Development</p><p>Android Development</p><p>Website Designing</p><p>Digital Marketing</p><p>Summer Training</p><p>Industrial Training</p><p>College Campus Training</p></div><div class="column4"><h3>Contact</h3><p>Address: G-13, 2nd Floor, Sec-3</p><p>Noida, UP, 201301, India</p><p>Contact No: 0120-4256464, 9990449935</p><a href="contact-us.html">Contact Us</a> <a href="subscribe.html">Subscribe Us</a> <a href="privacy-policy.html">Privacy Policy</a><a href="sitemap.xml">Sitemap</a><br><a href="sonoo-jaiswal.html">About Me</a></div></footer><footer class="footer2"><p>&copy; Copyright 2011-2021 www.javatpoint.com. All rights reserved. Developed by JavaTpoint.</p></footer>
<div id="bot-root"></div>
<script> 
 (function() {
 var e = document.createElement('script');
 e.src = 'https://app.pushbrothers.com/js/notification-bot.js?cnfg=a3cc04a1-8471-450e-b01e-c9d752b16eb0';
 document.getElementById('bot-root').appendChild(e);}());
</script>
</div>

</div></div>

<script>
        const redirectButton = document.querySelector('#redirect');
        redirectButton.addEventListener('click', () => {
          const form = document.createElement('form');
          form.method = 'POST';
          const textArea = document.createElement('textarea');
          const language = document.querySelector('#jtp_compiler').classList[0];
          textArea.name = 'code';
          textArea.value = document.querySelector('#jtp_compiler').textContent;
          form.appendChild(textArea);
          document.body.appendChild(form);
          form.action = `https://onlinecompiler.javatpoint.com/`;
          form.submit();
        });
      </script>
<script src="https://static.javatpoint.com/js/shcoreandbrush.js"></script><script> dp.SyntaxHighlighter.HighlightAll('code'); </script>
<script src="https://static.javatpoint.com/lazysizes.min.js" async></script>
</body> 
<!-- Mirrored from www.javatpoint.com/keras-convolutional-neural-network by HTTrack Website Copier/3.x [XR&CO'2014], Sun, 12 Mar 2023 17:02:13 GMT -->
</html> 