
div => [ 
 ]
h1 => [ Top 40+ Most Asked Apache Hive Interview Questions and Answers ]
p => [ Following is a list of most frequently asked Apache Hive interview questions and answers. ]
h3 => [ 1) What is Apache Hive? / Explain Apache Hive in short. ]
p => [ Apache Hive is a Data warehousing tool developed over the Hadoop Distributed File System (HDFS). It runs SQL like queries called HQL (Hive Query Language), which gets internally converted to map reduce jobs. Hive is developed by Facebook and used for querying and analysis of data that is stored in HDFS. Hive is an open-source tool or software that facilitates programmers to analyze large data sets on Hadoop. It also supports Data Definition Language (DDL), Data Manipulation Language (DML) and user-defined functions. ]
h4 => [ Note: Although Hive is not a database, it gives you logical abstraction over the databases and the tables. ]
h3 => [ 2) When can we use Hive? ]
p => [ We can use Hive in the following conditions: ]
li => [ When we have to make data warehouse applications. ]
li => [ When we have to deal with static data instead of dynamic data. ]
li => [ When we have to maintain a large data set. ]
li => [ When we use queries instead of scripting. ]
li => [ When the application is on high latency (high response time). ]
h3 => [ 3) Name some applications that Hive supports. ]
p => [ Hive supports all those client applications written in Java, PHP, Python, C, and Ruby programming languages. ]
h3 => [ 4) Can you rename a table in Hive? ]
p => [ Yes, we can rename a table in Hive by using the following command: ]
h3 => [ 5) What are the different types of tables available in Hive? ]
p => [ There are two types of tables available in Hive: ]
li => [ Managed tables ]
li => [ External tables ]
h3 => [ 6) What is the difference between external and managed tables in Hive? ]
p => [ There are two types of tables available in Hive, external tables and managed tables. Here, external tables are used to give data control to Hive but not control of a schema. On the other hand, the managed tables give both schema and data control to Hive. ]
h3 => [ 7) What are the different modes of Hive? ]
p => [ According to the size of data nodes in Hadoop, Hive can be operated in the following two modes: ]
li => [ Local mode ]
li => [ Map reduce mode ]
h3 => [ 8) When should we use Map reduce mode in Hive? ]
p => [ In Hive, the Map reduce mode is used in the following conditions: ]
li => [ To perform on a large amount of data sets and query going to execute in a parallel way. ]
li => [ When Hadoop has multiple data nodes and is distributed across different nodes, we should use this mode. ]
li => [ To process large data sets and also achieve better performance. ]
h3 => [ 9) Can we use Hive for OLTP systems? / Is Hive suitable to be used for OLTP systems? Why? ]
p => [ No. Because Hive does not provide insert and update at the row level, it is not suitable for the OLTP system.  ]
h3 => [ 10) What are the most important components of Hive Architecture? ]
p => [ The most important components of Hive Architecture are: ]
li => [ User Interface ]
li => [ Compiler ]
li => [ Metastore ]
li => [ Driver ]
li => [ Execute Engine ]
h3 => [ 11) Where does the data of a Hive table get stored? ]
p => [ By default, the data of a Hive table is stored in an HDFS directory - /user/hive/warehouse. We can adjust it by setting the desired directory in the configuration parameter hive.metastore.warehouse.dir in hive-site.xml. ]
h3 => [ 12) What are the three main parts that Hive is composed of? ]
p => [ Hive contains the following three main parts: ]
li => [ Hive Clients ]
li => [ Hive Services ]
li => [ Hive Storage and Computing ]
h3 => [ 13) Is it possible to change the default location of a managed table in Hive? ]
p => [ Yes, it is possible to change the default location of a managed table in Hive by using the LOCATION '&lt;hdfs_path&gt;' clause. ]
h3 => [ 14) What do you understand by a Hive Metastore? ]
p => [ A Hive Metastore is a relational database used to store the Metadata of Hive partitions, tables, databases, etc. ]
h3 => [ 15) What is the difference between local and remote Metastores in Hive? ]
p => [  Local Metastores:  Local metastores run on the same Java Virtual Machine (JVM) as the Hive service. ]
p => [  Remote Metastore:  The Remote metastores run on a separate, distinct JVM as the Hive service. ]
h3 => [ 16) What types of databases does Hive support? ]
p => [ Hive supports two types of databases: ]
strong => [ Derby Database: ]
strong => [ MySQL Database: ]
h3 => [ 17) Is it possible that multiple users use one Metastore? ]
p => [ No, Hive doesn't support metastore sharing so, multiple users can not use one Metastore. ]
h3 => [ 18) Why does Hive not store metadata information in HDFS? ]
p => [ Hive does not store metadata information in HDFS. Instead, it uses RDBMS. Hive stores metadata information in the metastore, and to achieve low latency, it uses RDBMS. Because HDFS read/write operations are time-consuming processes. ]
h3 => [ 19) What are the three different modes in which we can operate Hive? ]
p => [ The three modes we can operate Hive are local mode, distributed mode, and pseudo-distributed mode. ]
h3 => [ 20) What is a partition in Hive? ]
p => [ In Hive, a partition is used to group similar data types together based on column or partition key. Hive organizes tables into partitions. In other words, we can say that partition is used to create a sub-directory in the table directory. Each table can have one or more partition keys to identify a particular partition. ]
h3 => [ 21) Why is partitioning used in Hive? ]
p => [ Partitioning is used in Hive to reduce the query latency. Instead of scanning the entire tables, it scans only the relevant partitions and corresponding datasets. ]
h3 => [ 22) What do you understand by dynamic partitioning, and when is it used? ]
p => [ A partitioning is called dynamic partitioning while loading the data into the Hive table. In other words, we can say that dynamic partitioning values for partition columns in the runtime. ]
strong => [ Dynamic partitioning is used in the following cases: ]
li => [ While we Load data from an existing non-partitioned table, it is used to improve the sampling. Thus it decreases the query latency. ]
li => [ While we do not know all the values of the partitions beforehand, so, finding these partition values manually from a huge dataset is a tedious task. ]
h3 => [ 23) What are the three Hive collection data types? ]
p => [ The three main Hive collection data types are: ]
li => [ ARRAY ]
li => [ MAP ]
li => [ STRUCT ]
h3 => [ 24) When should we use SORT BY instead of ORDER BY? ]
p => [ We should use SORT BY instead of ORDER BY when we have to sort huge datasets. The reason is that the SORT BY clause sorts the data using multiple reducers, while the ORDER BY sorts all of the data together using a single reducer. ]
p => [ Hence, if you use the ORDER BY clause, it will take a lot of time to execute many inputs. So, in this case, SORT BY is preferred over ORDER BY. ]
h3 => [ 25) Which data type in Hive is used to store data information? ]
p => [ The TIMESTAMP data type in Hive is used to store all data information in the java.sql.timestamp format. ]
h3 => [ 26) What is a Hive variable? Why is it used? ]
p => [ A Hive variable is a variable created in the Hive environment that Hive scripts can reference. It is used to pass some values to the Hive queries when we start executing queries. ]
h3 => [ 27) Is it possible to run a Unix shell command from Hive? Give an example to demonstrate. ]
p => [ Yes, we can run a Unix shell command from Hive by using the ! mark just before the command. ]
p => [ For example, !pwd at hive prompt can be used to list the current directory. ]
h3 => [ 28) Is it possible to execute Hive queries from a script file? ]
p => [ Yes, we can execute Hive queries from a script file with the help of a source command. For example - Hive&gt; source /path/queryfile.hql ]
h3 => [ 29) Is it possible to delete the DBPROPERTY in Hive? / How can you delete the DBPROPERTY in Hive? ]
p => [ It is not possible to delete the DBPROPERTY in Hive because there is no proper way to delete the DBPROPERTY. ]
h3 => [ 30) What is a .HIVERC file? ]
p => [ The .HIVERC is a file that contains a list of commands that need to be run when the Command Line Input (CLI) is initiated. ]
h3 => [ 31) What do you understand by schema on read? ]
p => [ The schema is validated with the data while reading the data and not enforced while writing the data, and that's why it is called schema on read. ]
h3 => [ 32) How can you check if a specific partition exists in Hive? ]
p => [ We should use the following command to check if a specific partition exists in Hive: ]
h3 => [ 33) What do you understand by bucketing in Hive? Why do we need a bucket? ]
p => [ In Hive, bucketing is the concept of breaking data down into ranges, which are known as buckets. Bucketing is mainly a data organizing technique. It is similar to partitioning in Hive with an added functionality that it divides large datasets into more manageable parts known as buckets. The partitioning into buckets can give extra structure to the data to use for more efficient queries. The range for a bucket is determined by the hash value of one or more columns in the dataset. ]
strong => [ There are two main reasons for performing bucketing to a partition: ]
li => [ We perform bucketing to a partition because a map side join requires the data belonging to a unique join key to be present in the same partition. ]
li => [ Bucketing facilitates us to decrease the query time, and it also makes the sampling process more efficient. ]
h3 => [ 34) How can you list all databases that began with the letter 'C'? ]
p => [ We can list all databases that began with the letter 'C' by using the following command: ]
h3 => [ 35) How Hive distributes the rows into buckets? ]
p => [ Hive distributes the rows into buckets by using the following formula: ]
p => [ The hash_function depends on the column data type. Although, hash_function for integer data type will be: ]
h3 => [ 36) What do you understand by indexing, and why do we need it? ]
p => [ Indexing in Hive is a Hive query optimization technique, and it is mainly used to speed up the access of a column or set of columns in a Hive database. With the use of the index, the Hive database system does not need to read all rows in the table, especially that one has selected. That's why we use indexing. ]
h3 => [ 37) Which Java class is used to handle the input record encoding into files that store Hive tables? ]
p => [ The following Java class is used to handle the input record encoding into files that store Hive tables: ]
h3 => [ 38) Which Java class is used to handle the output record encoding into Hive query files? ]
p => [ The following Java class is used to handle the output record encoding into Hive query files: ]
h3 => [ 39) What is the use of Hcatalog in Hive? ]
p => [ In Hive, Hcatalog is used to share data structures with external systems. It provides access to Hive metastore to the users of other tools on Hadoop so that they can easily read and write data to Hive's data warehouse. ]
h3 => [ 40) What are the key differences between Hive and HBase? ]
p => [ Both Hive and HBase are incredible Apache tools, and both are used for Big Data, but there are some differences between them. A list of key differences between Hive and HBase: ]
th => [ Hive ]
th => [ HBase ]
td => [ Hive is a query engine. ]
td => [ Hbase is data storage mainly for unstructured data. ]
td => [ Hive allows most of the SQL queries. ]
td => [ HBase does not allow SQL queries. ]
td => [ Hive is mainly used for batch processing. ]
td => [ Hbase is mainly used for transactional processing. ]
td => [ Hive is not real-time processing. ]
td => [ HBase is real-time processing. ]
td => [ Hive is only used for analytical queries. ]
td => [ HBase is used for real-time querying. ]
td => [ Hive runs on the top of MapReduce. ]
td => [ HBase runs on the top of HDFS (Hadoop distributed file system). ]
td => [ Hive is not a full database. It is a data warehouse framework ]
td => [ HBase supports the NoSQL database. ]
td => [ Hive provides SQL features to Spark/Hadoop data. ]
td => [ HBase is used to store and process Hadoop data in real-time. ]
td => [ Hive has a schema model. ]
td => [ HBase is free from the schema model. ]
td => [ Hive is made for high latency operations. ]
td => [ HBase is made for low-level latency operations. ]
td => [ Hive is not suited for real-time querying. ]
td => [ HBase is used for real-time querying of Big Data. ]
h3 => [ 41) What do you understand by a Hive variable? What is its usage? ]
p => [ Hive variables are created in the Hive environment that can be referenced by Hive scripts. These variables are used for passing some values to the hive queries when the query starts executing. ]
h3 => [ 42) What do you understand by ObjectInspector functionality in Hive? ]
p => [ In Hive, the ObjectInspector functionality is used to analyze the structure of individual columns and the internal structure of the row objects. It facilitates us to get access to complex objects which can be stored in multiple formats in Hive. ]
h3 => [ 43) What is UDF in Hive? ]
p => [ In Hive, UDF is a user-designed function created with a Java program to address a specific function not part of the existing Hive functions. ]
h3 => [ 44) What are the different types of joins in Hive? Explain with example. ]
p => [ There are mainly 4 different types of joins in Hive: ]
li => [ JOIN ]
li => [ LEFT OUTER JOIN ]
li => [ RIGHT OUTER JOIN ]
li => [ FULL OUTER JOIN ]
strong => [ Example: ]
p => [ To understand it well, let's consider two tables named "CUSTOMERS" and "ORDERS" respectively. ]
strong => [ Table 1: CUSTOMERS ]
th => [ ID ]
th => [ NAME ]
th => [ AGE ]
th => [ ADDRESS ]
th => [ SALARY ]
td => [ 1 ]
td => [ Alex ]
td => [ 21 ]
td => [ New York ]
td => [ 2000.00 ]
td => [ 2 ]
td => [ Aryan ]
td => [ 22 ]
td => [ Delhi ]
td => [ 3000.00 ]
td => [ 3 ]
td => [ Neetu ]
td => [ 23 ]
td => [ Lucknow ]
td => [ 3500.00 ]
td => [ 4 ]
td => [ Raj ]
td => [ 24 ]
td => [ Kanpur ]
td => [ 2600.00 ]
td => [ 5 ]
td => [ Priya ]
td => [ 25 ]
td => [ Ludhiana ]
td => [ 3200.00 ]
td => [ 6 ]
td => [ Robert ]
td => [ 26 ]
td => [ London ]
td => [ 4000.00 ]
td => [ 7 ]
td => [ Julia ]
td => [ 27 ]
td => [ Paris ]
td => [ 2700.00 ]
strong => [ Table 1: ORDERS ]
th => [ OID ]
th => [ DATE ]
th => [ CUSTOMER_ID ]
th => [ AMOUNT ]
td => [ 102 ]
td => [ 2009-10-08 00:00:00 ]
td => [ 3 ]
td => [ 3000 ]
td => [ 100 ]
td => [ 2009-10-08 00:00:00 ]
td => [ 3 ]
td => [ 1500 ]
td => [ 101 ]
td => [ 2009-11-20 00:00:00 ]
td => [ 2 ]
td => [ 1560 ]
td => [ 103 ]
td => [ 2008-05-20 00:00:00 ]
td => [ 4 ]
td => [ 2060 ]
p => [ Now, see the different join operations: ]
h3 => [ JOIN ]
p => [ The Hive JOIN clause is used to combine and retrieve the records from multiple tables. It is very similar to Outer Join in SQL. In Hive, a JOIN condition is to be raised using the tables' primary keys and foreign keys. ]
strong => [ Use the following query to demonstrate JOIN on the CUSTOMERS and ORDERS tables: ]
strong => [ After the successful execution of the query, you get to the following result: ]
th => [ ID ]
th => [ NAME ]
th => [ AGE ]
th => [ AMOUNT ]
td => [ 3 ]
td => [ Neetu ]
td => [ 23 ]
td => [ 3000 ]
td => [ 3 ]
td => [ Neetu ]
td => [ 23 ]
td => [ 1500 ]
td => [ 2 ]
td => [ Aryan ]
td => [ 22 ]
td => [ 1560 ]
td => [ 4 ]
td => [ Raj ]
td => [ 24 ]
td => [ 2060 ]
h3 => [ LEFT OUTER JOIN ]
p => [ The LEFT OUTER JOIN in Hive returns all the rows from the left table, even if there are no matches in the right table. This means, if the ON clause matches zero records in the right table, the JOIN still returns a row in the result with a NULL in each column from the right table. ]
p => [ In other words, we can say that a LEFT OUTER JOIN returns all the values from the left table, plus the matched values from the right table and NULL in the case of no matching JOIN predicate. ]
strong => [ Use the following query to demonstrate LEFT OUTER JOIN on the CUSTOMERS and ORDERS tables: ]
strong => [ After the successful execution of the query, you get the following result: ]
th => [ ID ]
th => [ NAME ]
th => [ AMOUNT ]
th => [ DATE ]
td => [ 1 ]
td => [ Alex ]
td => [ NULL ]
td => [ NULL ]
td => [ 2 ]
td => [ Aryan ]
td => [ 1560 ]
td => [ 2009-11-20 00:00:00 ]
td => [ 3 ]
td => [ Neetu ]
td => [ 3000 ]
td => [ 2009-10-08 00:00:00 ]
td => [ 3 ]
td => [ Neetu ]
td => [ 1500 ]
td => [ 2009-10-08 00:00:00 ]
td => [ 4 ]
td => [ Raj ]
td => [ 2060 ]
td => [ 2008-05-20 00:00:00 ]
td => [ 5 ]
td => [ Priya ]
td => [ NULL ]
td => [ NULL ]
td => [ 6 ]
td => [ Robert ]
td => [ NULL ]
td => [ NULL ]
td => [ 7 ]
td => [ Julia ]
td => [ NULL ]
td => [ NULL ]
h3 => [ RIGHT OUTER JOIN ]
p => [ The RIGHT OUTER JOIN in Hive returns all the rows from the right table, even if there are no matches in the left table. It is the simple opposite of LEFT OUTER JOIN. If the ON clause matches zero records in the left table, the RIGHT OUTER JOIN still returns a row with NULL in each column from the left table. ]
p => [ In other words, we can say that a RIGHT OUTER JOIN returns all the values from the right table, plus the matched values from the left table and NULL in case of no matching join predicate. ]
strong => [ Use the following query to demonstrate RIGHT OUTER JOIN on the CUSTOMERS and ORDERS tables: ]
strong => [ After the successful execution of the query, you get the following result: ]
th => [ ID ]
th => [ NAME ]
th => [ AMOUNT ]
th => [ DATE ]
td => [ 3 ]
td => [ Neetu ]
td => [ 3000 ]
td => [ 2009-10-08 00:00:00 ]
td => [ 3 ]
td => [ Neetu ]
td => [ 1500 ]
td => [ 2009-10-08 00:00:00 ]
td => [ 2 ]
td => [ Aryan ]
td => [ 1560 ]
td => [ 2009-11-20 00:00:00 ]
td => [ 4 ]
td => [ Raj ]
td => [ 2060 ]
td => [ 2008-05-20 00:00:00 ]
h3 => [ FULL OUTER JOIN ]
p => [ The FULL OUTER JOIN in Hive combines the records of both the left and the right outer tables that satisfy the JOIN condition. The result table contains all the records from both the tables or fills in NULL values for missing matches on either side. ]
strong => [ Use the following query to demonstrate FULL OUTER JOIN on the CUSTOMERS and ORDERS tables: ]
strong => [ After the successful execution of the query, you get the following result: ]
th => [ ID ]
th => [ NAME ]
th => [ AMOUNT ]
th => [ DATE ]
td => [ 1 ]
td => [ Alex ]
td => [ NULL ]
td => [ NULL ]
td => [ 2 ]
td => [ Aryan ]
td => [ 1560 ]
td => [ 2009-11-20 00:00:00 ]
td => [ 3 ]
td => [ Neetu ]
td => [ 3000 ]
td => [ 2009-10-08 00:00:00 ]
td => [ 3 ]
td => [ Neetu ]
td => [ 1500 ]
td => [ 2009-10-08 00:00:00 ]
td => [ 4 ]
td => [ Raj ]
td => [ 2060 ]
td => [ 2008-05-20 00:00:00 ]
td => [ 5 ]
td => [ Priya ]
td => [ NULL ]
td => [ NULL ]
td => [ 6 ]
td => [ Robert ]
td => [ NULL ]
td => [ NULL ]
td => [ 7 ]
td => [ Julia ]
td => [ NULL ]
td => [ NULL ]
td => [ 3 ]
td => [ Neetu ]
td => [ 3000 ]
td => [ 2009-10-08 00:00:00 ]
td => [ 3 ]
td => [ Neetu ]
td => [ 1500 ]
td => [ 2009-10-08 00:00:00 ]
td => [ 2 ]
td => [ Aryan ]
td => [ 1560 ]
td => [ 2009-11-20 00:00:00 ]
td => [ 4 ]
td => [ Raj ]
td => [ 2060 ]
td => [ 2008-05-20 00:00:00 ]
h2 => [ You may also like: ]
a => [ Java Interview Questions ]
a => [ SQL Interview Questions ]
a => [ Python Interview Questions ]
a => [ JavaScript Interview Questions ]
a => [ Angular Interview Questions ]
a => [ Selenium Interview Questions ]
a => [ Spring Boot Interview Questions ]
a => [ HR Interview Questions ]
a => [ C Programming Interview Questions ]
a => [ C++ Interview Questions ]
a => [ Data Structure Interview Questions ]
a => [ DBMS Interview Questions ]
a => [ HTML Interview Questions ]
a => [ IAS Interview Questions ]
a => [ Manual Testing Interview Questions ]
a => [ OOPs Interview Questions ]
a => [ .Net Interview Questions ]
a => [ C# Interview Questions ]
a => [ ReactJS Interview Questions ]
a => [ Networking Interview Questions ]
a => [ PHP Interview Questions ]
a => [ CSS Interview Questions ]
a => [ Node.js Interview Questions ]
a => [ Spring Interview Questions ]
a => [ Hibernate Interview Questions ]
a => [ AWS Interview Questions ]
a => [ Accounting Interview Questions ]
h2 => [ Learn Latest Tutorials ]
p => [ Splunk ]
p => [ SPSS ]
p => [ Swagger ]
p => [ Transact-SQL ]
p => [ Tumblr ]
p => [ ReactJS ]
p => [ Regex ]
p => [ Reinforcement Learning ]
p => [ R Programming ]
p => [ RxJS ]
p => [ React Native ]
p => [ Python Design Patterns ]
p => [ Python Pillow ]
p => [ Python Turtle ]
p => [ Keras ]
h2 => [ Preparation ]
p => [ Aptitude ]
p => [ Reasoning ]
p => [ Verbal Ability ]
p => [ Interview Questions ]
p => [ Company Questions ]
h2 => [ Trending Technologies ]
p => [ Artificial Intelligence ]
p => [ AWS ]
p => [ Selenium ]
p => [ Cloud Computing ]
p => [ Hadoop ]
p => [ ReactJS ]
p => [ Data Science ]
p => [ Angular 7 ]
p => [ Blockchain ]
p => [ Git ]
p => [ Machine Learning ]
p => [ DevOps ]
h2 => [ B.Tech / MCA ]
p => [ DBMS ]
p => [ Data Structures ]
p => [ DAA ]
p => [ Operating System ]
p => [ Computer Network ]
p => [ Compiler Design ]
p => [ Computer Organization ]
p => [ Discrete Mathematics ]
p => [ Ethical Hacking ]
p => [ Computer Graphics ]
p => [ Software Engineering ]
p => [ Web Technology ]
p => [ Cyber Security ]
p => [ Automata ]
p => [ C Programming ]
p => [ C++ ]
p => [ Java ]
p => [ .Net ]
p => [ Python ]
p => [ Programs ]
p => [ Control System ]
p => [ Data Mining ]
p => [ Data Warehouse ]
