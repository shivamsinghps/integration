
div => [ 
 ]
h1 => [ ETL Testing Interview Questions ]
p => [  A list of frequently asked  ETL Testing Interview Questions and Answers  are given below. ]
h3 => [ 1) What is ETL? Explain it. ]
p => [  ETL stands for Extraction, Transformation, and Loading. It is an essential concept in Data Warehousing systems. There are three basics steps in Data Integration Process.  Extraction  stands for extracting the data from different data sources such as transactional systems or applications.  Transformation  stands to apply the conversion rules on data so that it becomes suitable for analytical reporting.  Loading  process involves, to move the data into the target system, i.e., Data Warehouse.  ]
h3 => [ 2) Explain the concept of Extraction, Transformation, and Loading? ]
strong => [ Extraction ]
p => [ Extracted the data from an external source and move it to the data Warehouse pre-processor database. ]
strong => [ Transformation ]
p => [ Transform data task allows point to point generating, modifying, and transforming the data. ]
strong => [ Loading ]
p => [ In this task, the data is added to the database table in a warehouse. ]
h3 => [ 3) What is the three-layer architecture of an ETL cycle? ]
p => [ The three layers in the ETL are:  ]
strong => [ Staging Layer: ]
strong => [ Data Integration Layer: ]
strong => [ dimension, and into facts and aggregation facts ]
strong => [ a schema ]
strong => [ Access Layer: ]
h3 => [ 4) What is BI? ]
p => [ Business Intelligence is the process for collecting raw business data and transforming it into a meaningful vision that is more useful for business.  ]
h3 => [ 5) What are the differences between ETL and BI tools? ]
th => [ ETL TOOLS ]
th => [ BI TOOLS ]
td => [ The ETL tools are used to extract the data from different data sources, transform the data, and load it into a data warehouse system. ]
td => [ BI tools are used to generate interactive and ad-hoc reports for end-users, data visualization for monthly, quarterly, and annual board meetings. ]
td => [ Most commonly ETL tools are Informatica, SAP BO data service, Microsoft SSIS, Oracle Data Integrator (ODI) Clover ETL Open Source, etc. ]
td => [ Most commonly BI tools are SAP Lumira, IBM Cognos, Microsoft BI platform, Tableau, Oracle Business Intelligence Enterprise Edition, etc. ]
h3 => [ 6) What are the ETL tools available in the market? ]
p => [ The popular ETL tools available in the market are: ]
li => [ IBM- Websphere DataStage ]
li => [ Informatica- Power Center ]
li => [ SAP- Business objects data service BODS ]
li => [ SAS - Data Integration Studio ]
li => [ Oracle- Warehouse Builder ]
li => [ Open source Clover ETL. ]
h3 => [ 7) When we need the staging area in the ETL process? ]
p => [ Staging area is a central area which is available between the data sources and data warehouse/data marts systems. It is a place where data is stored temporarily in the process of data integration. In the staging, area data is cleansed and checked for any duplication. The staging area is designed to provide many benefits, but the primary goal is to use the staging area. It is used to increase efficiency, ensure the data integrity, and support the data quality operations. ]
h3 => [ 8) What is the difference between the data warehouse and data mining? ]
p => [ Data warehousing is a broad concept as compared to data mining. Data Mining involves extracting the hidden information from the data and interpreting it for future forecasting. In contrast, data warehousing includes operations such as analytical reporting to generate detailed reports and ad-hoc reports, information processing to generate interactive dashboards and charts. ]
h3 => [ 9) What are the differences between data warehousing and data mining? ]
th => [ OLTP ]
th => [ OLAP ]
td => [ OLTP stands for Online Transactional Processing. ]
td => [ OLAP stands for Online Analytical Processing. ]
td => [ OLTP is a relational database, and it is used to manage the day to day transaction. ]
td => [ OLAP is a multidimensional system, and it is also called a data warehouse. ]
h3 => [ 10) What is a dimension table and how it is different from the fact table? ]
p => [ Here, we are taking an example to describe how the dimension table is distinguishing from the fact table. ]
p => [ Suppose a company sells its products to its customer. Every sale is a fact which occurs within the company, and the fact table is used to record these facts. Each fact table stores the primary key that joins fact table with the dimension table and measures/ facts. ]
strong => [ Example: Fact Units ]
th => [ Cust_ID ]
th => [ Prod_ID ]
th => [ Time_ID ]
th => [ No. of units sold ]
td => [ 101 ]
td => [ 24 ]
td => [ 1 ]
td => [ 25 ]
td => [ 102 ]
td => [ 25 ]
td => [ 2 ]
td => [ 15 ]
td => [ 103 ]
td => [ 26 ]
td => [ 3 ]
td => [ 30 ]
p => [ A dimension table which store attributes or dimensions describe the objects in a fact table. It is a set of companion tables to a fact table. ]
th => [ Cust_ID ]
th => [ Cust_Name ]
th => [ Gender ]
td => [ 101 ]
td => [ Sana ]
td => [ F ]
td => [ 102 ]
td => [ Jass ]
td => [ M ]
h3 => [ 11) What is a Data Mart? ]
p => [ Data Mart is a simple form of Data Warehouse, and it is focused on a single functional area. It gets the only from few sources. ]
p => [  For example:  In an organization, data marts may exist for marketing, finance, human resource, and other individual departments which stores the data related to their specific functions. ]
h3 => [ 12) What is the difference between Manual Testing and ETL Testing? ]
p => [ The difference between Manual testing and ETL testing is: ]
li => [ Manual testing focuses on the functionality of the program while the ETL testing is related to database and its count. ]
li => [ ETL is the automated testing process where we do not need any technical knowledge. ETL testing is extremely faster, systematic, and assurance of the result required by the business. ]
li => [ Manual testing is a time-consuming process where we need the technical knowledge to write the test cases and scripts. It is slow, highly prone to errors, and also need efforts. ]
h3 => [ 13) What is ETL Testing? ]
p => [ ETL stands for Extraction, Transform, and Loading the information. ETL testing is done to ensure that the data is loaded from different source to destination after the accurately business transformation. It involves data verification at multiple stages that are being used between the source and the destination. ]
h3 => [ 14) What is the responsibility of ETL tester? ]
p => [ The responsibility of ETL Tester is divided into three major categories: ]
li => [ Stage Tables ]
li => [ Business Logic Transformation ]
li => [ Target table loading from the staging table, once we apply the transformation. ]
p => [ Responsibilities of ETL tester are: ]
li => [ ETL tester tests the ETL software thoroughly. ]
li => [ The tester will check the test component of the ETL Data Warehouse. ]
li => [ The tester will execute the data-driven test in the backend. ]
li => [ The tester creates the design and executes the test cases, test plans or test harness, etc. ]
li => [ Tester identifies the problems and will suggest the best solution also. ]
li => [ Tester approves the requirements and design specification. ]
li => [ Tester transfers the data from flat files. ]
li => [ They write the SQL queries for the different test scenario. ]
h3 => [ 15) What is the need for ETL Testing? ]
p => [ In today's time, we are migrating the lots of system from old technology to new technology. At the time of migration activities, we also need to migrate the data as well from old DBMS to latest DBMS. So there is a lot of need to test whether the data is correct from the target side.  ]
p => [ Here, are some important points where the need for ETL testing is arising: ]
li => [ ETL testing used to keep an eye on the data which is being transferred from one system to another.  ]
li => [ The need for ETL testing is to keep a track on the efficiency and speed of the process. ]
li => [ The need for ETL testing is arising to be familiar with the ETL process before we implement it into our business and production. ]
h3 => [ 16) Where the user use ETL concepts? Explain it. ]
li => [ Before ETL tools user writes the extended code for data transformation to data loading. ]
li => [ ETL makes life more comfortable, and one tool manages all the scenarios of transformation and loading of the data. ]
p => [ Here is the following example where we are using the ETL: ]
strong => [ Example: Data Warehousing ]
p => [ ETL is used in data warehousing concept. Here, we need to fetch the data from multiple different systems and loads it in the data warehouse database. ETL concept is used here to extract the data from the source, transform the data, and load it into the target system. ]
strong => [ Example: Data Migration ]
p => [ Data migrations are a difficult task if we are using PLSQL. If we want to migrate the data using a simple way, we will use different ETL tools. ]
strong => [ Example: Mergers and Acquisitions ]
p => [ In today's time, lots of companies are merging into different MNCs. To move the data from one company to another, the need for ETL concept arises. ]
h3 => [ 17) How we use ETL in third party management? ]
p => [ The big organization always gives different application development to different kind of vendors. A single vendor cannot manage everything. Here we are taking an example of a telecommunication project where billing is handled by one company, and another company manages CRM. If CRM company needs the data from the company, who is managing the billing, now the company will receive the data feed from other company. To load the data from the ETL process is used. ]
h3 => [ 18) How we use ETL in Data Warehousing? ]
p => [ Most commonly, the ETL used in Data Warehousing. User fetches the historical data as well as current data for developing the data warehouse. Data in the data warehouse is the combination of historical data as well as transactional data. Data Source of data warehouse might be different. We need to fetch the data from multiple different systems and load it into a single target system, which is also called a data warehouse. ]
h3 => [ 19) What is the difference between ETL Testing and Database Testing? ]
p => [ The differences between the ETL testing and Database testing are: ]
th => [ ETL Testing ]
th => [ Database Testing ]
td => [ In ETL testing, the goal is the reporting of business intelligence ]
td => [ In DB testing, the goal is to integrate the data. ]
td => [ The flow of business environment is based on the data used earlier ]
td => [ Database Testing applies to business flow systems only. ]
td => [ The tools Informatica, Query Surge, Cognos can be used. ]
td => [ In DB testing, the QTP and Selenium tools are used. ]
td => [ In ETL testing, Dimensional model is used. ]
td => [ In DB testing, relational model is used. ]
td => [ In ETL testing, Analytics are processed. ]
td => [ In DB testing, Transactions are processed. ]
td => [ Denormalized data is used in ETL testing. ]
td => [ .Normalized data is used. ]
h3 => [ 20) What are the characteristics of Data Warehouse? ]
li => [ Data Warehouse is a database which is different from the operational database and stores the historical data. ]
li => [ Data Warehouse Database contains the analytical as well as transactional data. ]
li => [ Data Warehouse is used for data analysis and reporting purpose. ]
li => [ Data Warehouse helps the higher management to take strategic and tactical decisions using historical or current data. ]
li => [ Data Warehouse helps the business user to the current trend to run the business. ]
h3 => [ 21) What are the types of Data Warehouse systems? ]
li => [ Online Analytical Processing (OLAP) ]
li => [ Predictive Analysis ]
li => [ Online Transactional Processing ]
li => [ Data Mart ]
h3 => [ 22) What are the steps followed in ETL testing process? ]
p => [ The different steps followed in ETL testing process are: ]
strong => [ Step 1. Requirement Analyzing ]
p => [ In this step, we understand the business structure and the requirement. ]
strong => [ Step 2. Validation and Test Estimation ]
p => [ An estimation of time and expertise is required in this step. ]
strong => [ Step 3. Test Planning and designing the testing environment ]
p => [ This step is based on the validation and test estimation. In this step, the environment of ETL is planned according to the input which is used in the test estimation and worked according to that. ]
strong => [ Step 4. Test Data Preparation and Execution ]
p => [ As per the test, data is prepared and executed as per the requirement. ]
strong => [ Step 5. Summary Report ]
p => [ On the completion of the test run, a summary report is prepared for concluding and improvising. ]
h3 => [ 23) How is ETL used in Data Migration Project? Explain it. ]
p => [ ETL tools are generally used in Data Migration Project. If any organization is managing the data in Oracle 10g previously, now the organization wants to use SQL server cloud database, then there is a need to move the data from source to target. For this kind of movement, ETL tools are very useful. If we want to write the code for ETL, it is a very time-consuming process. To make this simple, we use ETL tool, which makes the coding simple PL SQL or T- SQL code. So the ETL process is useful in Data Migration Projects. ]
h3 => [ 24) What are the steps followed to choose the ETL process? ]
p => [ It is a very difficult task to choose the ETL tools. To select the correct ETL tool, we need to consider a lot of factors according to the project. To choose the ETL tool for a specific project is a very strategic move, even we need it for a small project. ]
p => [ Here are some points which will help us to choose the ETL tool. ]
strong => [ Data Connectivity ]
strong => [ Performance ]
strong => [ Transformation Flexibility ]
strong => [ Data Quality ]
strong => [ Flexible data action option ]
strong => [ Committed ETL vendor ]
h3 => [ 25) What are the ETL bugs? ]
p => [ Here are the following ETL bugs: ]
li => [ Source Bugs ]
li => [ Load Condition Bugs ]
li => [ Calculation Bugs ]
li => [ ECP related Bugs ]
li => [ User-Interface Bugs ]
h3 => [ 26) What is Operation Data Source? ]
li => [ ODS stands for Operational Data Source. ]
li => [ ODS works between the staging area and the Data Warehouse. The data is ODS will be at the level of granularity. ]
li => [ When the data is inserted in ODS, all the data will be loaded in the EDW through ODS. ]
h3 => [ 27) What is the data extraction phase in ETL? ]
p => [ Data Extraction is nothing, but it is extracting the data from multiple different sources using ETL tools. ]
p => [ Here are two types of data extraction. ]
strong => [ Full Extraction: ]
strong => [ Partial Extraction: ]
p => [  Source System Performance:  The extraction strategies of data should not affect the performance of the source system. ]
h3 => [ 28) What are the ETL Tools? ]
p => [ The popular tools are: ]
strong => [ 1. Enterprise ETL tools ]
li => [ Informatica ]
li => [ Talend ]
li => [ IBM Datastage ]
li => [ Abnitio ]
li => [ MS SQL Server Integration service ]
li => [ Clover ETL ]
strong => [ 2. Open Source ETL tools ]
li => [ Pentaho ]
li => [ Kettle ]
h3 => [ 29) What is partitioning in ETL? ]
p => [ Transactions are always needed to be divided for better performance. The same processes are known as Partitioning. It merely makes sure that the server can directly access the sources through multiple connections. ]
h3 => [ 30) What is ETL Pipeline? ]
p => [ ETL Pipeline refers to a set of processes to extract the data from one system, transform it, and load it into some database or data warehouse. ETL pipelines are built for data warehousing applications, which includes both enterprise data warehouse as well as subject-specific data marts. ETL pipelines are also used for data migration solutions. Data warehouse/ business intelligence engineers build ETL pipelines. ]
h3 => [ 31) What is the Data Pipeline? ]
p => [ Data Pipeline refers to any set of processes elements that move data from one system to another. Data Pipeline can be built for any kind of application which uses data to bring the value. It can be used for integrating the data across the applications, build the data-driven web products and carrying out the data mining activities. Data engineers build the data pipeline. ]
h3 => [ 32) What is the staging place in the ETL Testing? ]
p => [ Staging place is the temporary storage area that is used during the data integration process. In this place, data is analyzed carefully for redundancy and duplication. ]
h3 => [ 33) What is ETL mapping sheet? Define its significance. ]
p => [ ETL mapping sheet contains all the necessary information from the source file and stores the details in rows and column. Mapping sheets help in writing the SQL queries to speed up the testing process. ]
h3 => [ 34) What is the transformation in ETL Testing? ]
li => [ Transformation is defined as the archive objects to generate, modify, or pass the data. Transformation can be Active or passive. Transformation is beneficial in many ways. ]
li => [ It helps in getting values very quickly. ]
li => [ The transformation can update the slowly changing dimension table. ]
li => [ It checks or verifies whether the record exists or not inside the table. ]
h3 => [ 35) What is the use of dynamic cache and static cache in transformation? ]
p => [  Dynamic cache  is used to update the dimension or master table slowly. The static cache is used in flat files. ]
h3 => [ 36) What is a mapping, Session, Worklet, and Mapplet? ]
strong => [ Mapping: ]
strong => [ Workflow: ]
strong => [ Mapplet: ]
strong => [ Worklet: ]
strong => [ Session: ]
h3 => [ 37) What is full load and incremental or refresh load? ]
p => [  Full Load:  Full load completely erase the content of one or more tables and reload with fresh data. ]
p => [  Incremental Load:  In this, we apply the ongoing changes to one or more table, which is based on a predefined schedule. ]
h3 => [ 38) What are joiner and lookup? ]
p => [  The  joiner  is used to join two or more tables to retrieve the data from tables. ]
p => [  Lookup  is used to check and compare the source table and the target table. ]
h3 => [ 39) What is data purging? ]
p => [ Data Purging is a term that is commonly used to describe the methods which remove and permanently erase the data from a storage space. In other words, it can be defined as deleting the data from the data warehouse is known as data purging. Usually, we have to clean up the junk data like rows which have null values or spaces. Data Purging is the process of cleaning the junk values. ]
h3 => [ 40) What is the difference between ETL tools and OLAP tools? ]
p => [  ETL Tools  is meant for extraction the data from the legacy system and load it into the specified database with some process of cleansing data. ]
p => [  For example:  Informatica, data stage etc. ]
p => [  OLAP Tools:  It is used for reporting purpose in OLAP data available in the multidirectional model. We can write a simple query to extract the data from the database.  ]
p => [  Example:  Business object, Cognos, etc.  ]
a => [ Interview Tips ]
a => [ Job/HR Interview Questions ]
a => [ Company Interview Questions &amp; Procedure ]
a => [ JavaScript Interview Questions ]
a => [ Java Basics Interview Questions ]
a => [ Java OOPs Interview Questions ]
a => [ Servlet Interview Questions ]
a => [ JSP Interview Questions ]
span => [ Spring Interview Questions ]
span => [ Hibernate Interview Questions ]
span => [ PL/SQL Interview Questions ]
span => [ SQL Interview Questions ]
span => [ Oracle Interview Questions ]
span => [ Android Interview Questions ]
a => [ jQuery Interview Questions ]
span => [ MySQL Interview Questions ]
h2 => [ You may also like: ]
a => [ Java Interview Questions ]
a => [ SQL Interview Questions ]
a => [ Python Interview Questions ]
a => [ JavaScript Interview Questions ]
a => [ Angular Interview Questions ]
a => [ Selenium Interview Questions ]
a => [ Spring Boot Interview Questions ]
a => [ HR Interview Questions ]
a => [ C Programming Interview Questions ]
a => [ C++ Interview Questions ]
a => [ Data Structure Interview Questions ]
a => [ DBMS Interview Questions ]
a => [ HTML Interview Questions ]
a => [ IAS Interview Questions ]
a => [ Manual Testing Interview Questions ]
a => [ OOPs Interview Questions ]
a => [ .Net Interview Questions ]
a => [ C# Interview Questions ]
a => [ ReactJS Interview Questions ]
a => [ Networking Interview Questions ]
a => [ PHP Interview Questions ]
a => [ CSS Interview Questions ]
a => [ Node.js Interview Questions ]
a => [ Spring Interview Questions ]
a => [ Hibernate Interview Questions ]
a => [ AWS Interview Questions ]
a => [ Accounting Interview Questions ]
h2 => [ Learn Latest Tutorials ]
p => [ Splunk ]
p => [ SPSS ]
p => [ Swagger ]
p => [ Transact-SQL ]
p => [ Tumblr ]
p => [ ReactJS ]
p => [ Regex ]
p => [ Reinforcement Learning ]
p => [ R Programming ]
p => [ RxJS ]
p => [ React Native ]
p => [ Python Design Patterns ]
p => [ Python Pillow ]
p => [ Python Turtle ]
p => [ Keras ]
h2 => [ Preparation ]
p => [ Aptitude ]
p => [ Reasoning ]
p => [ Verbal Ability ]
p => [ Interview Questions ]
p => [ Company Questions ]
h2 => [ Trending Technologies ]
p => [ Artificial Intelligence ]
p => [ AWS ]
p => [ Selenium ]
p => [ Cloud Computing ]
p => [ Hadoop ]
p => [ ReactJS ]
p => [ Data Science ]
p => [ Angular 7 ]
p => [ Blockchain ]
p => [ Git ]
p => [ Machine Learning ]
p => [ DevOps ]
h2 => [ B.Tech / MCA ]
p => [ DBMS ]
p => [ Data Structures ]
p => [ DAA ]
p => [ Operating System ]
p => [ Computer Network ]
p => [ Compiler Design ]
p => [ Computer Organization ]
p => [ Discrete Mathematics ]
p => [ Ethical Hacking ]
p => [ Computer Graphics ]
p => [ Software Engineering ]
p => [ Web Technology ]
p => [ Cyber Security ]
p => [ Automata ]
p => [ C Programming ]
p => [ C++ ]
p => [ Java ]
p => [ .Net ]
p => [ Python ]
p => [ Programs ]
p => [ Control System ]
p => [ Data Mining ]
p => [ Data Warehouse ]
